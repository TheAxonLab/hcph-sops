{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"The Human Connectome PHantom (HCPh) study: Standard Operating Procedures","text":"<p>These SOPs correspond to a pre-registered report</p> <p>These documents correspond to a pre-registration<sup>1</sup>. Please check the corresponding registered report (direct download) to get a better understanding of what these SOPs implement.</p> <p>The experiments and hypotheses were pre-registered to further guarantee research rigor and seek early scrutiny and feedback from experts in the field, thereby generating consensus on data collection and analysis. Researchers increasingly perceive pre-registration as a tool to maximize research transparency, improve study planning, and eliminate incentives conducive to dubious practices in the search for positive outcomes. By pre-registering the study, we will maximize the impact and usefulness of this work.</p> <p>Future reports and public communications of results of this project will be pre-registered whenever that is possible.</p> Thanks to C\u00e9sar Caballero-Gaud\u00e9s and Stefano Moia <p>We highly appreciate the decisive help we have received from C\u00e9sar and Stefano to bring together the physiology component of this project.</p> <p>C\u00e9sar provided very valuable feedback at the earliest stages of the design of the project and has also facilitated it with key feedback (including a visit to show their settings at BCBL).</p> <p>Stefano helped edit our registered report, and traveled to Lausanne twice to help us on the spot with the BIOPAC and calibration.</p> Thanks to Garikoitz Lerma-Usabiaga <p>Gari filmed several versions of the Mundaka clip, that allowed us to edit the final clip that is presented during the resting state fMRI.</p> Thanks to In\u00e8s de Riedmatten and Arthur Spencer <p>In\u00e8s has contributed with excellent materials to the initial versions of these SOPs, and re-enabled the trigger issuing by our dMRI sequence (which had disappeared after a scanner's software upgrade...) Arthur helped us with more recent aspects regarding the gas analyzer calibration and has supported us in other meaningful ways.</p> Figure 1. Experimental design of Cohort I. The first section of the study involves acquiring 72 sessions across three scanners of a single subject."},{"location":"#summary","title":"Summary","text":"<p>Unveiling how the brain's structure defines its distributed function and modulates the dynamics of processing holds the promise of triggering a revolution in neuroscience and applications to mental health and neurodegenerative diseases. Magnetic resonance imaging (MRI) has proven a valuable, non-invasive way of probing both the architecture and activity of the brain in-vivo, with sufficient spatial and temporal resolution to understand many aspects of its function. Although a large body of literature has shown strong correlations between structural and functional networks at the larger scales<sup>2,3,4,5</sup>, the accumulated unreliability of MRI measurements from the scanner and through further steps of the research workflow impedes the link between structure, function, and dynamics at clinically relevant spatial and temporal scales. In particular, the measurements obtained with MRI are highly indirect, spatiotemporally uncertain, and confounded by other sources of MR signal. This complexity provides an immense informatics challenge that crosses multiple imaging modalities, including structural, functional, and dynamic connectivity approaches to understanding the human brain. Nonetheless, functional and structural networks extracted from MRI have proven sufficient levels of reliability to discriminate between individuals<sup>5,6,7,8</sup>, and such reliability has proven stable from months to years<sup>9</sup>. Therefore, it is critical to characterize the reliability of this network\u2019s phenotyping before these analytical approaches may be applied clinically<sup>10,11</sup>. In this project, we will first optimize the research workflow of MR network analyses to maximize the reliability of functional and structural connectivity matrices (so-called connectomes). Indeed, these matrices have been shown to contain large ratios of false positives and false negatives in both the functional 12 and the structural<sup>13,14</sup> cases.  We hypothesize that such improvements in sensitivity and specificity of functional and structural networks generalize across scanners and subjects, allowing the univocal identification of individuals from their brain\u2019s networks (\"fingerprinting\"). In order to be able to statistically separate and characterize the sources of signal variation, the project involves acquiring large amounts of repeated data on a small number of individuals. This approach has recently been dubbed \"precision MRI\"<sup>15</sup> and focuses on individual differences rather than group differences. The data acquisition approach is structured in three efforts with varying numbers of subjects, repetitions, and scanning devices. The first two, called \"Cohort I\" and \"Cohort II\" are sequential in time, and collected on three different devices. Cohort I involves a single individual who will undergo a total of 60 scanning sessions. Subsequently, Cohort II involves six (6) individuals and a total of twelve (12) sessions each. Finally, \"Cohort III\" is a quality control set involving 18 individuals and a total of two sessions each in a single scanner. In total, the project plans for repeated MRI acquisition on 25 healthy, adult human subjects, across three different 3.0 Tesla (T) MRI scanners available at CHUV. In addition to the new data, the project will reuse existing, open-access data to pilot various aspects of the MRI processing and analysis workflow to further support the overall reliability of the findings.</p>"},{"location":"#impact","title":"Impact","text":"<p>Overall, this project will equip researchers with a framework for the extraction of reliable and precise structural, functional and dynamic networks that permit their joint modeling and analysis with interpretable and reproducible methods. The project will publicly release two highly valuable datasets necessary for the improvement of the workflow for structural and functional network extraction under open access and reuse terms. Upon conclusion, this study will mark a turning point for MRI research as a fundamental resource for academic training and a necessary assessment to unlock clinical applications in the long-term with the improvement of the reliability of MRI-network analyses. At a local scale, the project will substantially contribute to ensuring the reliability of the MRI clinical workflow that routinely aids medical decisions at CHUV.</p>"},{"location":"changes/","title":"Change History","text":"<p>All notable changes to these SOPs are documented below, starting with the most recent version of the document.</p> <p>You found an error</p> <p>If you want to check the list of open issues, please proceed to our issue tracker.</p> <p>If you have identified a problem, a typo, or something missing, and you know it is not in our tracker, please report it by creating a new issue.</p>"},{"location":"changes/#040-september-27-2023","title":"0.4.0 (September 27, 2023)","text":"<p>Compare with 0.3.0</p>"},{"location":"changes/#enhancements-new-features-and-additions","title":"Enhancements, new features, and additions","text":"<ul> <li>Add report pre-registered on OSF and fix references  (f9a8360 by Oscar Esteban).</li> <li>Replace <code>--merge true</code> with <code>--how merge</code> in datalad updates  (d297d45 by Oscar Esteban).</li> <li>Add DataLad documentation for synchronizing and adding new data  (5d57e74 by Oscar Esteban).</li> <li>Add a <code>.zenodo.json</code> with the intent of connecting Zenodo  (ee429ea by Oscar Esteban).</li> <li>Play nice with Apache license in heuristic, better documentation  (2dffffc by Oscar Esteban).</li> </ul>"},{"location":"changes/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Datalad DOI and link  (fc63118 by Oscar Esteban).</li> <li>Escape HTML special characters  (e54c468 by Oscar Esteban).</li> <li>Escaping characters  (737edce by Oscar Esteban).</li> <li>Remaining bugs in heuristic file  (443493c by Oscar Esteban). Related issues/PRs: #179</li> <li>Revise heuristic after testing it  (ca49867 by Oscar Esteban).</li> <li>Overhaul of the data-management section with DataLad  (5afcd97 by Oscar Esteban). Related issues/PRs: #100, #163, #160</li> </ul>"},{"location":"changes/#030-september-06-2023","title":"0.3.0 (September 06, 2023)","text":"<p>Compare with 0.2.0</p>"},{"location":"changes/#enhancements-new-features-and-additions_1","title":"Enhancements, new features, and additions","text":"<ul> <li>Replace unicode symbols with octicons/fontawesome icons  (675e1ff by Oscar Esteban).</li> <li>Add ET description to intro  (8bf5278 by Oscar Esteban). Related issues/PRs: #146, #153</li> <li>Deep revision of the PR  (1fefe2d by Oscar Esteban).</li> <li>Added a safety check for the desiccant chamber color  (7c13efc by Alexandre Cionca).</li> </ul>"},{"location":"changes/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>Scanner name leak  (71a5e81 by Alexandre Cionca).</li> <li>Indentation for rendering / show admonition folded  (0747ffe by Oscar Esteban).</li> <li>Typos (ae572d9 by C\u00e9line Provins).</li> <li>Add missing picture in emergency procedures section  (e977607 by Oscar Esteban). Related issues/PRs: #89</li> </ul>"},{"location":"changes/#020-august-29-2023","title":"0.2.0 (August 29, 2023)","text":"<p>Compare with 0.1.0</p>"},{"location":"changes/#enhancements-new-features-and-additions_2","title":"Enhancements, new features, and additions","text":"<ul> <li>Change icon of quote admonitions  (fbadaed by Oscar Esteban).</li> <li>Large overhaul, including initial flowchart of the experiment  (0e0d390 by Oscar Esteban).</li> <li>Add explanation in SOPs and code to run defacing  (2d8982c by C\u00e9line Provins ).</li> <li>Add codespell  (61717da by Oscar Esteban).</li> <li>Add folder structure of the BIDS dataset  (c3d0a2a by Oscar Esteban). Related issues/PRs: #94</li> <li>Add tape for head motion  (2dbae4d by Oscar Esteban). Related issues/PRs: #87</li> <li>Add STP100D and MMBT-S manuals  (9feb336 by Oscar Esteban).</li> <li>Improve some admonitions  (de3f034 by Oscar Esteban).</li> </ul>"},{"location":"changes/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>Stop leaking host name  (5a42d85 by Oscar Esteban). Related issues/PRs: #122</li> <li>Refactor of the preliminary section, separating an intro from it  (19b4571 by Oscar Esteban).</li> <li>Trim trailing spaces, change admonition type  (6e16e80 by Oscar Esteban).</li> <li>Revert removal of indentation in script file  (9be8d05 by Oscar Esteban).</li> <li>Reorder some incongruent steps, move sound, light and ventilation  (e1f4b4b by Oscar Esteban).</li> <li>Use octicons and fontawesome  (09927cc by Oscar Esteban).</li> <li>Inconsistencies in the ET's eye-coverage setting and calibration  (15cebe2 by Oscar Esteban).</li> <li>Misplaced ET description and minor revisions  (60475e7 by Oscar Esteban). Related issues/PRs: #99</li> <li>Spell check and indentation with spaces  (2c2cdeb by Oscar Esteban).</li> <li>Add a note regarding disruption on BIDS names after session 14  (1da4810 by Oscar Esteban).</li> <li>Wrong number of sessions at index page  (1adb77d by Oscar Esteban).</li> <li>Typo  (abe827c by Oscar Esteban).</li> <li>Improve the key listening  (ead2438 by Oscar Esteban).</li> </ul>"},{"location":"changes/#maintenance-and-continuous-integration","title":"Maintenance and Continuous Integration","text":"<ul> <li>Update git-changelog config  (29d79f0 by Oscar Esteban).</li> <li>Fix file path and run black for style  (164d8f1 by Oscar Esteban).</li> </ul>"},{"location":"changes/#010-june-29-2023","title":"0.1.0 (June 29, 2023)","text":"<p>The first release of these SOPs. Currently, the document is still a work in progress, with the Data management, Preprocessing, and Release of data yet to be written.</p> <p>Compare with first commit</p>"},{"location":"changes/#enhancements-new-features-and-additions_3","title":"Enhancements, new features, and additions","text":"<ul> <li>Rename study-settings file  (f53526e by Oscar Esteban).</li> <li>Add task timings and references  (b21c717 by Oscar Esteban). Related issues/PRs: #73 Co-authored-by: Elodie Savary</li> <li>Add phys2bids commandline  (0d22fd7 by Oscar Esteban).</li> <li>Change theme, add chuv logo, update data-storage  (a00e833 by Oscar Esteban).</li> <li>Refining the participant preparation  (f450fd2 by Oscar Esteban).</li> <li>Sectioning the participant preparation  (84a4ee1 by Oscar Esteban).</li> <li>Revise @celprov's code  (a011894 by Oscar Esteban).</li> <li>Minimal, stylistic changes  (030a9ca by Oscar Esteban).</li> <li>Remove comment about starting recordings as it is now covered by #71  (e4fa2cf by Oscar Esteban).</li> <li>Overhaul of the scanning section of the SOPs  (732c963 by Oscar Esteban).</li> <li>Add emergency procedures  (fc52766 by C\u00e9line Provins ).</li> <li>Miscalleneous improvements and picture addition  (b9b74c0 by C\u00e9line Provins ).</li> <li>Add info on how to configure the Acknowledge software and record physiolocal signals  (f321875 by C\u00e9line Provins ).</li> <li>Add information about the outputs of the different sequences to better explain the procedure  (c7db90a by H\u00e9l\u00e8ne Lajous).</li> <li>Add info about cleaning procedure  (f15155a by H\u00e9l\u00e8ne Lajous).</li> <li>Correct typos and add info in case you know which exam will be run next  (3d82aee by H\u00e9l\u00e8ne Lajous).</li> <li>Add details about how to switch to advanced user mode to save a protocol  (8e5c46a by H\u00e9l\u00e8ne Lajous).</li> <li>Add details and correct a few typos  (fdd742d by H\u00e9l\u00e8ne Lajous).</li> <li>Review comments  (1745329 by Oscar Esteban).</li> <li>Add picture of the ET attached  (eaa3a8a by Oscar Esteban).</li> <li>Setup mkpdfs plugin  (2d6f9fd by Oscar Esteban).</li> <li>Make it louder  (6d6cce4 by Oscar Esteban).</li> <li>Add info box about moving the mirror slightly to the right  (589fd63 by Oscar Esteban).</li> <li>Add warning about attachment of infrared mirror  (00c214d by Oscar Esteban).</li> <li>Miscalleneous improvements and image additions  (a74aa6d by C\u00e9line Provins ).</li> <li>Give instructions on how to switch on the scanner  (c83ad23 by H\u00e9l\u00e8ne Lajous).</li> <li>Improve how the scanner is switched off  (f95d559 by H\u00e9l\u00e8ne Lajous).</li> <li>Say you want to turn the key  (85180b4 by H\u00e9l\u00e8ne Lajous).</li> <li>[heudiconv heuristic] Do not deduplicate if run is found  (5f15cca by Oscar Esteban).</li> <li>Add phone call script  (8b10d1c by C\u00e9line Provins ).</li> <li>Add what to do if the alarm rings  (f89e399 by C\u00e9line Provins ).</li> <li>Replace BIOPAC setup photo with Ines' annotated one  (8e97af7 by C\u00e9line Provins ).</li> <li>Add missing bibliography  (a667955 by C\u00e9line Provins ).</li> <li>Addition of miscalleneous information and of many missing pictures  (20ad2bd by C\u00e9line Provins ).</li> <li>Add link to reproin  (dd4978f by Oscar Esteban).</li> <li>Add a filter to show missing secrets as REDACTED or replace values  (61451c8 by Oscar Esteban).</li> <li>Improvements to the data management section  (2a176c1 by Oscar Esteban).</li> <li>Minimal improvements to clean-up  (d20edf3 by Oscar Esteban).</li> <li>Add pictures and improve new exam description  (c02291f by Oscar Esteban).</li> <li>Split data collection  (516c388 by Oscar Esteban).</li> <li>Add GA video  (944a525 by Oscar Esteban).</li> <li>Reorder misplaced steps, improve rendering  (3ede838 by Oscar Esteban).</li> <li>Ensuring it looks good when rendered  (07b0f04 by Oscar Esteban).</li> <li>Added some files, restructure and fix some items  (3fa2c85 by Oscar Esteban).</li> <li>Fix typos and overhaul of data collection  (00e3daf by Oscar Esteban).</li> <li>Add images of gas analyzer  (6032ed0 by C\u00e9line Provins ).</li> <li>Add info how to setup the respiration belt and the gas analyzer  (62bf6fd by C\u00e9line Provins ).</li> <li>Add info to setup BIOPAC  (3719eca by C\u00e9line Provins ).</li> <li>Add info to turn off computer  (3e66ec8 by C\u00e9line Provins ).</li> <li>Add info about plugging the coil after the exam has been open  (1d5b501 by C\u00e9line Provins ).</li> <li>Add info about how to save the magnitude image of the fmap  (d3efc7d by C\u00e9line Provins ).</li> <li>Add ack, edit/reorder some sections  (46e41fa by Oscar Esteban).</li> <li>First pass at data collection checklist  (2ab93f7 by Oscar Esteban).</li> <li>Update README  (3833e37 by Oscar Esteban).</li> </ul>"},{"location":"changes/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>Add missing settings file  (0d4d3f8 by Oscar Esteban).</li> <li>[heudiconv heuristic] Identify phase and mag in func and fmap-epi  (e1e3170 by Oscar Esteban).</li> <li>[heudiconv heuristic] Robuster detection of phase/mag in GRE fieldmaps  (e65f0d2 by Oscar Esteban).</li> <li>Wrong path of mathjax  (731dfdd by Oscar Esteban).</li> <li>Reorder scanning protocol to match sequences order in the manuscript  (80ee8f4 by C\u00e9line Provins ).</li> <li>Correct console parameter name for reconstruction  (dd1f3cf by C\u00e9line Provins ).</li> <li>Fix layout  (3facec9 by C\u00e9line Provins ).</li> <li>Wrong link to psychopy git repo  (33ed5e5 by C\u00e9line Provins ).</li> <li>Missing picture  (7eb7f42 by C\u00e9line Provins ).</li> <li>Update RR figure 1  (387722b by Oscar Esteban).</li> <li>Add missing dependency  (976ae4c by Oscar Esteban).</li> <li>Correct errors I introduced in @helenelajous' PR  (3b656f2 by Oscar Esteban).</li> <li>[heudiconv heuristic] More sensible decision for phasediff fieldmaps  (3d9b73e by Oscar Esteban).</li> <li>[heudiconv heuristic] Set run when duplicates of a sequence are found  (504e217 by Oscar Esteban).</li> <li>[heudiconv heuristic] Overhaul of the reproin heuristic  (6576b32 by Oscar Esteban).</li> <li>Minimal amends  (9e9d56f by Oscar Esteban).</li> <li>PACSMAN instructions  (b562372 by Oscar Esteban).</li> <li>PACSMAN csv file example  (e0a8f66 by Oscar Esteban).</li> <li>Images with wrong paths, and names  (5260d62 by Oscar Esteban).</li> <li>Miscellaneous stuff  (df5a300 by Oscar Esteban).</li> <li>Update version of gha/checkout and fix path second time  (cfcc19c by Oscar Esteban).</li> <li>Still setting up path  (dfe542c by Oscar Esteban).</li> <li>Roll-back the path option  (ac2661f by Oscar Esteban).</li> <li>Checkout action  (1a149b2 by Oscar Esteban).</li> <li>Remove toc plugin  (3861174 by Oscar Esteban).</li> </ul>"},{"location":"changes/#maintenance-and-continuous-integration_1","title":"Maintenance and Continuous Integration","text":"<ul> <li>Set <code>--in-place</code> editing of the changelog  (48f8acd by Oscar Esteban).</li> <li>Refine changelog update with git-changelog  (e4ea298 by Oscar Esteban).</li> <li>Use git-changelog to update the changelog  (856e58a by Oscar Esteban).</li> <li>Remove old exemplary code  (2e5697c by Oscar Esteban).</li> </ul>"},{"location":"release/","title":"Defacing","text":"<p>The first step before releasing the data is to deface the T1w and T2w images for all sessions. To perform defacing, we are using a software called PyDeface (Gulban et al. 2019). To proceed, run the following command in the command line: <pre><code>    bash ./code/defacing/run_pydeface.sh\n</code></pre></p>"},{"location":"release/#references","title":"References","text":"<p>[1]: Gulban, Omer Faruk, Dylan Nielson, Russ Poldrack, John Lee, Chris Gorgolewski, Vanessa Sochat, and Satrajit Ghosh. 2019. \u201cPoldracklab/Pydeface: V2.0.0.\u201d Zenodo. doi: 10.5281/zenodo.3524401.</p>"},{"location":"assets/code/events/events-from-psychopy/","title":"Generating BIDS events files from Psychopy's artifacts","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\n\nfrom matplotlib import pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (20, 2.5)\n</pre> %matplotlib inline  from matplotlib import pyplot as plt plt.rcParams[\"figure.figsize\"] = (20, 2.5) In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\nfrom pickle import load\nfrom json import dumps\nimport numpy as np\nimport pandas as pd\nimport h5py\nfrom psychopy.tools.filetools import fromFile\n</pre> from pathlib import Path from pickle import load from json import dumps import numpy as np import pandas as pd import h5py from psychopy.tools.filetools import fromFile In\u00a0[\u00a0]: Copied! <pre>DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/psychopy\")\nBIDS_PATH = Path(\"/data/datasets/hcph\")\n</pre> DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/psychopy\") BIDS_PATH = Path(\"/data/datasets/hcph\") In\u00a0[\u00a0]: Copied! <pre>session_path = DATA_PATH / \"session-2023-11-03\"\n</pre> session_path = DATA_PATH / \"session-2023-11-03\" In\u00a0[\u00a0]: Copied! <pre>f = h5py.File(session_path / \"bht_2023-11-03_20h27.56.353_0_session_29.hdf5\")\ndata = f[\"data_collection\"]\nprint(list(data.keys()))\nlist(data[\"events\"].keys())\n</pre> f = h5py.File(session_path / \"bht_2023-11-03_20h27.56.353_0_session_29.hdf5\") data = f[\"data_collection\"] print(list(data.keys())) list(data[\"events\"].keys()) In\u00a0[\u00a0]: Copied! <pre>data[\"session_meta_data\"][:]\n</pre> data[\"session_meta_data\"][:] In\u00a0[\u00a0]: Copied! <pre>data[\"events\"][\"experiment\"][\"MessageEvent\"].shape\n</pre> data[\"events\"][\"experiment\"][\"MessageEvent\"].shape In\u00a0[\u00a0]: Copied! <pre>import os\n\nos.environ['PYOPENGL_PLATFORM'] = 'egl'\n</pre> import os  os.environ['PYOPENGL_PLATFORM'] = 'egl' In\u00a0[\u00a0]: Copied! <pre>from jupylet.app import App\nfrom jupylet.label import Label\napp = App(width=320, height=64)\n\npsydata = fromFile(session_path / \"bht_2023-11-03_20h27.56.353_0_session_29.psydat\")\n</pre> from jupylet.app import App from jupylet.label import Label app = App(width=320, height=64)  psydata = fromFile(session_path / \"bht_2023-11-03_20h27.56.353_0_session_29.psydat\") In\u00a0[\u00a0]: Copied! <pre>logtext = (session_path / \"qct_2023-11-03_19h58.22.540_0_session_29.log\").read_text()\n</pre> logtext = (session_path / \"qct_2023-11-03_19h58.22.540_0_session_29.log\").read_text() In\u00a0[\u00a0]: Copied! <pre>print(logtext)\n</pre> print(logtext) In\u00a0[\u00a0]: Copied! <pre>from write_event_file import write_event_file_from_log\n</pre> from write_event_file import write_event_file_from_log In\u00a0[\u00a0]: Copied! <pre>import re\nfrom write_event_file import TRIAL_TYPE\n\ndef write_event_file_from_log(logfile: Path) -&gt; None:\n    \"\"\"\n    Create a BIDS events file from the psychopy log.\n    Parameters\n    ----------\n    log :obj:`os.pathlike`\n         The path to the log output from psychopy.\n    \"\"\"\n    \n    logtext = logfile.read_text()\n    \n    # Initialize events dataframe\n    event_dataframe = pd.DataFrame(\n        columns=[\"onset\", \"duration\", \"trial-type\", \"value\"]\n    )\n\n    # Find the timestamp of the first trigger aka the beginning of fMRI recording\n    trigger_pattern = r\"([\\d.]+)\\s+DATA\\s+Keypress:\\s+s\"\n    trigger_timestamp = float(re.findall(trigger_pattern, logtext)[0])\n\n    # Create a regular expression pattern to match lines containing any of the word corresponding to tasks\n    autodraw_pattern = r\"([\\d.]+)\\s+EXP\\s+({}):\\s+autoDraw\\s*=\\s*(\\w+)\".format(\n        \"|\".join(TRIAL_TYPE.keys())\n    )\n\n    # Use re.findall to find all matching lines in the log\n    autodraw_events = re.findall(autodraw_pattern, logtext)\n    timestamps, keywords, statuses = zip(*autodraw_events)\n    events_table = pd.DataFrame.from_dict(\n        {\n            \"onset\": np.array(timestamps, dtype=float) - trigger_timestamp,\n            \"event\": [TRIAL_TYPE[k] for k in keywords],\n            \"status\": statuses,\n        },\n    )\n    print(events_table)\n\n    # Initialize variable to keep track of the start timestampss\n    start_timestamp = {}\n\n    # Extract the times associated with the matches\n    for timestamp, keyword, status in autodraw_events:\n        if status == \"True\":\n            # Store the start timestamp for \"autoDraw=True\"\n            start_timestamp[keyword] = timestamp\n\n        elif status == \"False\" and keyword in start_timestamp:\n\n            # Calculate the duration for \"autoDraw=False\" if there is a corresponding \"autoDraw=True\"\n            onset = float(start_timestamp[keyword])\n            end = float(timestamp)\n            duration = end - onset\n\n            # Match keyword with associated sub-task\n            trial_type = TRIAL_TYPE[keyword]\n\n            # For the fingertapping and the eye movement sub-tasks, we have to encode which hand or the position\n            # of the fixation point to fully characterize the sub-task instance.\n            value = \"\"\n            if trial_type == \"mot\":\n                # Which hand is instructed to fingertap is encoded in the psychopy log one line above\n                # the onset 'ft_hand : autoDraw = True' and as the same timestamp as the onset.\n                hand_pattern = (\n                    r\"{:.4f}\\s+EXP\\s+ft_hand:\\s*text\\s*=\\s*\\'(RIGHT|LEFT)\\'\".format(\n                        onset\n                    )\n                )\n                hand_match = re.search(hand_pattern, logtext)\n                value = hand_match.group(1).lower()\n\n            elif trial_type == \"cog\":\n                # The position of the point is reported in the psychopy log 5 to 7 lines above\n                # the onset event of the cognitive instance.\n\n                # Retrieve line number corresponding to the onset event\n                pattern = r\"{:.4f}\\s+EXP\\s+{}:\\s+autoDraw\\s*=\\s*True\".format(\n                    onset, keyword\n                )\n                match = re.search(pattern, logtext)\n                (\n                    start,\n                    end,\n                ) = match.span()  # Get the start and end position of the match\n                line_nbr = (\n                    logtext.count(\"\\n\", 0, start) + 1\n                )  # Calculate the corresponding line number\n\n                # Extract the seven lines before the match\n                previous_lines = logtext.splitlines()[line_nbr - 7 : line_nbr]\n                previous_lines_text = \"\\n\".join(previous_lines)\n\n                # Find all the matches using the regular expression\n                fix_pos_pattern = r\"([\\d.]+)\\s+EXP\\s+New trial \\(rep=\\d+, index=\\d+\\): OrderedDict\\(\\[\\(\\'xpos\\', (-?\\d+\\.\\d+)\\), \\(\\'ypos\\', (-?\\d+\\.\\d+)\\)\\]\\)\"\n                matches = re.findall(fix_pos_pattern, previous_lines_text)\n                #If the patterns is found several times, the last appearance is the one corresponding to the event\n                timestamp, xpos, ypos = matches[-1]\n                value = f\"[{xpos}, {ypos}]\"\n\n            # If no trigger were recorded in the psychopy log, we need to approximate its timestamp\n            # with the closest log event.\n            if not timestamp:\n                if keyword == \"movie\":\n                    # We coded the resting-state task such that the movie starts at the trigger.\n                    trigger_timestamp = onset\n                elif keyword in [\"blank\", \"cog\", \"mot\", \"cog\"]:\n                    # The closest event for qct is \"EXP \teyetracker.clearEvents()\"\n                    trigger_pattern = r\"(\\d+\\.\\d+)\\s+EXP\\s+eyetracker.clearEvents()\"\n                    trigger_timestamp = float(re.findall(trigger_pattern, logtext)[0])\n                else:\n                    # The closest event for bht is \"EXP  text_2: autoDraw = False\"\n                    trigger_pattern = r\"(\\d+\\.\\d+)\\s+EXP\\s+text_2: autoDraw = False\"\n                    trigger_timestamp = float(re.findall(trigger_pattern, logtext)[0])\n\n            # Subtract the timestamp of the first trigger to the onset of the task to get events\n            # onset in the fMRI recording time.\n            onset = onset - trigger_timestamp\n\n            # Keep only 1 decimal of precision\n            onset = \"{:.1f}\".format(round(onset, 1))\n            duration = \"{:.1f}\".format(round(duration, 1))\n\n            # We have all the information needed for the event, it can be inserted in the dataframe.\n            event = {\n                \"onset\": onset,\n                \"duration\": duration,\n                \"trial-type\": trial_type,\n                \"value\": value,\n            }\n            event_dataframe = pd.concat(\n                [event_dataframe, pd.DataFrame([event])], ignore_index=True\n            )\n\n            # Remove the start timestamp from the dictionary to avoid double counting\n            del start_timestamp[keyword]\n\n    output_folder = os.path.dirname(log)\n    base_name = os.path.basename(log)\n    # The from_log might break the BIDS compatibility, but for now I don't know how else\n    # to distinguish between events.tsv generated from the channels versus the psychopy log\n    output_file = os.path.join(\n        output_folder, base_name.replace(\".log\", \"_from_log_events.tsv\")\n    )\n    return event_dataframe\n</pre> import re from write_event_file import TRIAL_TYPE  def write_event_file_from_log(logfile: Path) -&gt; None:     \"\"\"     Create a BIDS events file from the psychopy log.     Parameters     ----------     log :obj:`os.pathlike`          The path to the log output from psychopy.     \"\"\"          logtext = logfile.read_text()          # Initialize events dataframe     event_dataframe = pd.DataFrame(         columns=[\"onset\", \"duration\", \"trial-type\", \"value\"]     )      # Find the timestamp of the first trigger aka the beginning of fMRI recording     trigger_pattern = r\"([\\d.]+)\\s+DATA\\s+Keypress:\\s+s\"     trigger_timestamp = float(re.findall(trigger_pattern, logtext)[0])      # Create a regular expression pattern to match lines containing any of the word corresponding to tasks     autodraw_pattern = r\"([\\d.]+)\\s+EXP\\s+({}):\\s+autoDraw\\s*=\\s*(\\w+)\".format(         \"|\".join(TRIAL_TYPE.keys())     )      # Use re.findall to find all matching lines in the log     autodraw_events = re.findall(autodraw_pattern, logtext)     timestamps, keywords, statuses = zip(*autodraw_events)     events_table = pd.DataFrame.from_dict(         {             \"onset\": np.array(timestamps, dtype=float) - trigger_timestamp,             \"event\": [TRIAL_TYPE[k] for k in keywords],             \"status\": statuses,         },     )     print(events_table)      # Initialize variable to keep track of the start timestampss     start_timestamp = {}      # Extract the times associated with the matches     for timestamp, keyword, status in autodraw_events:         if status == \"True\":             # Store the start timestamp for \"autoDraw=True\"             start_timestamp[keyword] = timestamp          elif status == \"False\" and keyword in start_timestamp:              # Calculate the duration for \"autoDraw=False\" if there is a corresponding \"autoDraw=True\"             onset = float(start_timestamp[keyword])             end = float(timestamp)             duration = end - onset              # Match keyword with associated sub-task             trial_type = TRIAL_TYPE[keyword]              # For the fingertapping and the eye movement sub-tasks, we have to encode which hand or the position             # of the fixation point to fully characterize the sub-task instance.             value = \"\"             if trial_type == \"mot\":                 # Which hand is instructed to fingertap is encoded in the psychopy log one line above                 # the onset 'ft_hand : autoDraw = True' and as the same timestamp as the onset.                 hand_pattern = (                     r\"{:.4f}\\s+EXP\\s+ft_hand:\\s*text\\s*=\\s*\\'(RIGHT|LEFT)\\'\".format(                         onset                     )                 )                 hand_match = re.search(hand_pattern, logtext)                 value = hand_match.group(1).lower()              elif trial_type == \"cog\":                 # The position of the point is reported in the psychopy log 5 to 7 lines above                 # the onset event of the cognitive instance.                  # Retrieve line number corresponding to the onset event                 pattern = r\"{:.4f}\\s+EXP\\s+{}:\\s+autoDraw\\s*=\\s*True\".format(                     onset, keyword                 )                 match = re.search(pattern, logtext)                 (                     start,                     end,                 ) = match.span()  # Get the start and end position of the match                 line_nbr = (                     logtext.count(\"\\n\", 0, start) + 1                 )  # Calculate the corresponding line number                  # Extract the seven lines before the match                 previous_lines = logtext.splitlines()[line_nbr - 7 : line_nbr]                 previous_lines_text = \"\\n\".join(previous_lines)                  # Find all the matches using the regular expression                 fix_pos_pattern = r\"([\\d.]+)\\s+EXP\\s+New trial \\(rep=\\d+, index=\\d+\\): OrderedDict\\(\\[\\(\\'xpos\\', (-?\\d+\\.\\d+)\\), \\(\\'ypos\\', (-?\\d+\\.\\d+)\\)\\]\\)\"                 matches = re.findall(fix_pos_pattern, previous_lines_text)                 #If the patterns is found several times, the last appearance is the one corresponding to the event                 timestamp, xpos, ypos = matches[-1]                 value = f\"[{xpos}, {ypos}]\"              # If no trigger were recorded in the psychopy log, we need to approximate its timestamp             # with the closest log event.             if not timestamp:                 if keyword == \"movie\":                     # We coded the resting-state task such that the movie starts at the trigger.                     trigger_timestamp = onset                 elif keyword in [\"blank\", \"cog\", \"mot\", \"cog\"]:                     # The closest event for qct is \"EXP \teyetracker.clearEvents()\"                     trigger_pattern = r\"(\\d+\\.\\d+)\\s+EXP\\s+eyetracker.clearEvents()\"                     trigger_timestamp = float(re.findall(trigger_pattern, logtext)[0])                 else:                     # The closest event for bht is \"EXP  text_2: autoDraw = False\"                     trigger_pattern = r\"(\\d+\\.\\d+)\\s+EXP\\s+text_2: autoDraw = False\"                     trigger_timestamp = float(re.findall(trigger_pattern, logtext)[0])              # Subtract the timestamp of the first trigger to the onset of the task to get events             # onset in the fMRI recording time.             onset = onset - trigger_timestamp              # Keep only 1 decimal of precision             onset = \"{:.1f}\".format(round(onset, 1))             duration = \"{:.1f}\".format(round(duration, 1))              # We have all the information needed for the event, it can be inserted in the dataframe.             event = {                 \"onset\": onset,                 \"duration\": duration,                 \"trial-type\": trial_type,                 \"value\": value,             }             event_dataframe = pd.concat(                 [event_dataframe, pd.DataFrame([event])], ignore_index=True             )              # Remove the start timestamp from the dictionary to avoid double counting             del start_timestamp[keyword]      output_folder = os.path.dirname(log)     base_name = os.path.basename(log)     # The from_log might break the BIDS compatibility, but for now I don't know how else     # to distinguish between events.tsv generated from the channels versus the psychopy log     output_file = os.path.join(         output_folder, base_name.replace(\".log\", \"_from_log_events.tsv\")     )     return event_dataframe In\u00a0[\u00a0]: Copied! <pre>write_event_file_from_log(session_path / \"qct_2023-11-03_19h58.22.540_0_session_29.log\")\n</pre> write_event_file_from_log(session_path / \"qct_2023-11-03_19h58.22.540_0_session_29.log\") In\u00a0[124]: Copied! <pre>from __future__ import annotations\nimport pandas as pd\nimport numpy as np\nimport re\nfrom pathlib import Path\n\nTRIAL_TYPE = {\n    \"eye_movement_fixation\": \"cog\",\n    \"ft_hand\": \"mot\",\n    \"fixation\": \"blank\",\n    \"grating\": \"vis\",\n    \"movie\": \"movie\",\n    \"bh_body\": \"red\",\n    \"bh_end\": \"lightred\",\n    \"end_trial_msg\": \"end-message\",\n    \"polygon_4\": \"in\",\n    \"polygon1\": \"out\",\n    \"polygon_6\": \"in-last\",\n    \"polygon_8\": \"out-last\",\n    \"bh_body_2\": \"hold\",\n    \"bh_end_2\": \"hold-warning\",\n    \"bh_end_3\": \"refractory\",\n    \"polygon_5\": \"out\",  # old\n    \"polygon_7\": \"out\",  # old\n}\n\n\ndef psychopy2pandas(log_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert a PsychoPy log file to a *Pandas* DataFrame.\n\n    Parameters\n    ----------\n    log_file : :obj:`os.pathlike`\n        The path to the PsychoPy log file.\n\n    Returns\n    -------\n    df : :obj:`pandas.DataFrame`\n        A DataFrame containing event information.\n    \n    \"\"\"\n    \n\n    df = pd.read_csv(\n        log_path,\n        sep=\"\\t\",\n        names=[\"onset\", \"level\", \"desc\"],\n        dtype={\"onset\": float},\n    )\n\n    # Refer all onsets to the first trigger (first DATA entry)\n    df.onset -= df[df.level.str.contains(\"DATA\")].onset.values[0]\n\n    # Extract events\n    df[[\"trial_type\", \"start_end\"]] = df[\"desc\"].str.extract(r\"({}):\\s+autoDraw\\s*=\\s*(\\w+)\".format(\"|\".join(TRIAL_TYPE.keys())))\n\n    # Extract hand of motor block of qct\n    df[\"hand\"] = df[\"desc\"].str.extract(r\"ft_hand:\\s*text\\s*=\\s*\\'(RIGHT|LEFT)\\'\")\n    df.loc[df.hand.notna(), \"trial_type\"] = \"ft_hand\"\n    # Normalize L/R values of motor blocks\n    df = df.replace({\"hand\": {\"RIGHT\": \"R\", \"LEFT\": \"L\"}})\n\n    # Extract coordinates of cognitive block of qct\n    df[[\"x\", \"y\"]] = df[\"desc\"].str.extract(r\"New trial \\(rep=\\d+, index=\\d+\\): OrderedDict\\(\\[\\(\\'xpos\\', (-?\\d+\\.\\d+)\\), \\(\\'ypos\\', (-?\\d+\\.\\d+)\\)\\]\\)\")\n    df[[\"x\", \"y\"]] = df[[\"x\", \"y\"]].astype(float)\n    df.loc[df.x.notna(), \"trial_type\"] = \"eye_movement_fixation\"\n\n    # Drop duplicates (all columns exactly the same)\n    df = df.drop_duplicates()\n   \n    return df\n\n\ndef pandas2bids(input_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert a Pandas DataFrame with event information to a BIDS-compatible DataFrame.\n\n    This function takes an input DataFrame with event information, performs various data transformations\n    to create a BIDS-compatible DataFrame, and returns the resulting DataFrame.\n\n    Parameters\n    ----------\n    input_df : :obj:`pandas.DataFrame`\n        The input DataFrame containing event information.\n\n    Returns\n    -------\n    df : :obj:`pandas.DataFrame`\n        A BIDS-compatible DataFrame with columns 'onset', 'duration', 'trial_type', and 'value'.\n\n    Notes:\n    - Rows without 'trial_type' are dropped from the input DataFrame.\n    - New columns 'duration' and 'value' are added to the resulting DataFrame.\n    - Durations are calculated based on 'start_end' information and assigned to the appropriate rows.\n    - Values are retrieved from previous rows for specific trial types and assigned to the relevant rows.\n    - Event names are normalized based on 'TRIAL_TYPE' (please ensure 'TRIAL_TYPE' is defined).\n    - Mock events in 'end-message' are replaced with appropriate values, and block numbers are assigned.\n\n    Examples\n    --------\n    &gt;&gt;&gt; input_df = pd.DataFrame(...)\n    &gt;&gt;&gt; output_df = pandas2bids(input_df)\n\n    \"\"\"\n\n    # Drop rows without trial type\n    df = input_df[input_df.trial_type.notna()]\n    # Prepare new columns (duration and value)\n    df = df.reindex(columns=[\"onset\", \"duration\", \"trial_type\", \"value\", \"start_end\", \"hand\", \"x\", \"y\"])\n    df[\"value\"] = df[\"value\"].astype(str)\n    \n    for et in set(df.trial_type.values):\n        # Create a subdataframe with only this trial type\n        subdf = df[df.trial_type == et]\n\n        if len(subdf) &lt; 2:  # No need to try if not a block\n            continue\n\n        # Calculate durations\n        onsets = subdf.start_end.notna() &amp; subdf.start_end.str.contains(\"True\")\n        offsets = subdf.start_end.notna() &amp; subdf.start_end.str.contains(\"False\")\n        \n        if len(subdf[onsets].onset.values) == len(subdf[offsets].onset.values):\n            durations = subdf[offsets].onset.values - subdf[onsets].onset.values\n        else:\n            durations = subdf[offsets].onset.values[::2] - subdf[onsets].onset.values\n        \n        # And assign the duration to the first event row (the one containing autoDraw = True)\n        subdf.loc[onsets, \"duration\"] = durations\n\n        # Retrieve values from previous row for cognitive and motor blocks\n        if et == \"eye_movement_fixation\":\n            shifted = subdf.loc[subdf.start_end.isna() &amp; subdf.x.notna(), [\"x\", \"y\"]].values\n            subdf.loc[onsets, \"value\"] = [f\"({v[0]}, {v[1]})\" for v in shifted]\n        elif et == \"ft_hand\":\n            shifted = subdf.loc[subdf.start_end.isna(), \"hand\"].values\n            subdf.loc[onsets, \"value\"] = shifted\n\n        # Move back to general dataframe\n        df[df.trial_type == et] = subdf\n\n    # Drop rows from which data was copied to the principal event row.\n    df = df.drop(df[df.start_end.notna() &amp; df.start_end.str.contains(\"False\")].index)\n    df = df.drop(df[df.start_end.isna() &amp; df.x.notna()].index)\n    df = df.drop(df[df.start_end.isna() &amp; df.hand.notna()].index)\n  \n    # Normalize event names\n    df = df.replace({\"trial_type\": TRIAL_TYPE})\n    \n    # Replace mock events in bht\n    if \"end-message\" in set(df.trial_type.values):\n        end_index = df[df.trial_type == \"end-message\"].index[0]\n        df.loc[:end_index] = df.loc[:end_index].replace(\n            {\n                \"trial_type\": {\"in\": \"green\", \"out\": \"yellow\", \"in-last\": \"light-green\", \"out-last\": \"gold\"},\n            },\n        )\n        df.loc[:end_index, \"value\"] = \"mock\"\n        \n        # After the mock there are 5 \"true\" blocks.\n        len_remaining = len(df.loc[end_index + 1:, \"value\"])\n        df.loc[end_index + 1:, \"value\"] = [f\"block{v}\" for block in range(1, 7) for v in [block] * 13][:len_remaining]\n        \n    return df[[\"onset\", \"duration\", \"trial_type\", \"value\"]]\n</pre> from __future__ import annotations import pandas as pd import numpy as np import re from pathlib import Path  TRIAL_TYPE = {     \"eye_movement_fixation\": \"cog\",     \"ft_hand\": \"mot\",     \"fixation\": \"blank\",     \"grating\": \"vis\",     \"movie\": \"movie\",     \"bh_body\": \"red\",     \"bh_end\": \"lightred\",     \"end_trial_msg\": \"end-message\",     \"polygon_4\": \"in\",     \"polygon1\": \"out\",     \"polygon_6\": \"in-last\",     \"polygon_8\": \"out-last\",     \"bh_body_2\": \"hold\",     \"bh_end_2\": \"hold-warning\",     \"bh_end_3\": \"refractory\",     \"polygon_5\": \"out\",  # old     \"polygon_7\": \"out\",  # old }   def psychopy2pandas(log_path: str | Path) -&gt; pd.DataFrame:     \"\"\"     Convert a PsychoPy log file to a *Pandas* DataFrame.      Parameters     ----------     log_file : :obj:`os.pathlike`         The path to the PsychoPy log file.      Returns     -------     df : :obj:`pandas.DataFrame`         A DataFrame containing event information.          \"\"\"           df = pd.read_csv(         log_path,         sep=\"\\t\",         names=[\"onset\", \"level\", \"desc\"],         dtype={\"onset\": float},     )      # Refer all onsets to the first trigger (first DATA entry)     df.onset -= df[df.level.str.contains(\"DATA\")].onset.values[0]      # Extract events     df[[\"trial_type\", \"start_end\"]] = df[\"desc\"].str.extract(r\"({}):\\s+autoDraw\\s*=\\s*(\\w+)\".format(\"|\".join(TRIAL_TYPE.keys())))      # Extract hand of motor block of qct     df[\"hand\"] = df[\"desc\"].str.extract(r\"ft_hand:\\s*text\\s*=\\s*\\'(RIGHT|LEFT)\\'\")     df.loc[df.hand.notna(), \"trial_type\"] = \"ft_hand\"     # Normalize L/R values of motor blocks     df = df.replace({\"hand\": {\"RIGHT\": \"R\", \"LEFT\": \"L\"}})      # Extract coordinates of cognitive block of qct     df[[\"x\", \"y\"]] = df[\"desc\"].str.extract(r\"New trial \\(rep=\\d+, index=\\d+\\): OrderedDict\\(\\[\\(\\'xpos\\', (-?\\d+\\.\\d+)\\), \\(\\'ypos\\', (-?\\d+\\.\\d+)\\)\\]\\)\")     df[[\"x\", \"y\"]] = df[[\"x\", \"y\"]].astype(float)     df.loc[df.x.notna(), \"trial_type\"] = \"eye_movement_fixation\"      # Drop duplicates (all columns exactly the same)     df = df.drop_duplicates()         return df   def pandas2bids(input_df: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"     Convert a Pandas DataFrame with event information to a BIDS-compatible DataFrame.      This function takes an input DataFrame with event information, performs various data transformations     to create a BIDS-compatible DataFrame, and returns the resulting DataFrame.      Parameters     ----------     input_df : :obj:`pandas.DataFrame`         The input DataFrame containing event information.      Returns     -------     df : :obj:`pandas.DataFrame`         A BIDS-compatible DataFrame with columns 'onset', 'duration', 'trial_type', and 'value'.      Notes:     - Rows without 'trial_type' are dropped from the input DataFrame.     - New columns 'duration' and 'value' are added to the resulting DataFrame.     - Durations are calculated based on 'start_end' information and assigned to the appropriate rows.     - Values are retrieved from previous rows for specific trial types and assigned to the relevant rows.     - Event names are normalized based on 'TRIAL_TYPE' (please ensure 'TRIAL_TYPE' is defined).     - Mock events in 'end-message' are replaced with appropriate values, and block numbers are assigned.      Examples     --------     &gt;&gt;&gt; input_df = pd.DataFrame(...)     &gt;&gt;&gt; output_df = pandas2bids(input_df)      \"\"\"      # Drop rows without trial type     df = input_df[input_df.trial_type.notna()]     # Prepare new columns (duration and value)     df = df.reindex(columns=[\"onset\", \"duration\", \"trial_type\", \"value\", \"start_end\", \"hand\", \"x\", \"y\"])     df[\"value\"] = df[\"value\"].astype(str)          for et in set(df.trial_type.values):         # Create a subdataframe with only this trial type         subdf = df[df.trial_type == et]          if len(subdf) &lt; 2:  # No need to try if not a block             continue          # Calculate durations         onsets = subdf.start_end.notna() &amp; subdf.start_end.str.contains(\"True\")         offsets = subdf.start_end.notna() &amp; subdf.start_end.str.contains(\"False\")                  if len(subdf[onsets].onset.values) == len(subdf[offsets].onset.values):             durations = subdf[offsets].onset.values - subdf[onsets].onset.values         else:             durations = subdf[offsets].onset.values[::2] - subdf[onsets].onset.values                  # And assign the duration to the first event row (the one containing autoDraw = True)         subdf.loc[onsets, \"duration\"] = durations          # Retrieve values from previous row for cognitive and motor blocks         if et == \"eye_movement_fixation\":             shifted = subdf.loc[subdf.start_end.isna() &amp; subdf.x.notna(), [\"x\", \"y\"]].values             subdf.loc[onsets, \"value\"] = [f\"({v[0]}, {v[1]})\" for v in shifted]         elif et == \"ft_hand\":             shifted = subdf.loc[subdf.start_end.isna(), \"hand\"].values             subdf.loc[onsets, \"value\"] = shifted          # Move back to general dataframe         df[df.trial_type == et] = subdf      # Drop rows from which data was copied to the principal event row.     df = df.drop(df[df.start_end.notna() &amp; df.start_end.str.contains(\"False\")].index)     df = df.drop(df[df.start_end.isna() &amp; df.x.notna()].index)     df = df.drop(df[df.start_end.isna() &amp; df.hand.notna()].index)        # Normalize event names     df = df.replace({\"trial_type\": TRIAL_TYPE})          # Replace mock events in bht     if \"end-message\" in set(df.trial_type.values):         end_index = df[df.trial_type == \"end-message\"].index[0]         df.loc[:end_index] = df.loc[:end_index].replace(             {                 \"trial_type\": {\"in\": \"green\", \"out\": \"yellow\", \"in-last\": \"light-green\", \"out-last\": \"gold\"},             },         )         df.loc[:end_index, \"value\"] = \"mock\"                  # After the mock there are 5 \"true\" blocks.         len_remaining = len(df.loc[end_index + 1:, \"value\"])         df.loc[end_index + 1:, \"value\"] = [f\"block{v}\" for block in range(1, 7) for v in [block] * 13][:len_remaining]              return df[[\"onset\", \"duration\", \"trial_type\", \"value\"]] In\u00a0[125]: Copied! <pre>DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/psychopy\")\nBIDS_PATH = Path(\"/data/datasets/hcph\")\nsession_path = DATA_PATH / \"session-2023-11-03\"\n\n# Create a BIDS dataframe with rows defining a trial_type\noutput_df = psychopy2pandas(session_path / \"bht_2023-11-03_20h27.56.353_0_session_29.log\")\nbids_df = pandas2bids(output_df)\nbids_df[40:]\n</pre> DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/psychopy\") BIDS_PATH = Path(\"/data/datasets/hcph\") session_path = DATA_PATH / \"session-2023-11-03\"  # Create a BIDS dataframe with rows defining a trial_type output_df = psychopy2pandas(session_path / \"bht_2023-11-03_20h27.56.353_0_session_29.log\") bids_df = pandas2bids(output_df) bids_df[40:] Out[125]: onset duration trial_type value 277 158.2357 2.3044 out block3 282 160.5401 2.7026 in block3 286 163.2427 2.3043 out block3 290 165.5470 2.7025 in block3 294 168.2495 2.2880 out block3 298 170.5375 2.7025 in block3 302 173.2400 2.3051 out block3 306 175.5451 2.7018 in-last block3 310 178.2469 2.3047 out-last block3 313 180.5516 13.0149 hold block3 322 193.5333 2.0060 hold-warning block3 326 195.5230 10.0138 refractory block3 340 205.5368 2.7029 in block4 344 208.2397 2.3040 out block4 348 210.5437 2.7026 in block4 352 213.2463 2.3045 out block4 356 215.5508 2.6859 in block4 360 218.2367 2.3049 out block4 364 220.5416 2.7021 in block4 368 223.2437 2.3043 out block4 372 225.5480 2.7027 in-last block4 376 228.2507 2.2878 out-last block4 380 230.5385 13.0150 hold block4 389 243.5204 2.0059 hold-warning block4 393 245.5263 10.0142 refractory block4 406 255.5405 2.7024 in block5 410 258.2429 2.3045 out block5 414 260.5474 2.7025 in block5 418 263.2499 2.2879 out block5 422 265.5378 2.7026 in block5 426 268.2404 2.3042 out block5 431 270.5446 2.7026 in block5 434 273.2472 2.3047 out block5 439 275.5519 2.6859 in-last block5 442 278.2378 2.3048 out-last block5 446 280.5426 13.0144 hold block5 455 293.5244 2.0055 hold-warning block5 459 295.5299 10.0143 refractory block5 In\u00a0[126]: Copied! <pre># Create a BIDS dataframe with rows defining a trial_type\noutput_df = psychopy2pandas(session_path / \"qct_2023-11-03_19h58.22.540_0_session_29.log\")\nbids_df = pandas2bids(output_df)\nbids_df[[\"onset\", \"duration\", \"trial_type\", \"value\"]][40:]\n</pre> # Create a BIDS dataframe with rows defining a trial_type output_df = psychopy2pandas(session_path / \"qct_2023-11-03_19h58.22.540_0_session_29.log\") bids_df = pandas2bids(output_df) bids_df[[\"onset\", \"duration\", \"trial_type\", \"value\"]][40:] Out[126]: onset duration trial_type value 557 83.4206 0.5655 cog (0.5, 0.6) 581 83.9861 5.0088 mot R 592 88.9949 5.0773 mot L 616 94.0722 3.0776 blank nan 630 97.1498 0.5127 cog (-0.7, 0.0) 635 97.6625 0.4973 cog (0.5, 0.6) 640 98.1598 0.5142 cog (0.7, 0.0) 646 98.6740 0.4971 cog (-0.5, -0.6) 651 99.1711 0.4975 cog (0.5, -0.6) 656 99.6686 0.5714 cog (-0.5, 0.6) 682 100.2400 3.0820 blank nan 703 103.3220 3.0840 blank nan 724 106.4060 3.0919 blank nan 746 109.4979 5.0090 mot R 756 114.5069 5.0812 mot L 778 119.5881 4.9995 mot L 789 124.5876 5.0885 mot R 813 129.6761 3.0821 blank nan 825 132.7582 3.0927 vis nan 852 135.8509 0.5075 cog (0.5, -0.6) 859 136.3584 0.5141 cog (0.7, 0.0) 864 136.8725 0.4979 cog (-0.7, 0.0) 870 137.3704 0.4968 cog (0.5, 0.6) 875 137.8672 0.4975 cog (-0.5, -0.6) 880 138.3647 0.5841 cog (-0.5, 0.6) 907 138.9488 3.1678 blank nan 917 142.1166 3.1039 vis nan 944 145.2205 0.5056 cog (0.5, -0.6) 951 145.7261 0.5141 cog (-0.5, 0.6) 956 146.2402 0.4975 cog (0.7, 0.0) 962 146.7377 0.4968 cog (-0.7, 0.0) 967 147.2345 0.4976 cog (0.5, 0.6) 972 147.7321 0.6048 cog (-0.5, -0.6) 988 148.3369 3.1007 vis nan 1010 151.4376 3.1110 vis nan 1033 154.5486 3.1819 vis nan In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"assets/code/events/events-from-psychopy/#generating-bids-events-files-from-psychopys-artifacts","title":"Generating BIDS events files from Psychopy's artifacts\u00b6","text":""},{"location":"assets/code/sessions/schedule/","title":"Schedule","text":"session day PE replaces 1 2023-10-20 LR         2 2023-10-20 LR 3 2023-10-21 LR 4 2023-10-21 RL 5 2023-10-22 PA 6 2023-10-22 PA 7 2023-10-23 LR 8 2023-10-23 RL 9 2023-10-24 AP 10 2023-10-24 RL 11 2023-10-25 AP        12 2023-10-25 PA 13 2023-10-26 PA        14 2023-10-26 LR 15 2023-10-27 AP 16 2023-10-27 RL 17 2023-10-28 PA 18 2023-10-28 LR 19 2023-10-29 PA 20 2023-10-29 RL 21 2023-10-30 RL 22 2023-10-30 AP 23 2023-10-31 AP 24 2023-10-31 AP 25 2023-11-01 RL 26 2023-11-01 PA        27 2023-11-02 AP 28 2023-11-02 RL 29 2023-11-03 PA        30 2023-11-03 AP        31 2023-11-04 PA        32 2023-11-04 AP        33 2023-11-05 LR        34 2023-11-05 LR        35 2023-11-06 LR        36 2023-11-06 RL 37 2023-11-09 LR 2 38 2023-11-09 PA 12 39 2023-11-10 LR 14 40 2023-11-10 AP 27 41 2023-11-11 AP 30 42 2023-11-11 PA 31 43 2023-11-12 AP 32 44 2023-11-12 LR 33 45 2023-11-13 LR 34 46 2023-11-13 LR 35 47 2023-11-14 RL 36"},{"location":"assets/code/signals/","title":"hcphsignals","text":"<p>Table of Contents</p> <ul> <li>Installation</li> <li>License</li> </ul>"},{"location":"assets/code/signals/#installation","title":"Installation","text":"<pre><code>python -m pip install code/signals/\n</code></pre>"},{"location":"assets/code/signals/#license","title":"License","text":"<p><code>hcphsignals</code> is distributed under the terms of the Apache 2.0 license.</p>"},{"location":"data-collection/emergency-procedures/","title":"Emergency procedures","text":"<p>Reminder: Phone number of internal emergency services can be found in the agenda of all the phones of the hospital.</p>"},{"location":"data-collection/emergency-procedures/#fire-in-the-scanning-room","title":"Fire in the scanning room","text":"<ul> <li> Immediately call the internal firefighter service at  ##-###.</li> <li> <p> Enter in the MRI room and cut the electricity in the MRI room by pressing the red button next to the entrance.</p> <p>Cutting electricity will NOT turn off the magnetic field!</p> </li> <li> <p> Remove the subject from the scanner's room, applying the manual extraction procedure described below.</p> </li> <li> Close the scanner's room.</li> <li> <p> Retrieve the MR-compatible extinguisher from its designated corner of the control room (see picture below) and put it in front of the scanning room.</p> <p>Conventional extinguishers MUST NOT be entered in the scanning room because the magnetic field is still active</p> <p></p> </li> </ul>"},{"location":"data-collection/emergency-procedures/#emergency-quench","title":"Emergency quench","text":"<p>The quench button is to be used only in the case of an emergency in which a person is injured and the only safe way to avoid further injury is to decrease the magnetic field strength of the magnet.</p> <ul> <li> Lift the security cover to free the red, mushroom-shaped button with the STOP word written on it, and push it.     </li> </ul> <p>Fire in the scanner's room does not justify quenching unless the high field poses a direct threat to a person's health</p>"},{"location":"data-collection/emergency-procedures/#participant-set-the-alarm","title":"Participant set the alarm","text":"<p>If at any point the participant rings the alarm, you MUST check on the participant IMMEDIATELY with the scanner's speaker system.</p> <ul> <li> <p> Press the speaker button (1 in the picture below) and ask if everything is alright. It is possible that the participant triggered the alarm by mistake.     </p> <p>Pressing the speaker button (1) or the crossed-bell button (4) will turn the alarm off and open the speaker line to talk to the participant.</p> </li> </ul> <ul> <li> Assess the participant and the situation by asking them what is wrong and checking the camera inside the room and the scanner's console.</li> </ul> <p>If you can anticipate that the participant will need to be retrieved</p> <p>Initiate the extraction of the bed from the scanner console using the Room in menu (lower left corner of the screen), and then click on the home () button.</p>"},{"location":"data-collection/emergency-procedures/#alarm-event-requires-further-safety-procedures","title":"Alarm event requires further safety procedures","text":"<ul> <li> <p> Enter the scanning room if you do not get a response or the answer is unclear.</p> <p>If there is an impending risk to the participant's health and it is safe for you and other operators to intervene, take actions to avert the dangerous situation.</p> <p>For example, if the participant is choking because of the accidental occlusion of their respiratory ways after the displacement of some experimental instrument or sensor, immediately extract them from the scanner's bore with the fastest procedure available to you and remove the occluding instruments.</p> <p>Similarly, suppose the participant suffers an acute panic attack and starts violently and uncontrollably shaking on the table. In that case, you will first lift the security side rails of the bed and securely restrain the participant further within the scanning table if necessary. This is critical to preempt their body from falling off the table while the head coil is still attached. Only when you can safely do so, extract them from the bore and remove the head coil.</p> </li> </ul>"},{"location":"data-collection/emergency-procedures/#participant-possibly-needs-to-be-retrieved-but-there-isnt-impending-risk-to-their-health","title":"Participant possibly needs to be retrieved but there isn't impending risk to their health","text":"<ul> <li> <p> If the alarm is still blaring, press the large, circular button at either side of the scanner's bore.     </p> </li> <li> <p> Make the participant aware that you entered the room and ask them what is wrong.</p> <p>If the participant is unresponsive, extract them from the scanner's bore using the standard procedure (the Home button). In case you previously cut the electricity or failure of the standard procedure, follow the manual procedure described in the first steps of manual extraction protocol.</p> </li> <li> <p> Determine whether the participant can continue the session after some comforting or information or if it must be stopped at that point (e.g., the participant is feeling claustrophobic and cannot continue).</p> </li> <li> If the session must be stopped, or you determine it is necessary to extract the participant before making that decision, hit the \"Home\" button to bring the participant outside the scanner's bore quickly.         </li> </ul>"},{"location":"data-collection/emergency-procedures/#in-case-you-feel-unsafe","title":"In case you feel unsafe","text":"<p>If you feel unsafe for any reason (for example, because a patient behaves aggressively or threatens you), CALL SECURITY at  ##-###.</p>"},{"location":"data-collection/emergency-procedures/#technical-difficulties","title":"Technical difficulties","text":"<p>If you are facing technical difficulties:</p> <ul> <li> Seek help from anyone on the BH7 floor.</li> <li> If you still have problems or didn't find anyone (e.g., scanning on a weekend), call the ER's MRI staff at  ##-###.</li> </ul>"},{"location":"data-collection/emergency-procedures/#a-person-requires-medical-attention","title":"A person requires medical attention","text":"<p>At any moment, you may determine that the participant will require medical attention:</p> <ul> <li>The participant's health has been threatened or is actively at risk (e.g., elevated heart frequency, lack of pulse, respiratory issues, unconsciousness, dizzyness, unsteadyness, etc.)</li> <li>The participant is unresponsive</li> <li>The participant reports feeling unwell and needs attention</li> <li>You think they may need medical attention but you are unsure.</li> </ul> <p>If you determine that someone needs medical attention, call the resuscitation unit  ##-###</p> <p>The resuscitation unit  ##-### is the number to call in any case, even if the participant is not in life-threatening condition.</p> <p>The phone number of the emergency services can be found on all the phones at CHUV.</p> <p>After you called the resuscitation unit:</p> <ul> <li> <p> Press on the heart button  \u2014(1) in the picture below\u2014 on the wall, after lifting the security lid.</p> The heart button  (1) initiates a beacon to guide the intensive care team to the place where they need to intervene; (2) cancels the beacon. <p>In case you pressed the heart button by mistake, turn it off by pressing the adjacent green button (2).</p> </li> <li> <p> If the participant remains in the scanning room, re-enter the room and proceed with the manual extraction protocol.</p> </li> </ul> <p>Danger</p> <p>If the resuscitation team needs to shock the participant for cardiac resuscitation, it must never be done on the MR table.</p>"},{"location":"data-collection/emergency-procedures/#manual-extraction-procedure","title":"Manual extraction procedure","text":"<ul> <li> If the bed is inside the bore:<ul> <li> Unlock the manual retrieval of the scanner's bed</li> <li> Pull the bed all the way out of the bore</li> <li> Lock the manual retrieval back</li> </ul> </li> <li> Lift the table's breaks locking the wheels</li> <li> Lift the manual lock of the table's attachment to the bore.</li> <li> Pull the bed out of the scanning room</li> <li> Reassess the participant's health in the control room and determine a course of action.</li> </ul> <p>Resetting the scanner's table after it's been manually detached</p> <ul> <li> Dock the table onto the scanner's bore by insert the arrow-shaped prong into the docking bay.</li> <li> Wait for the MRI screen to indicate it is ready for docking, push down the right attachment pedal with your foot for locking.</li> <li> Simultaneously press the up and down buttons to activate the automatic recalibration of the table.</li> </ul>"},{"location":"data-collection/emergency-procedures/#immediately-report-incidents","title":"Immediately report incidents","text":"<p>MRI coordinators must be informed</p> <p>Once the situation is resolved, and before anything else, send an email to \u2588\u2588\u2588 and \u2588\u2588\u2588. Make sure to report any potential risk you can anticipate to clinical activity the following day.</p>"},{"location":"data-collection/intro/","title":"Overall experimental settings","text":"<p>The goal of the experimental setting is to obtain several functional MRI tasks and a long diffusion MRI scan with synchronized physiological recordings, including gas contents with a gas analyzer (GA), eye tracking (ET; including the right eye position, pupil size, blinks, etc.), respiration tracking through a pneumatic respiration belt (RB), and finally MRI-compatible electrocardiogram (ECG).</p> <p>The overall experimental setting can be summarized as follows:</p> <pre><code>flowchart TB\n\n    subgraph \"Scanning Room\"\n        direction TB\n        sr1[Scanner]\n        sr2[Cannula]\n        sr3[RB]\n        sr4[ECG]\n        sr5[ET]\n    end\n\n    subgraph \"BIOPAC\"\n        direction TB\n        biopac1[DA100C]\n        biopac2[ECG100C MRI]\n        biopac3[AMI100D]\n        biopac4[STP100D]\n    end\n\n    sr1 ---&gt;|Trigger| sb[Syncbox]\n    sr2 ---&gt; ga[Gas Analyzer]\n    sr3 ---&gt;|\"Negative (-)\"| biopac1[DA100C]\n    sr4 ---&gt; biopac2[ECG100C MRI]\n    sr5 ---&gt; et[Eye Tracker PC]\n\n    ga ---&gt;|\"Channel 3 (CO&lt;sub&gt;2&lt;/sub&gt;)\"| biopac3\n    ga ---&gt;|\"Channel 4 (O&lt;sub&gt;2&lt;/sub&gt;)\"| biopac3\n\n    sb ---&gt;|USB| pc1[\"Stimuli presentation Laptop (\u2588\u2588\u2588)\"]\n    pc1 &lt;---&gt;|Ethernet| et\n    pc1 ---&gt;|USB| modem[MMBT-S Interface]\n    pc1 ---&gt;|HDMI| display[Projector]\n    modem ---&gt;|25-pin parallel| biopac4\n\n    BIOPAC ---&gt;|Ethernet| pc2[\"Physio-recording Laptop (\u2588\u2588\u2588)\"]</code></pre> <p>The above graph can be broken down as follows:</p> <ol> <li>Signals generating from the Scanning Room.     In addition to the MR imagery produced by the scanner, the participant will be wearing the RB, the ECG leads, a nasal cannula to retrieve the expired gases, and finally their right eye will be recorded with the infrared camera of the ET.     All those probes and devices carry signals outside the Scanning Room either through cables or tubes, with the access panel as the interface.     The access panel also has a connector carrying the trigger signals generated by MR schemes, which indicate important events in the MRI acquisition (typically, one trigger pulse is generated for each new repetition time \u2014TR\u2014, e.g., with every fMRI volume).</li> <li> <p>Syncbox.     A NordicLabs Syncbox receives TTL (transistor-transistor logic) triggers from the scanner.     This box can just forward the triggers converted into other formats and/or manipulate them (e.g., filter, generate, etc.).</p> The NordicLabs Syncbox </li> <li> <p>Physiology recording hub (BIOPAC).     We use the MP160 (BIOPAC Systems, Inc., Goleta, CA, US) to record most of physiological signals.     The main unit (MP160) has directly attached several additional modules for the reception and recording of several analogical signals from the Scanning Room (for the case of the RB and the ECG), and indirectly from the gas analyzer (see next item).     The physiology recording hub also registers digital signals from the stimuli presentation laptop (\u2588\u2588\u2588) through the digital signal module (described below).</p> </li> <li>Gas analyzer (GA).     We use the ML206 (AD Instruments Pty. Ltd., Sydney, Australia).     The GA is a device that continuously measures the amount of two gases (CO<sub>2</sub> and O<sub>2</sub>) from a sample fed at the front of the device with a connected tube (this tube comes from inside of the Scanning Room and ends in the nasal cannula the participant is wearing, as shown in the graph).</li> <li>Eye tracker (ET).     We use the EyeLink 1000 Plus (SR Research Ltd., Ottawa, Canada).     Our particular variant \u00abLong Range\u00bb is composed of three main elements:     (i) inside the scanner's bore, we place an arm that holds an infrared lens and camera sensor on one side and an infrared lamp that illuminates the right eye of the subject through (ii) a special mirror to reflect the infrared spectrum; and (iii) a PC tower that receives the camera recordings, postprocesses the images and calculates the final parameters of interest (position of the eye, pupil size, etc.).     The ET is also connected to the Psychopy laptop (\u2588\u2588\u2588), and communicates bi-directionally with it (e.g., to record logs or receive \"messages\" such as triggers or task events).     The ET is NOT connected to the BIOPAC, with the implication that the ET data is not stored with the other physiological information.</li> <li>Stimuli presentation laptop.     The Psychopy laptop (\u2588\u2588\u2588) has the Psychopy software install and with it, the task programs are executed.     This experiment consists of three tasks: breath-holding task (BHT), resting-state fMRI (rest), and a quality-control task (QCT).     This laptop also stores the data recorded by the ET at the end of the experiment.</li> <li>Physiology recording laptop.     The AcqKnowledge laptop (\u2588\u2588\u2588) runs the BIOPAC's AcqKnowledge software and with it, this computer records the signals and allows visualization of the data coming from the BIOPAC.     All the inputs to the BIOPAC are multiplexed through into an Ethernet cable that is connected to this laptop.</li> </ol>"},{"location":"data-collection/intro/#getting-familiar-with-the-instruments","title":"Getting familiar with the instruments","text":""},{"location":"data-collection/intro/#gas-analyzer-ml206-documentation-and-basics","title":"Gas analyzer ML206: documentation and basics","text":"<p>The front of the gas analyzer (GA) looks like this:</p> <p></p> <p>It is critical to familiarize with the GA's manual to learn about its correct utilization.</p> <p>Make sure you understand the switching on and off procedures described in these SOPs</p> <p>Finally, make sure to watch the following video:</p>    Your browser does not support the video. Click here to download it"},{"location":"data-collection/intro/#physiological-recording-hub-biopac-documentation-and-devices","title":"Physiological recording hub BIOPAC: documentation and devices","text":"<p>Get familiar with the BIOPAC setup and read through the hardware documentation. The system is composed by the main unit (MP160; extreme left in the picture below), to which modules are attached depending on what signals are to be recorded.</p> <p></p> <p>Additional modules in our settings are (from left to right in the above picture):</p> <ul> <li>The SPT100D (solid state relay driver unit) is used to input digital signals that must be recorded.</li> <li>The AMI100C unit can receive up to 16 analog signals.</li> <li>The DA100C unit records the signal coming from the respiration belt.     This unit requires the pressure transducer and amplifier TSD160A unit to be connected at its front.     The belt has a pneumatic sensor TSD221-MRI (see product sheet), that is connected to the pressure transducer TSD160A via the longer tube (AFT30-XL 10 m).</li> <li>The ECG100C unit records the electrical signal coming from the heart via three ECG leads.     This unit requires the amplifier MECMRI-2 unit to be connected at its front.</li> </ul> <p>In addition to the main unit, we have a data modem to feed digital signals into the SPT100D. This modem is the MMBT-S Trigger Interface Box adapter (N-shaped, pink box):</p> <p></p>"},{"location":"data-collection/intro/#eye-tracker-eyelink-1000-plus-documentation-and-basics","title":"Eye tracker EyeLink 1000 Plus: documentation and basics","text":"<p>Get familiar with the setup and read through the ET Instruction Manual.</p> Thanks to Benedetta Franceschiello! <p>All the documentation about the ET is derived from Benedetta Franceschiello's user guide.   We greatly appreciate her help with the device.</p> The ET is an EyeLink 1000 Plus (Long Range). The ET is composed of three major elements: the ET arm (left), which holds the lens and camera and an infrared lamp, the Host Computer (middle), and the infrared mirror (right) <ul> <li>The ET arm is an articulated support for the infrared camera and lens in one end and with an infrared lamp at the other end.     The ET arm is installed inside the Scanning Room, inside the scanner's bore, standing on a transparent plexiglass panel tailored to the scanner's bed rail.     Two lengthy cables (black for power and orange for signal) are passed through the access panel and connect the ET arm to the ET computer.</li> <li>The ET computer is a standard PC with customized software for the control of the ET.</li> <li>The infrared mirror is critical to be able to record the right eye of the participant, and is mounted covering the standard mirror of the coil.</li> </ul>"},{"location":"data-collection/intro/#scanning-protocols","title":"Scanning protocols","text":"<p>The study will collect data with two different scanning protocols. Most of what is described in the present SOPs addresses the Reliability Imaging Protocol that will be acquired on the \u2588\u2588\u2588 scanner.</p> <p>Reliability imaging protocol printouts</p> <p>The final printouts are here: HCPh_AP, HCPh_PA, HCPh_LR, and HCPh_RL.</p> Reliability Imaging Protocol (36 sessions \\(\\times\\) one scanner) mm:ss Standard Imaging Protocol (12 sessions \\(\\times\\) three scanners) mm:ss Head scout 00:14 Head scout 00:14 FoV Manual positioning 01:00 FoV Manual positioning 01:00 T1w (anatomical reference) 5:41 T1w (anatomical reference) 5:41 DWI (\\(B_\\text{0}\\) field mapping) 00:54 EPI BOLD (\\(B_\\text{0}\\) field mapping) 00:30 DWI (dMRI, structural connectivity) 33:52 BOLD (single-echo RSfMRI, eyes open) 20:09 GRE (\\(B_\\text{0}\\) field mapping) 02:38 GRE (\\(B_\\text{0}\\) field mapping) 03:08 BOLD (positive-control task fMRI) 03:07 BOLD (multi-echo RSfMRI, eyes open, only \u2588\u2588\u2588) 10:09 EPI BOLD (\\(B_\\text{0}\\) field mapping) 00:27 DWI (dMRI, structural connectivity) 27:31 BOLD (multi-echo RSfMRI, naturalistic movie) 20:09 DWI (\\(B_\\text{0}\\) field mapping) 01:10 BOLD (breath-holding task fMRI) 06:00 T2w (anatomical reference) 08:24 T2w (anatomical reference) 05:10 Total Acquisition Time 79:12 Total Acquisition Time 77:56 <p>Stimulation program timings (reliability imaging protocol only)</p> <p> The stimuli presentation laptop (\u2588\u2588\u2588) will execute four experiments, which will allow the synchronization of all devices by sending the adequate signals at their predesignated times and also present visual stimuli with the scanner's projector. The lengths of the four Psychopy experiments should be:</p> <ul> <li><code>task-fixation_dwi</code> \u279c 33min 11s,</li> <li><code>task-qct_bold</code> \u279c 2min 38s,</li> <li><code>task-rest_bold</code> \u279c 20min 6s, and</li> <li><code>task-bht_bold</code> \u279c 5min 41s.</li> </ul>"},{"location":"data-collection/legacy-et/","title":"Legacy procedure for the ET mirror","text":"<p>Placing the infrared mirror</p> <ul> <li> Detach the standard mirror's frame from the head coil, if it is placed there.     Remove unnecessary items from the scanning bed, and prepare the mirror to attach the infrared mirror of the ET at a later step.</li> <li> Prepare two long strips of tape and leave them in a convenient place to attach the ET mirror later.     E.g., attach the corner of each strip to the back part of the mirror frame.</li> <li> <p> Go back to the control room and take the infrared mirror out of the \u00abfMRI usage\u00bb box. DO NOT EXTRACT THE MIRROR OUT FROM ITS BOX YET. The mirror's box is labeled as RELIQUIA DI SAN GENNARO to emphasize that THIS IS THE MOST DELICATE PART, BECAUSE THE MIRROR CANNOT BE REPLACED NOR CLEANED. This mirror is EXTREMELY EXPENSIVE.</p> <p></p> </li> <li> <p> Get two gloves (e.g., from the box hanging at the entrance of the scanner room), then approach the scanner bed. Put the gloves on, and DON'T TOUCH ANYTHING. You MUST have the standard mirror dismounted and in front of you at this point. WITH THE GLOVES proceed to extract the infra-red mirror from its box, being extremely careful. YOU CAN ONLY TOUCH THE MIRROR WITH GLOVES, because it cannot be cleaned up. Watch out for FINGERPRINTS and once taken out of its box, IMMEDIATELY PROCEED TO ATTACH IT to the standard coil mirror. The mirror MUST NOT be placed anywhere else if not in its box.</p> </li> <li> <p> WITH YOUR GLOVES ON, attach the ET mirror to the standard coil mirror (the larger mirror that points toward projector's screen at the back of the scanning room) using the scotch tape strips you prepared before. Put it more or less in the center, although this position may need to be adjusted (being careful and with the same precautions explained before). Do not touch the surface of the ET mirror.</p> <p></p> <p>The infrared mirror MUST be airtight attached</p> <p>It is critical that there is no air gap between the infrared mirror and the standard mirror. Also, make sure the scotch tape is firmly glued to the standard mirror because the infrared mirror will be hanging when placed on the coil and may loosen up creating a gap with the standard mirror.</p> <p>Suggestion</p> <p>Since we are going to track the right eye only, it is useful to displace the infrared mirror to the right from the participant's standpoint and cut the scotch tape narrower to occlude less surface of the mirrors on the right side.</p> </li> <li> <p> Place the mirror frame back on the head coil. As always, DO NOT TOUCH THE MIRROR.</p> </li> </ul>"},{"location":"data-collection/notes-et/","title":"ET extended guidelines","text":"<p>Please note that some of the images used in this section are sourced from the ET manual.</p>"},{"location":"data-collection/notes-et/#setting-viewframe-and-focusing","title":"Setting viewframe and focusing","text":"<p>To ensure accurate performance and prevent minor drifts in the pupil and corneal reflection (CR) thresholds, perform the ET Setup 10-15 minutes after powering the ET on.</p> <ul> <li> <p> Initiate the fixation program on the stimuli laptop (\u2588\u2588\u2588), by typing the following on a terminal:</p> Make sure to have the correct environment loaded before invoking the task <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <pre><code>cd ~/workspace/HCPh-fMRI-tasks\npython task-fixation_dwi.py\n</code></pre> <p>A modal dialog will ask you for the number of trial (automatically calculated, DO NOT modify) and the session number.</p> <p>The following two steps MUST be executed in this order</p> <pre><code>- [ ] Drag and drop the modal dialog into the scanner's projector screen.\n- [ ] Update the session number with the corresponding number.\n</code></pre> </li> <li> <p> Press Enter to begin the Camera Setup Mode.</p> <p>The Camera Setup Mode contains a view of one eye, and you can switch that view between two modes</p> <ul> <li>The Head Camera will allow you to \"find\" and aim the right eye, as it has a wider field-of-view.</li> <li>The Right Eye Camera is a zoomed clip of the eye, if it is properly identified by the software (i.e., the eye is fully within the field-of-view of the camera).</li> </ul> </li> <li> <p> Switch to the Head Camera mode by pressing the  or  arrow.     This will allow you to adjust the ET position as the infrared camera provides feedback inside the scanning room on the projection screen.</p> </li> <li> Enter the scanning room.</li> <li> Ask the participant to slide the mirror with their hands until the infrared mirror fully covers the image on the screen.</li> <li> <p> Action the ET arm position looking at the Head Camera view that should be now projecting on the screen to ensure the right eye is in the center of the field-of-view.</p> <p>The right eye should be visible at the center of the coil's square window for the eye.</p> <p></p> <ul> <li> To adjust the camera position, slightly unscrew the fixation locks of the camera arm, move the arm in search of the correct position, and tighten the locks again on the desired position.</li> <li> If the eye coverage is still inappropriate, realign the mirror frame position by sliding it along the rails attached to the coil.     You may ask the participant to do it while inside the bore.</li> <li> If the eye coverage is still inappropriate, re-adjust the participant's head positioning inside the coil.     You'll need to extract the bed outside of the bore for this by pressing the Home () button.</li> <li> If the eye coverage is still inappropriate, revise the vertical position of the infrared mirror with respect to the standard mirror (this will require new gloves and replacing the tape to stick the infrared mirror).     Even a tiny adjustment can impact calibration and eye positioning.</li> <li> Repeat the previous steps until the eye is properly aimed and focused.</li> <li> As a last resort, you can also adjust the strength of the infrared light (emitter).     This is the black box on the opposite side of the lens on the ET arm.     Under the emitter there are two little screws.     Unscrew, move the emitter front/back, check the contrast of the face image, re-screw.</li> </ul> </li> <li> <p> Tighten the nut that locks the arm's position.</p> </li> <li> Focus the lens so that the image is sharp (e.g., the eyebrows and eyelashes are well defined).     </li> <li> Switch the ET to Right Eye Camera mode (zoomed in).</li> <li> Verify that the eye is still well covered by the view and the pupil is segmented.</li> <li> Press the A key to set the pupil and CR detection thresholds automatically.</li> <li> Check that two crosses appear on the eye.</li> <li> Fine-tune the pupil detection threshold using the  and  arrow keys if necessary.     While checking the pupil/CR image and thresholding, ask the participant to look at the screen corners to verify correct detection even in extreme positions.     </li> </ul> <p>At this point, the pupil should correctly be seen and segmented, and the crosses on the ET computer should appear in the right eye.</p> <ul> <li> Inform the participant that you are leaving the room.</li> <li> Exit the camera mode by pressing Enter.</li> </ul>"},{"location":"data-collection/notes-et/#calibration","title":"Calibration","text":"<ul> <li> <p> On the eye-tracking (ET) computer, ensure that the appropriate calibration type is selected (9-point for QCT and 5-point for resting state and breath-holding tasks):</p> <ul> <li> Click on Set Options located on the right side of ET computer screen.</li> <li> <p> Under Calibration type in the top left corner, choose the image containing either 9 or 5 points.</p> <p></p> </li> </ul> </li> <li> <p> Two crosses should appear on the ET computer screen: one at the center of the pupil and the other at the center of the corneal reflection.</p> <p>If the two crosses do not appear, the coverage, focus and intensity of the ET are incorrect</p> <ul> <li> Repeat the steps for their setting up given above.</li> </ul> </li> <li> <p> Initiate the ET calibration by pressing C on the laptop keyboard or by clicking on Calibration on the ET interface.</p> </li> <li> <p> Once the participant's gaze stabilizes on the first fixation point, the Accept Fixation button turns green.     Click on it to confirm the initial position.</p> <p></p> </li> <li> <p> Subsequent positions should be automatically validated when the gaze remains stable.     If not, manually click the Accept Fixation button when it turns green.</p> </li> <li> After the calibration, ensure that the fixation points' positions match the expected pattern corresponding to the 9- or 5-point calibration.     If the pattern appears too distorted, restart the calibration.</li> <li> Upon successful calibration, initiate validation by clicking Validation on the ET interface or pressing the V key on the laptop keyboard. Follow the same instructions as in the calibration to validate positions.</li> <li> If validation fails, repeat previous steps and restart calibration. Otherwise, you can leave the calibration mode and proceed with the task program by pressing the Esc key on the laptop (\u2588\u2588\u2588).</li> </ul>"},{"location":"data-collection/notes-et/#drift-check","title":"Drift check","text":"<ul> <li> On the eye-tracking (ET) Setup's menu, locate and select Drift Check.</li> <li> Instruct the participant to focus their gaze on the fixation point displayed on the screen.</li> <li> Press on Accept when the gaze is stable.</li> <li> If the drift is significant and the eye-tracking system suggests recalibration, proceed with the recalibration process.</li> </ul>"},{"location":"data-collection/notes-misc/","title":"Additional miscellaneous protocols","text":""},{"location":"data-collection/notes-misc/#measuring-blood-pressure","title":"Measuring blood pressure","text":"<ul> <li> Turn the blood pressure machine on.     </li> <li> Carefully place the arm band on the patient's right arm.</li> <li> Make sure the tubes are placed correctly (see below).     </li> <li> <p> Check that the adult preset is loaded (if not, load it).</p> Load a new preset <ul> <li> Press CONFIG MONITEUR to open the options.</li> <li> Scroll using the wheel and select by pressing it.</li> <li> Enter to PATIENT, and select ADULTE.</li> <li> Exit by pressing the wheel on RETOUR.</li> </ul> <p></p> <ul> <li> Measure the blood pressure by pressing the DEBUT ARRET button. </li> </ul> </li> </ul>"},{"location":"data-collection/notes-misc/#ecg-electrodes-placement","title":"ECG electrodes placement","text":"<p>Ask the participant if they have atopic skin or other skin problems</p> <p>If the participant reports having skin issues, be careful with the following process and do not unnecessarily irritate their skin (e.g., skip the alcohol cleaning and perhaps the abrasion with the preparation gel)</p> <ul> <li> Open the sterile cotton gauze pads package, take one and soak it with alcohol.</li> <li> Clean the skin around the three areas with the alcohol-soaked pad with circular movements.</li> <li> Get a second cotton gauze pad and put some Nuprep preparation gel and gently abrade the skin by rubbing it onto the skin with four or five circular movements.</li> <li> Remove gel excess with a clean cotton gauze.</li> <li> Remove the protective film from the electrode.</li> <li> Stick the electrode on the participant's skin by starting in one side and ironing the rest of the electrode.     This procedure ensures that no air is trapped between the electrode and your skin and that no wrinkles from at the edges. Repeat for the three electrodes.     </li> </ul>"},{"location":"data-collection/notes-scanning/","title":"Notes on the scanner's console","text":""},{"location":"data-collection/notes-scanning/#protocol-setup-and-management","title":"Protocol setup and management","text":""},{"location":"data-collection/notes-scanning/#preparing-the-protocol","title":"Preparing the protocol","text":"<ul> <li> Close open patients discarding changes.     </li> <li> Search for the participant by clicking on the \"Patient Browser\" in the top left corner.       If the participant is not shown (because it is archived and hence not locally found):<ul> <li> Click on the DICOM Q/R button on the top-right area.       </li> <li> Introduce some unambiguous search criteria:       </li> <li> Select the subject (left column) or the sequence (right column) you want to retrieve and hit Retrieve. Be careful, you probably want to retrieve a subject, that means make sure you have selected a row on the left column:       </li> <li> Go back to the \"Patient Browser\" and check that the patient now shows up in the local search.</li> </ul> </li> <li> Check the head coil is not plugged before initiating a \"New examination\" to ensure good SNR of the localizer sequence.</li> <li> Right click and select \"New examination\".     </li> <li> Fill in the requested information (e.g., height and weight).</li> <li> Introduce the Operator name(s) on the middle column of options, e.g., \"ES/AC\".</li> <li> In the Program Selection tab:     <ul> <li> Enter the weight and height of the participant.</li> <li> Select the right protocol under RESEARCH \u2937 Oscar.</li> <li> Select Brain as the organ.</li> <li> Select the Position as \"Head First Supine\".</li> <li> Before you hit Exam, you can edit general patient's data by changing to the Patient Registration tab if you need to edit general information about the patient.</li> <li> Click the Exam button (red background, rightmost-bottom).</li> </ul> </li> </ul>"},{"location":"data-collection/notes-scanning/#editing-a-sequence","title":"Editing a sequence","text":"<ul> <li> Double click on the sequence name.</li> <li> <p> After editing the sequence, you MUST store the changes if you want them to be kept by clicking on the Go button:</p> <p></p> </li> </ul>"},{"location":"data-collection/notes-scanning/#setting-sequences-for-automatic-start","title":"Setting sequences for automatic start","text":"<ul> <li> <p> You can set the worker icon on the left of the sequence by clicking on it if you want to pause before starting that sequence. If the worker is not present, the sequence will launch automatically.</p> <p></p> </li> <li> <p> Blocks with a name between double underscores <code>__*__</code> introduce an Exam Paused break.     Such breaks prompt a modal dialog with the Exam Paused title like this:</p> <p></p> <p>The Patient has Contrast Agent checkbox MUST always be unchecked, as this protocol does not involve a contrast agent\"</p> </li> <li> <p> Click Continue when you are ready to proceed.</p> </li> </ul>"},{"location":"data-collection/notes-scanning/#setting-the-fov","title":"Setting the FoV","text":"<p>Using the anatomical image to adjust the field-of-view (FoV) is RECOMMENDED</p> <ul> <li> Drag and drop the protocol's stack icon (\ud83d\uddc7) corresponding to the <code>anat-T1w__mprage</code> sequence into the image viewer.     The icon will appear AFTER the image has been acquired.</li> </ul> <ul> <li> Make sure that the FOV (yellow square) includes the whole brain by tilting or translating the FOV. If the full brain, including the cerebellum, do not fit in the FOV, favorise making sure that the cortex is fully enclosed in the yellow square. For reproducibility, it is better if the FOV across sequences have a similar center and a similar tilt. However, if it is not possible, the priority remains to include the whole brain in the FOV.</li> <li> If two sequences have the same resolution and the same number of slices, you can copy paste the FOV<ul> <li> Open the sequence for which you want to adjust the FOV/geometry</li> <li> Right click on the sequence for which the FOV has already been carefully positioned</li> <li> Select <code>Copy Parameters</code></li> <li> <code>Center of slice groups and saturation regions</code></li> </ul> </li> <li> <p> Once the FOV is well placed, store the new settings of the sequence by pressing Go.</p> <p></p> </li> </ul>"},{"location":"data-collection/notes-scanning/#repeat-scan","title":"Repeat scan","text":"<ul> <li> <p> If you have to interrupt a sequence because a problem occurred (e.g., the participant fell asleep, the stimuli were not adequately started, etc.), or you have to repeat a sequence because the image was of low quality, right click on the sequence that needs to be restarted and click on Repeat to restart the scan without changing anything in its name!</p> <p></p> </li> </ul>"},{"location":"data-collection/notes-scanning/#managing-protocols","title":"Managing protocols","text":"<ul> <li> (Optional) Load an existing protocol</li> <li> <p> Edit the protocol as needed</p> <p>Follow Reproin conventions</p> <p>When assigning names to the MR sequences in the protocol, make sure to follow the Reproin conventions to maximally facilitate the conversion into BIDS.</p> </li> <li> <p> Update the Number of measurements in all <code>func-bold_task-*</code> sequences, according to the previously recorded timings:</p> \\[ N_\\text{measurements} = L_t / \\text{TR}, \\quad t \\in \\{\\text{bht}, \\text{qct}, \\text{rest}\\}, \\] <p>where \\(L_t\\) is the length of a particular task \\(t\\) (either BHT, QCT, or resting state) in seconds as timed before, and \\(\\text{TR}\\) is the repetition time of the BOLD sequence, in seconds.</p> </li> <li> <p> Save the protocol</p> <p>Logging in as an advanced user is required before saving the protocol</p> <p>As a good practice, always work as the standard user <code>janedoe</code>. However, you MUST change into advanced user mode before saving the protocol.</p> <p>Simultaneously press the Tab + Delete +  on the control-computer's keyboard:</p> <p>Username: <code>superjanedoe</code></p> <p>Password: <code>******</code></p> <p>After three wrong password entries, access will be denied, and only a Siemens engineer will be able to unlock the MR scanner.</p> <ul> <li> Open the Dot-Cockpit window     </li> <li> In <code>Browse</code>, find the right folder to save the protocol in (RESEARCH \u2937 Oscar).</li> <li> Right click on the folder and select New \u2937 Program. This opens an empty page in the program editor      </li> <li> Select all the sequences you want to run from the sequence list and click right to copy.     </li> <li> Drag or paste the copied sequences in the program editor.     </li> <li> Once finished, click on the floppy disk icon () in the upper left to save.</li> <li> Give the protocol a relevant name starting with the date of acquisition in the format YYYYMMDD and click Save.     </li> <li> If desired, the protocol details can also be downloaded as a pdf on a peripherical USB key.<ul> <li> Right-click on the protocol and select Print</li> <li> Save the PDF in your USB key.</li> </ul> </li> <li> Make sure you save a different protocol for each of the four PE directions (i.e., AP, PA, LR, RL).</li> </ul> </li> </ul>"},{"location":"data-collection/notes-scanning/#scanner-boot-up-protocol","title":"Scanner boot-up protocol","text":"<p>Please wait for all systems to finalize their boot-up (about 10 minutes), even if only the satellite station (\u2588\u2588\u2588\u2588\u2588\u2588) is to be used.</p> <p></p> <ul> <li> Turn the key of the System ON/OFF Station Box into the open lock position ()</li> <li> Push the blue button with the sun symbol  and the SYSTEM ON label above, which is found right above the key</li> </ul>"},{"location":"data-collection/notes-scanning/#scanner-shutdown-protocol","title":"Scanner shutdown protocol","text":"<p>Do not switch the scanner off if some data are yet to be archived</p> <p></p> <ul> <li> Turn off the satellite station (\u2588\u2588\u2588, the computer on the left side of the control desk)</li> <li> Turn off the control station (\u2588\u2588\u2588, the computer on the right side of the control desk)</li> <li> Wait for both computers to shut down.</li> <li> Push the blue button displaying an overdotted circle and the SYSTEM OFF label above, which is found right above the key</li> <li> Turn the key into the closed lock position ()</li> </ul>"},{"location":"data-collection/notes-scanning/#scanner-interface","title":"Scanner interface","text":"<p>The picture below shows you the scanner interface as you will see it when you operate the MR machine. The arrow points to the screen and the red circles indicate the control buttons. </p>"},{"location":"data-collection/notes-scanning/#scanners-settings-buttons","title":"Scanner's settings buttons","text":"<p>Adjust settings by pressing the respective button and then turning the central knob (1) to adjust the setting to the desired level:</p> <p></p> <ul> <li> Use the headphones  button (2) to adjust the volume of the earphones.</li> <li> Use the speaker  button (3) to adjust the volume of the air speaker in the scanning room.</li> <li> Use the light  button (4) to adjust the intensity of the illumination inside the scanning room.</li> <li> Use the fan  button (5) to adjust the ventilation in the scanning room.</li> </ul> <p>The central knob (button 1) will turn off the alarm if pushed when the alarm is on</p>"},{"location":"data-collection/notes-scanning/#communication-with-the-participant","title":"Communication with the participant","text":"<ul> <li> <p>      Make sure the speaker is audible (and not annoying) and confirm the participant's feedback.     First, keep the speak mode button (1) pressed while you talk to the participant:</p> <p>Hey [NAME], can you hear me well? Is the audio too loud or too low?</p> </li> <li> <p> Enable the feedback channel from the Scanning Room by pressing the listen mode button (2) once.     Release the speak mode button (1) before you are ready to listen to participant responses.</p> </li> <li> Set the volume control of your microphone and the participant's speaker by pressing the corresponding  buttons.</li> <li> If this volume increase is not enough for the participant to hear you well, proceed as follow:<ul> <li> In the Siemens program, click on Configuration represented by a gear wheel () at the top right of the screen.</li> <li> Click on Configuration panel</li> <li> Under the section Scan application, locate the icon of the speaker and tune the volume to the maximum.</li> <li> Click Apply</li> </ul> </li> </ul> <p>Emergency buttons</p> <p>The STOP button (3) immediately stops the currently running sequence and will require you to go inside the scanner room and simultaneously press the <code>bed up</code> and <code>bed down</code> buttons to keep going. The crossed-out bell  button (4) stops the alarm if the participant actioned it.</p>"},{"location":"data-collection/notes-scanning/#participant-insertion","title":"Participant insertion","text":"<ul> <li>      Move the scanner bed up until it is aligned with the bore's rails.</li> <li> Move the bed forward slowly with the manual regulation knob.     Stop when the head is under the head-localizer.</li> <li> Ask the participant to close their eyes</li> <li>      Press the laser alignment button and align the head-coil markers with the red light.</li> <li> Switch off the alignment light.</li> <li> Inform the participant that they can open their eyes now.</li> <li>      Move the bed inside the scanner with either of these two options:<ul> <li> manually with the designated knob until the mm counter marks \"Isometric\", or</li> <li> press the knob for two seconds, which will place the participant into the isocenter automatically.</li> </ul> </li> </ul>"},{"location":"data-collection/notes-scanning/#standard-extraction-of-the-participant","title":"Standard extraction of the participant","text":"<p>There are two options to extract the participant, when the session has concluded or within the session if the participant needs to be extracted and there is no emergency (e.g., in case of technical error the scanner does not permit continuing the session and it needs to be aborted).</p> The participant can be extracted by pressing the extraction button (bottom arrow in the leftmost picture) and then genly rolling the central knob. Alternatively, you can just press the Home  button (rightmost picture). Thanks to Stephanie Bogaert, MSc, Pieter Vandemaele, MSc and Pim Pullens, PhD <p>Some of the pictures in this section have been extracted from the Ghent Institute for functional and Metabolic Imaging MRI User 2019 written by Stephanie Bogaert, MSc, Pieter Vandemaele, MSc and Pim Pullens, PhD. We express our gratitude that they put together such a comprehensive guide.</p>"},{"location":"data-collection/notes-software/","title":"Notes on software installation and tips","text":""},{"location":"data-collection/notes-software/#preparing-ubuntu-for-psychopy","title":"Preparing Ubuntu for Psychopy","text":"Psychopy is preferably installed in a pure Python environment <p>If an anaconda environment is activated, run the following command to deactivate it: <pre><code>conda deactivate\n</code></pre></p> <ul> <li> <p> Ensure your Ubuntu system has all necessary dependencies:     <pre><code>sudo apt install python3-dev \\\n                 libgtk-4-dev \\\n                 libgstreamer1.0-dev \\\n                 libgstreamer-plugins-base1.0-dev \\\n                 freeglut3-dev \\\n                 libwebkitgtk-6.0-dev \\\n                 libjpeg8-dev \\\n                 libpng-dev \\\n                 libtiff-dev \\\n                 libsdl1.2-dev \\\n                 libnotify-dev \\\n                 libsm-dev\n</code></pre></p> Multiple screens <p>If you want to use multiple screens, install the corresponding libxcb extension:</p> <pre><code>sudo apt-get install libxcb-xinerama0\n</code></pre> </li> <li> <p> Create a Python virtual environment:     <pre><code>python3 -m venv $HOME/psychopyenv\n</code></pre></p> </li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> <li> Update Pypi and setuptools to the latest version:     <pre><code>python -m pip install -U pip setuptools six wheel\n</code></pre></li> <li> Update Numpy to the latest version:     <pre><code>python -m pip install -U numpy\n</code></pre></li> <li> Download the wxPython sources:     <pre><code>python -m pip download wxPython\n</code></pre></li> <li> Build wxPython (version of package may change on your settings, edit accordingly):     <pre><code>python -m pip wheel -v wxPython-4.2.1.tar.gz  2&gt;&amp;1 | tee build.log\n</code></pre></li> <li> Install the wheel you just created:     <pre><code>python -m pip install wxPython-4.2.1-&lt;python-version&gt;-linux_x86_64.whl\n</code></pre></li> <li> Test the installation (an empty window should we created without errors):     <pre><code>python -c \"import wx; a=wx.App(); wx.Frame(None,title='hello world').Show(); a.MainLoop();\"\n</code></pre></li> <li> Install our HCPh-signals package (assumes these SOPs are checked out at <code>&lt;path&gt;</code>:     <pre><code>cd &lt;path&gt;/code/signals\npython -m pip install .\n</code></pre></li> </ul>"},{"location":"data-collection/notes-software/#psychopy-installation","title":"Psychopy installation","text":"<p>This block describes how to prepare an environment with a running Psychopy 3 installation.</p> Make sure to load the correct environment <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <ul> <li> Clone the Psychopy repository:     <pre><code>git clone https://github.com/psychopy/psychopy.git\n</code></pre></li> <li> Navigate to the Psychopy directory and check-out tag <code>2023.2.3</code>:     <pre><code>cd psychopy\ngit checkout 2023.2.3\n</code></pre></li> <li> Install Psychopy using the following command:     <pre><code>python -m pip install .[suggested]\n</code></pre></li> <li> <p> Install the EyeLink plugin for Psychopy:     <pre><code>python -m pip install git+https://github.com/oesteban/psychopy-eyetracker-eyelink.git\n</code></pre></p> On MacOSX or if you don't have access to pip directly, Psychopy's package manager <p>Open Psychopy as mentioned immediately below. Click Tools \u2937 Plugin/Packages manager..., then go to the Packages tab and hit the Open PIP terminal button (bottom left area). There, you can type: <pre><code>pip install git+https://github.com/oesteban/psychopy-eyetracker-eyelink.git\n</code></pre></p> </li> <li> <p> Install the Pylink module made by SR Research, it is distributed with the installation of the <code>eyelink-display-software</code> done previously:</p> <pre><code>python -m pip install /usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp310-cp310-linux_x86_64.whl\n</code></pre> Find the appropriate version for your Python distribution <p>The example above is for cPython 3.10, alternative installations are:</p> <pre><code>/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp27-cp27mu-linux_x86_64.whl\n/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp310-cp310-linux_x86_64.whl\n/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp311-cp311-linux_x86_64.whl\n/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp36-cp36m-linux_x86_64.whl\n/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp37-cp37m-linux_x86_64.whl\n/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp38-cp38-linux_x86_64.whl\n/usr/share/EyeLink/SampleExperiments/Python/wheels/sr_research_pylink-2.1.762.0-cp39-cp39-linux_x86_64.whl\n</code></pre> </li> <li> <p> Try opening Psychopy by typing:     <pre><code>psychopy --no-splash -b\n</code></pre></p> Check that the EyeLink eye tracker is available in the dropdown under the experiment's options <p>If the EyeLink is not available, most likely the appropriate Pylink is missing. See the last checkbox in the installation of the eye tracker to install it. Otherwise, make sure you installed the EyeLink plugin above.</p> The first time it runs, Psychopy will likely request some increased permissions <ul> <li> Add a new <code>psychopy</code> group to your system.     <pre><code>sudo groupadd --force psychopy\n</code></pre></li> <li> Add your current user to the new group:     <pre><code>sudo usermod -a -G psychopy $USER\n</code></pre></li> <li> Raise security thresholds for Psychopy, by inserting the following into <code>/etc/security/limits.d/99-psychopylimits.conf</code>:     <pre><code>@psychopy - nice -20\n@psychopy - rtprio 50\n@psychopy - memlock unlimited\n</code></pre></li> </ul> </li> </ul> Psychopy crashes when trying to run a experiment: <code>pyglet.gl.ContextException: Could not create GL context</code> <p>This is likely related to your computer having a GPU and a nonfunctional configuration:</p> <pre><code>$ glxinfo | grep PyOpenGL\nX Error of failed request:  BadValue (integer parameter out of range for operation)\n  Major opcode of failed request:  151 (GLX)\n  Minor opcode of failed request:  24 (X_GLXCreateNewContext)\n  Value in failed request:  0x0\n  Serial number of failed request:  110\n  Current serial number in output stream:  111\n</code></pre> <p>A quick attempt to solve this would be adding our user to the <code>video</code> group.</p> <p>However, that is unlikely to work out so you'll need to take more actions (see this, and this)</p> Psychopy crashes when trying to run a experiment: <code>qt.qpa.plugin: Could not load the Qt platform plugin 'xcb'</code> <p>If you installed <code>libxcb-xinerama0</code>, or you don't have multiple screens, first try:</p> <pre><code>python -m pip uninstall opencv-python\npython -m pip install opencv-python-headless\n</code></pre> <p>If that doesn't work, try a brute force solution by installing libxcb fully:</p> <pre><code>sudo apt-get install libxcb-*\n</code></pre> Psychopy does not recognize the SR Research eye tracker <p>If the eye tracker does not appear in the corresponding dropdown menu or your experiments fail as described in this issue, you almost certainly need to check the plugin is installed and available within Psychopy's environment.</p>"},{"location":"data-collection/notes-software/#setting-up-the-synchronization-service-as-a-daemon-in-the-background","title":"Setting up the synchronization service as a daemon in the background","text":"<p>It's fundamental to have a reliable means of communication with the BIOPAC digital inputs</p> <p>The following guidelines set up a little service on a linux box that keeps listening for key presses (mainly, the s trigger from the trigger box), and RPC (remote procedure calls) from typically Psychopy or similar software.</p> <p>The service is spun up automatically when you connect the MMBT-S modem interface that communicates with the BIOPAC (that is, the N-shaped pink box)</p> <ul> <li> To automatically start the program when the BIOPAC is connected, create a udev rule as follows:     <pre><code>sudo nano /etc/udev/rules.d/99-forward-trigger.rules\n</code></pre></li> <li> Add the following rule to the file:     <pre><code>ACTION==\"add\", KERNEL==\"ttyACM0\", SUBSYSTEM==\"tty\", TAG+=\"systemd\", ENV{SYSTEMD_WANTS}=\"forward-trigger.service\"\n</code></pre></li> <li> Save the file and exit the editor.</li> <li> Run the following command to reload the udev rules:     <pre><code>sudo udevadm control --reload-rules\n</code></pre></li> <li> Create a systemd service unit file:     <pre><code>sudo nano /etc/systemd/system/forward-trigger.service\n</code></pre></li> <li> Add the following content to the file (Adapt the path to forward-trigger.py to the location on your computer):     <pre><code>[Unit]\nDescription=Forward Trigger Service\nAfter=network.target\n\n[Service]\nExecStart=/usr/bin/python3 /path/to/forward-trigger.py\nWorkingDirectory=/path/to/forward-trigger/directory\nStandardOutput=null\n\n[Install]\nWantedBy=multi-user.target\n</code></pre></li> <li> Save the file and exit the text editor.</li> <li> Run the following command to enable the service to start at boot:     <pre><code>sudo systemctl enable forward-trigger\n</code></pre></li> <li> Run the following command to reload the systemd daemon:     <pre><code>sudo systemctl daemon-reload\n</code></pre></li> </ul>"},{"location":"data-collection/participant-prep/","title":"Preparing the participant","text":"<p>Procedures for when the participant has arrived</p> <p>It is critical to stay alert and anticipate any potential risk to the participant to avert them. This is particularly important for the first session.</p>"},{"location":"data-collection/participant-prep/#participant-reception","title":"Participant reception","text":"<ul> <li> Meet the participant at an easily locatable place (e.g., the reception desk of the Radiology Unit) and show them the way into the control room. Allow sufficient time before the experiment for the preparation (min. 30 minutes).</li> <li> Show the participant the scanning room and explain to them how the device is controlled from outside.</li> <li> <p> Ask the participant to fill out the consent form and MRI safety screener, and verbally confirm responses, paying attention to frequently forgotten devices and implants, like orthodontia.</p> <p>DO NOT subject the participant to any risk</p> <ul> <li> In case of any doubts emerging from the MRI safety screening, contact \u2588\u2588\u2588 immediately at  ###-###-####. DO NOT PROCEED if the medical contact cannot be reached.</li> <li> In case of discovering any previously undisclosed contraindication, the volunteer MUST NOT participate in the study.</li> </ul> </li> <li> <p> Load the adequate protocol (guidelines here).     Verify you are loading the appropriate phase-encoding (PE) direction corresponding to the session.</p> Session schedule <p> Today is 2023-11-09 15:36:</p> session day PE replaces 1 2023-10-20 LR         2 2023-10-20 LR 3 2023-10-21 LR 4 2023-10-21 RL 5 2023-10-22 PA 6 2023-10-22 PA 7 2023-10-23 LR 8 2023-10-23 RL 9 2023-10-24 AP 10 2023-10-24 RL 11 2023-10-25 AP        12 2023-10-25 PA 13 2023-10-26 PA        14 2023-10-26 LR 15 2023-10-27 AP 16 2023-10-27 RL 17 2023-10-28 PA 18 2023-10-28 LR 19 2023-10-29 PA 20 2023-10-29 RL 21 2023-10-30 RL 22 2023-10-30 AP 23 2023-10-31 AP 24 2023-10-31 AP 25 2023-11-01 RL 26 2023-11-01 PA        27 2023-11-02 AP 28 2023-11-02 RL 29 2023-11-03 PA        30 2023-11-03 AP        31 2023-11-04 PA        32 2023-11-04 AP        33 2023-11-05 LR        34 2023-11-05 LR        35 2023-11-06 LR        36 2023-11-06 RL 37 2023-11-09 LR 2 38 2023-11-09 PA 12 39 2023-11-10 LR 14 40 2023-11-10 AP 27 41 2023-11-11 AP 30 42 2023-11-11 PA 31 43 2023-11-12 AP 32 44 2023-11-12 LR 33 45 2023-11-13 LR 34 46 2023-11-13 LR 35 47 2023-11-14 RL 36 </li> </ul>"},{"location":"data-collection/participant-prep/#preparation-of-the-participant-in-the-control-room","title":"Preparation of the participant in the CONTROL ROOM","text":""},{"location":"data-collection/participant-prep/#collecting-participants-data","title":"Collecting participant's data","text":"<ul> <li> Measure the participant's blood pressure and write it in the covariates collection form.</li> <li> Ask the participant to fill out the <code>Before scan</code> part of the covariates collection on the issue you opened earlier.</li> <li> Remind the participant to use the bathroom at this moment if they need (\u2588\u2588\u2588).</li> </ul> <p>Only female participants, only the first session</p> <ul> <li> <p> Remind the participant that for their safety, pregnant women cannot participate:</p> <p>Hey [NAME], I have to remind you that pregnant women cannot participate for their safety.</p> <p>To be absolutely sure that you are not scanned while being pregnant, the ethical review board requests us that you take a pregnancy test before the first session. Here you have a test, and this is the urine sample cup. I'm going to show you the bathroom now so that you can do the test with the necessary privacy.</p> </li> <li> <p> Provide the participant with a pregnancy test and a urine sample cup.</p> </li> <li> Go over the instructions with them.</li> <li> Accompany them to the bathroom (situated at \u2588\u2588\u2588), and ask whether there is anything else they anticipate they will need.</li> <li> If the test is positive, the person CANNOT PARTICIPATE in the study.     You MUST be understanding of the situation as most likely the person will not be aware of the circumstance.</li> </ul> <ul> <li> <p> Instruct the participant on how to use the alarm button:</p> Alarm button should be used when needed <p>During the duration of the exam, you'll have an alarm button on your hand. You can use it at any moment. We will first talk with you to check everything is fine, and we will stop the session whenever you need to stop the experiment. There is no need for you to endure uncomfortable experiences or anxiety (for instance, if you feel claustrophobic)</p> </li> </ul>"},{"location":"data-collection/participant-prep/#describing-the-development-of-the-session","title":"Describing the development of the session","text":"<ul> <li> <p> Describe the participant how the session will develop, with special attention to tasks. In the first session, show the task while explaining them for clarity. Let them interrupt you to ask for clarifications and answer all the questions that may arise.</p> Script for the first session <p>We are going to acquire three types of images. The first type is anatomical imaging that we use to study the morphology of the brain. The second type is diffusion MRI, which we use to infer the pathways of major fiber bundles showing how the different regions of the brain may be interconnected. Finally, we collect functional MRI, which we use to understand how the brain activates as a response to stimuli we will present to you. During the whole duration of the exam, please do not create closed loops by crossing your legs or holding your hands together. It is possible that your peripheral nerves get stimulated at some points, so you will feel twitching of muscles, for instance, of your pectorals. Do not panic, it is okay, but if it feels too uncomfortable, please squeeze the alarm button.</p> <p>For the anatomical and the diffusion MRI we just ask you to relax and try to stay as still and comfortable as possible. Like a photographic camera, the largest problem making analyses difficult is motion. As opposed to a photo camera, the imaging of the brain happens very slow so there is a lot of opportunity for involuntary movements (e.g., when you blink or you take a deeper breath) or semi-voluntary (e.g., you need to swallow).</p> <p>The functional MRI is a bit more entertaining, as we will ask you to engage in different behavioral activities. The first functional block is what we call a positive-control task, that will tell us little about your brain but will help us determine if there are confounding signals intermixed with your data. In this positive-control task, you will be shown a fixation point with the shape of a circle. Whenever you see that fixation point, please focus your gaze at the center of it. At points the fixation point will browse around the screen. When that happens, please follow it with your eyes taking care of not moving your head with the eye movement. Other times it will be fixed on the center, and have a blank gray background or a flickering or grating circular area behind it. The last element of this block will show the words LEFT or RIGHT. When either appears, please tap your thumb on each of the your other four fingers of the hand designated by the word, sequentially with all fingers and reversing the direction at the extremes (your pointer and your pinkie). This quality-control task has a length of 2min 38s. During this task, please leave the alarm button on your tummy, where you can recover it when it finishes.</p> <p>Then there is a long block of 20min 6s that we call resting state. During this block, all you have to do is stay still and look at the movie. Please do not close your eyes.</p> <p>Finally, a breath-holding task will help us understand the signals elicited by your breathing that are detected by the scanner. This block has a length of 5min 41s. You will watch five repeats of the same block. Each block will show you a colored rectangle in the middle. The green rectangle means breathe in, the yellow rectangle means breathe out, and the red rectangle means hold your breath. The last two green and yellow rectangle will be shown on a lighter green and orange color respectively to signal you that a hold will follow immediately after the breathe-out. The red rectangle will turn pink to indicate that you will soon be able to breathe-out any remaining air in your lungs and breathe in again. Please remember to breathe out after the breath-hold. When no rectangle is presented, you can breathe as it feels more comfortable to you. The first of the blocks is a mock. That will be reminded to you at the beginning of the task on the screen. During the mock block, please look at the stimuli on the screen but keep your habitual breathing pace disregarding the task instructions. At the end of this mock block, a message will remind you to follow the task instructions from that moment on. You must adapt your breathing to the pace indicated by the color-changing rectangle in the center of the screen for the remaining four repetitions of the block.</p> <p>Is everything clear to you? Do you have any questions?</p> Script for the following sessions <p>As you probably remember, we acquire three types of images. For two of them you just stay still in the scanner, but we will also require your collaboration for the third, which is functional MRI. During the whole duration of the exam, please do not create closed loops by crossing your legs or holding your hands together. Also, remember to breathe through your nose, not through your mouth, so the expired CO<sub>2</sub> can be measured with the cannula. It is possible that your peripheral nerves get stimulated at some points, so you will feel twitching of muscles, for instance, of your pectorals. Do not panic, it is okay, but if it feels too uncomfortable, please squeeze the alarm button.</p> <p>Let's quickly recap the functional MRI tasks. The first is the positive-control task, you will be shown a fixation point with the shape of a circle that you must follow with your gaze wherever it goes and then the words LEFT or RIGHT while which you tap your fingers like this (remind to them). During this task, please leave the alarm button on your tummy, where you can recover it when it finishes.</p> <p>Then there is a long block of about 20 minutes that we call resting state, where you will be watching a movie. During this block, all you have to do is stay still and please do not close your eyes.</p> <p>Finally, the breath-holding task where you will watch five repeats of the same block with colored rectangles in the middle. The green rectangle means breathe in, the yellow rectangle means breathe out, and the red rectangle means hold your breath. The last two green and yellow rectangle will be shown on a lighter green and orange color respectively to signal you that a hold will follow immediately after the breathe-out. The red rectangle will turn pink to indicate that you will soon be able to breathe-out any remaining air in your lungs and breathe in again. Please remember to breathe out after the breath-hold. When no rectangle is presented, you can breathe as it feels more comfortable to you. The first of the blocks is a mock. That will be reminded to you at the beginning of the task on the screen. During the mock block, please look at the stimuli on the screen but keep your habitual breathing pace disregarding the task instructions. At the end of this mock block, a message will remind you to follow the task instructions from that moment on. You must adapt your breathing to the pace indicated by the color-changing rectangle in the center of the screen for the remaining four repetitions of the block.</p> <p>Is everything clear to you? Do you have any questions?</p> </li> </ul>"},{"location":"data-collection/participant-prep/#finalizing-the-preparation","title":"Finalizing the preparation","text":"<ul> <li> <p> Offer the participant a box to deposit everything they have in their pockets and all jewelry/hair accessories, and indicate the clothing to enter the scanning room:</p> Dress code inside the scanner if they need to CHANGE INTO SCRUBS <p>Before we continue, we need to make sure we do not introduce any dangerous object in the magnet room.</p> <p>Here you will find a changing room [SHOW THEM THE CHANGING ROOM]. I have prepared some scrubs for you. Please remove all your clothes and leave them in the changing room. Please keep your underwear on [if a woman, ask whether their undergarment DOES NOT contain any large metallic part such as shaping guides, and request their removal if they do].</p> Dress code inside the scanner if they CAN WEAR THEIR CLOTHES <p>Before we continue, we need to make sure we do not introduce any dangerous object in the magnet room.</p> <p>Please deposit here all your belongings, your belt, your glasses, your jewelry and any accessories, piercings, etc. that you have on you. If a woman, ask whether their undergarment DOES NOT contain any large metallic part such as shaping guides, and request their removal in the changing room.</p> </li> <li> <p> Help the participant to prepare their skin and place the ECG electrodes.</p> </li> </ul>"},{"location":"data-collection/participant-prep/#installing-the-participant-in-the-scanning-room","title":"Installing the participant in the SCANNING ROOM","text":"<ul> <li> Have the participant remove their shoes at the entrance of the scanning room.</li> <li> Show the alarm button to the participant and explain how they may use it.</li> <li> Give to the participant the emergency button. Make the participant try it, so they can see it works. To switch off the alarm, there's a button on the scanner (circular, both on the left and on the right of the hole)</li> <li> Give them the ear-plugs to protect their hearing during acquisition, allow time for them to place them.</li> <li> Instruct the participant to lay on the MRI bed.</li> </ul>"},{"location":"data-collection/participant-prep/#connecting-physiological-recording-sensors-and-probes","title":"Connecting physiological recording sensors and probes","text":"<ul> <li> Connect the ECG leads to the three electrodes. The electrodes MUST be connected following the color scheme shown in the picture below.     </li> <li> Install the RB below the participant's chest and connect it to the tube as shown in the picture below.     The RB measures the stretching induced by breathing, so it MUST surround the chest or stomach comfortably.     Positioning the RB higher (chest) or lower (stomach) depends on the individual's preferential respiration mode (chest breathing or diaphragmatic, respectively).     </li> <li> <p> Place the nasal cannula in the nose of the participant making sure the two protrusions are aligned with the nostrils of the participant.     Place the tube behind the ears and tighten under the chin for comfort and stability by sliding the ring as shown in the picture below.</p> <p></p> </li> <li> <p> Fasten the RB and check with the participant whether they are too uncomfortable when completely laying down on the bed.</p> </li> <li> <p> Check the AcqKnowledge signal visualization of the adjustment of the RB, and make sure that the signal is not saturating (when the RB is too tight) or too weak (when the RB is too loose).</p> Two-people protocol to check the RB settings. <p>This check requires two experimenters, one INSIDE (IN) the scanning room and one more outside (OUT)</p> <ul> <li> OUT indicates they are ready to start the check by signaling a THUMBS-UP WITH BOTH HANDS through the Scanning Room window  .</li> <li> IN MUST confirm they understand returning the THUMBS-UP WITH ONE HAND .</li> <li> IN finalizes the setting of the RB if necessary and asks the participant to breathe normally.</li> <li> Once the participant is lying down on the bed and breathing normally, and the check can be carried out, IN MUST signal they are ready by sending a THUMBS-UP WITH BOTH HANDS   through the window.</li> <li> OUT MUST acknowledge the understanding, return a THUMBS-UP WITH BOTH HANDS  , and check the AcqKnowledge screen.</li> <li> OUT checks for signs of saturation and insufficient dynamic range.     These issues manifest as plateaus and excessively flat lines (respectively) in the AcqKnowledge visualization of the RB signal.</li> <li> OUT provides feedback to the inside room as follows:<ul> <li>If the RB must be tightened up, pointer finger going up ;</li> <li>if the RB must be loosened up, pointer finger going down ;</li> <li>if OUT needs to check again, they show two hands  , checks the AcqKnowledge again and signs another instruction; and</li> <li>if the check is finished, OUT signs a THUMBS-UP WITH BOTH HANDS  .</li> <li>IN MUST acknowledge all the commands with THUMBS-UP WITH ONE HAND  if understood. If not understood, they can request with a PRAYING gesture .</li> </ul> </li> </ul> </li> <li> <p> Solicit feedback on participant's comfort while positioning them on the scanner bed and suggest ergonomic positioning of their arms to avoid discomfort.</p> </li> </ul>"},{"location":"data-collection/participant-prep/#accommodating-the-participants-head-in-the-coil","title":"Accommodating the participant's head in the coil","text":"<ul> <li> Adjust the participant inside. With the paddings, their head position MUST be adjusted and elevated so that the nose and the forehead of the participant are both close to the upper coil. This procedure ensures the ET has the clearest possible view of eye.</li> <li> This part must be repeated taking out and putting back the upper part of the head-coil, adjusting the pillow at every step, until the head is fixed and the nose and forehead of the participant almost touch the coil. In case of need, ask the participant to rotate their head like when saying yes until reaching an adequate position, place any remaining paddings.</li> <li> Take the side paddings and fit them between each ear and the coil. If using the inflatable padding, pump air into them without making the participant uncomfortable (check with them).</li> <li> Cut a long strip of medical auto-adhesive band and stick it at each side of the lower block of the head coil, across the participant's forehead and stick it to the participant's forehead. Indicate the participant that this band will tell them when they moved and help them recover the original position.</li> <li> Place the top block of the coil and check that the participants' front touches or is really close to the coil. Now the nose can also be a bit far from the coil. Tell the participant to relax the neck, so the nose should go a bit up and touch the coil.</li> <li> Connect the coil's cable to the corresponding socket on the table.</li> <li> Check that both the posterior and anterior parts of the head-and-neck coil are now detected:<ul> <li> Verify \"Head Neck 64 Posterior\" is listed on the scanner's monitor, and</li> <li> Verify \"Head Neck 64 Anterior\" is listed in the scanner's monitor.</li> </ul> </li> <li> Place rectangular paddings at each side of the chest and help the participant accommodate their elbows on them.</li> <li> <p> Cover them with a blanket if necessary, and remind them of not closing loops with their body:</p> <p>Ask the participant if they are feeling cold</p> <p>Hey [NAME], are you feeling cold? Do you want a blanket?</p> <p>I have placed some paddings for your elbows, is there anything else you would need to feel comfortable?</p> <p>Throughout the examination, remember not to create closed loops by crossing your legs or holding hands together.</p> </li> <li> <p> Insert the participant in the scanner following the protocol.</p> </li> <li> Once the participant is lying on the scanner bed, check that no arms/legs rest on the GA or the RB tubes and may block them.</li> <li> Before continuing with the setup, make sure all cables and tubes leave the scanner's bed perpendicularly and lie on the floor.     Tape them to the floor so that they don't move accidentally.</li> </ul>"},{"location":"data-collection/participant-prep/#final-preparations","title":"Final preparations","text":"<ul> <li> Inform the participant that you are leaving the room and will shortly come back for a final preparation.</li> <li> Proceed with the ET aiming and focusing protocol.</li> <li> Inform the participant that you are leaving the room and will now close the door to start.     Let them also know that you are going to communicate with them very shortly to check that communications through the speaker are functioning.</li> <li> Exit the Scanning Room.</li> <li> Close the Scanning Room door.</li> <li> <p> Check the communication with the participant.</p> Do not allow a delay before talking to the participant <p>Delays in establishing contact with the participant will likely increase their anxiety.</p> </li> </ul> <p>You can now move on to initiating the session</p>"},{"location":"data-collection/pre-session/","title":"Before session day","text":""},{"location":"data-collection/pre-session/#three-days-before-1st-session","title":"Three days before 1<sup>st</sup> session","text":"<ul> <li> Verify that as part of the recruitement and screening procedure, you have sent a copy of the MRI Safety and screening form (EN|FR) to the participant over email and confirm reception by checking the 'First contact email sent' column in our recruits spreadsheet.</li> <li> Verify that the 'Phone interview done' and 'Participant volunteer and eligible' columns in our recruits spreadsheet are checked.<ul> <li> If the phone call interview was more than three days before the first session or the two items immediately above were not checked, call the participant again to reconfirm the following information:<ul> <li> Remind the participant that any jewelry should be removed prior to the scan.</li> <li> Indicate that they MUST shave the upper area of their chest where the ECG electrodes will be placed, if there is hair because the ECG electrodes MUST directly contact the skin.</li> <li> Confirm clothing:<ul> <li> if allowed to wear street clothes, remind the participant to avoid clothing with metal or that would uncomfortable to lie in for the duration of the scan; otherwise</li> <li> remark the participant they will be given a gown and they will need to change before every session.</li> </ul> </li> <li> Repeat at what time and where will you meet the participant.</li> <li> Verify that the participant has your phone number  ###-###-#### to call you in case they gets lost.</li> <li> FEMALE PARTICIPANTS ONLY: Remind the participant that pregnant women cannot undergo our MRI protocols. Therefore, they will take a pregnancy test (which we will have prepared) before the first session.</li> </ul> </li> </ul> </li> <li> If participant has indicated nervousness or history of claustrophobia, organize a session to use the mock scanner.</li> </ul>"},{"location":"data-collection/pre-session/#three-days-before-every-session","title":"Three days before EVERY session","text":"<p>We MUST verify that \u2588\u2588\u2588 correctly runs all Psychopy experiments.</p> <ul> <li> Connect a secondary screen to the HDMI input of the computer</li> <li> Switch it on and log in into the common user (password: <code>*****</code>).</li> <li> <p> Open a terminal</p> <p>Shortcut  + t</p> </li> <li> <p> Update the HCPh-fMRI-tasks repository on \u2588\u2588\u2588:     <pre><code>cd ~/workspace/HCPh-fMRI-tasks\ngit fetch upstream\ngit checkout master\ngit rebase upstream/master\n</code></pre></p> </li> </ul> The following two commands are executed with <code>sudo</code> <p>The console will request the common user password (<code>*****</code>).</p> <ul> <li> Spin up a mock MMBT-S device listening on <code>/dev/ttyACM0</code>:     <pre><code>sudo socat PTY,link=/tmp/virtual_serial_port PTY,link=/dev/ttyACM0,group-late=dialout,mode=666,b9600\n</code></pre></li> <li> Manually spin up the trigger-forwarding service:     <pre><code>sudo python3 code/synchronization/forward-trigger-service.py --disable-mmbt-check\n</code></pre></li> </ul> Make sure to load the correct environment <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <ul> <li> Run the compiled tasks with Python directly.</li> <li> <p> Load in the different experiments and check for proper functioning and timing:</p> <ul> <li>dMRI (only fixation):     <pre><code>python task-fixation_dwi.py\n</code></pre></li> <li>QCT:     <pre><code>python task-qct_bold.py\n</code></pre></li> <li>RSfMRI <pre><code>python task-rest_bold.py\n</code></pre></li> <li>BHT:     <pre><code>python task-bht_bold.py\n</code></pre></li> </ul> <p>All of the above command lines SHOULD open a modal dialog asking you for the number of trial (automatically calculated, DO NOT modify) and the session number.</p> <p>The following steps MUST be executed in this order</p> <ul> <li> Drag and drop the modal dialog into the scanner's projector screen.</li> <li> Update the session number with the corresponding number.</li> </ul> </li> <li> <p> Check the correct session number is set (use the default 9999 for testing) and hit OK.</p> The OK button MUST be clicked with this modal dialog on the secondary screen <p>Otherwise, the wrong screen will be selected by Psychopy</p> </li> </ul> Updating Ubuntu or Psychopy is not recommended in the proximity of data collection <p>However, you should make sure you are on Ubuntu 22.04 LTS, Python 3.10, and Psychopy 2023.2.3.</p>"},{"location":"data-collection/pre-session/#one-day-before-the-session","title":"One day before the session","text":"<ul> <li> Print the informed consent form (first session only)</li> <li> Print the MRI safety screener (EN|FR).</li> <li> Print a receipt form for each participant that will get scanned.</li> <li> Prepare a gas cannula (oxygen mask) by cutting it before the fork and plugging two medication line tubes.</li> </ul>"},{"location":"data-collection/scanning/","title":"Running the scanning session","text":"<p>Familiarize with emergency procedures</p> <p>You MUST know the security procedures in case of problem and keep yourself updated with changes. Some of the emergency procedures are found here.</p> <p>In addition to the brief guidelines given in these SOPs, further safety information is found in \u2588\u2588\u2588.</p>"},{"location":"data-collection/scanning/#before-initiating-the-session","title":"Before initiating the session","text":"Double check the protocol with the correct phase-encoding direction was selected <p>For conveniency, this is the session schedule (today is 2023-11-09 15:36):</p> session day PE replaces 1 2023-10-20 LR         2 2023-10-20 LR 3 2023-10-21 LR 4 2023-10-21 RL 5 2023-10-22 PA 6 2023-10-22 PA 7 2023-10-23 LR 8 2023-10-23 RL 9 2023-10-24 AP 10 2023-10-24 RL 11 2023-10-25 AP        12 2023-10-25 PA 13 2023-10-26 PA        14 2023-10-26 LR 15 2023-10-27 AP 16 2023-10-27 RL 17 2023-10-28 PA 18 2023-10-28 LR 19 2023-10-29 PA 20 2023-10-29 RL 21 2023-10-30 RL 22 2023-10-30 AP 23 2023-10-31 AP 24 2023-10-31 AP 25 2023-11-01 RL 26 2023-11-01 PA        27 2023-11-02 AP 28 2023-11-02 RL 29 2023-11-03 PA        30 2023-11-03 AP        31 2023-11-04 PA        32 2023-11-04 AP        33 2023-11-05 LR        34 2023-11-05 LR        35 2023-11-06 LR        36 2023-11-06 RL 37 2023-11-09 LR 2 38 2023-11-09 PA 12 39 2023-11-10 LR 14 40 2023-11-10 AP 27 41 2023-11-11 AP 30 42 2023-11-11 PA 31 43 2023-11-12 AP 32 44 2023-11-12 LR 33 45 2023-11-13 LR 34 46 2023-11-13 LR 35 47 2023-11-14 RL 36 <p>Report all observations in the session notes</p> <p>It is easy to forget details about particular sessions, especially when so many sessions are acquired.  They can however be very informative for quality control of your data or understand idiosyncrasies, so it is important to keep track of them. As such, please note any observation in the issue dedicated to collecting session notes that you should have opened in the preparation of the session.</p>"},{"location":"data-collection/scanning/#during-the-session","title":"During the session","text":"<ul> <li> Check in with the participant frequently, not necessarily only at the scripted points.</li> <li> Watch for motion and arousal state using the ET's camera.       If you detect motion or the participant falls asleep at inadequate points, use the speaker to inform them.</li> </ul>"},{"location":"data-collection/scanning/#check-experimental-setup","title":"Check experimental setup","text":"<p>DO NOT FORGET to check the readiness of the experimental setup at this point</p>"},{"location":"data-collection/scanning/#check-the-syncbox","title":"Check the syncbox","text":"<ul> <li> the box is on,</li> <li> Synchronization mode is on,</li> <li> session has been started,</li> <li> volume count is reset to 0 out of 9999,</li> <li> USB cable to \u2588\u2588\u2588 is connected.</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul>"},{"location":"data-collection/scanning/#check-the-biopac","title":"Check the BIOPAC","text":"<ul> <li> All cables are connected and not loose or hanging.</li> <li> The BIOPAC is turned on (switch it on if necessary).</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul>"},{"location":"data-collection/scanning/#check-the-ga","title":"Check the GA","text":"<ul> <li> the exhaust cap IS REMOVED</li> <li> the tubing coming from the scanning room is properly connected,</li> <li> the CO<sub>2</sub> BNC output is plugged through the filter to the BIOPAC AMI200, on input channel 3,</li> <li> the GA is on (switch it on if necessary),</li> <li> ensure the PUMP IS ON, and</li> <li> turn the pump's power knob to MAXIMUM position.</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul>"},{"location":"data-collection/scanning/#check-the-eye-tracker","title":"Check the eye-tracker","text":"<ul> <li> The ET computer is turned on (switch it on if necessary),</li> <li> The pupil is correctly detected (as described here)</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul>"},{"location":"data-collection/scanning/#check","title":"Check \u2588\u2588\u2588:","text":"<ul> <li> has enough battery, and plug the power cord if necessary;</li> <li> USB cable to the MMBT-S Trigger Interface Box is connected;</li> <li> serial cable from the MMBT-S Trigger Interface Box is connected to the back of the SPT100D digital interface (gray block) of the BIOPAC;</li> <li> computer is ready, with psychopy open, and with the appropriate version of experiments; and</li> <li> leave the computer with a pleasant screen projecting (e.g., a gray background).</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul> Make sure to load the correct environment <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul>"},{"location":"data-collection/scanning/#check_1","title":"Check \u2588\u2588\u2588:","text":"<ul> <li> has enough battery, and plug the power cord if necessary;</li> <li> computer is ready, with the AcqKnowledge software open and collecting data;</li> <li> check the ECG and RB signals, and fix unanticipated problems (e.g., the respiration belt needs to be fastened tighter);</li> <li> the Amphetamine app is running and keeping the computer unlocked while AcqKnowledge is working.</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul> <p>When running multiple sessions back-to-back</p> <pre><code>- [ ] Restart a new session of the syncbox (within one session we usually see 9,000+, and the maximum is 9,999):\n    - [ ] Press the central button :fontawesome-solid-circle:{ .bluecolor } to stop the session,\n    - [ ] use the up :fontawesome-solid-caret-up:{ .bluecolor } and down :fontawesome-solid-caret-down:{ .bluecolor } arrows to find and select the option &lt;span class=\"syncbox\"&gt;Start Session&lt;/span&gt; and hit enter :fontawesome-solid-circle:{ .bluecolor },\n    - [ ] Press the central button :fontawesome-solid-circle:{ .bluecolor } again to start the new session.\n- [ ] In *AcqKnowledge*, make sure you stopped the previous recording and started a new one (it will ask for a re-calibration of the respiration belt).\n- [ ] Start a *New examination* on the MR console:\n    - [ ] Make sure all acquisitions are done,\n    - [ ] close any open patient window,\n    - [ ] find the patient in the system (or write new information for a new participant)\n    - [ ] right click on the patient and press `start new examination`.\n</code></pre>"},{"location":"data-collection/scanning/#ensuring-the-quality-of-physiological-signals","title":"Ensuring the quality of physiological signals","text":"<p>It is critical to check that physiological signals are looking good:</p> <ul> <li>Before starting the session, and</li> <li>from time to time within the session.</li> </ul> Examples of good and problematic RB and CO<sub>2</sub> signals. Following these guidelines, our physiological signals should resemble the cases labeled as \"good\" above. <p>Thanks to C\u00e9sar Caballero-Gaud\u00e9s, Stefano Moia, Kristina Zvolankek, Elenor Morgenroth for the slide above<sup>1</sup>.</p>"},{"location":"data-collection/scanning/#checking-the-rb","title":"Checking the RB","text":"<p>To ensure the best RB signal</p> <p>Calibrate the RB with the tube unplugged while the participant is in the scanner (you may have to help the participant). Then, ask (and/or help) the participant to plug it back.</p> <ul> <li> The RB signal SHOULD NOT plateau (neither saturate at a peak value nor floor at the troughs).     This means the RB is maxing out and it requires loosening.</li> <li> The envelope of your signal SHOULD remain approximately constant.     If peaks drop or troughs rise, it might be a sign that the RB is too loose.     Go back into the scanning room and tighten the RB.</li> <li> Check the corresponding box in the issue collecting notes about the session.</li> </ul>"},{"location":"data-collection/scanning/#checking-the-co2-signal","title":"Checking the CO<sub>2</sub> signal","text":"<ul> <li> <p> The period of the CO<sub>2</sub> signal should remain constant.     If it varies, the vacuum MAY be too low:</p> <ul> <li> Check that the nasal cannula is correctly placed in the participant's nostrils.</li> <li> Check that all the extension connections of the tube are air-tight</li> <li> Check that the tube is not hanging at any point.</li> </ul> </li> <li> <p> The envelope of your signal SHOULD remain approximately constant.     If the peaks diminish, it might be a sign that the participant is breathing through their mouth.     In such a case, remind the participant to breathe through their nose.</p> Remind the participant they MUST breathe through their nose at all times <p>Hey [NAME],</p> <p>Is everything okay?</p> <p>I needed to ask you whether you are breathing through your nose because we are not recording sensible levels of CO<sub>2</sub>.</p> <p>[WAIT FOR THEIR RESPONSE]</p> <p>Thank you.</p> </li> <li> <p> Check the corresponding box in the issue collecting notes about the session.</p> </li> </ul>"},{"location":"data-collection/scanning/#checking-the-ecg-signal","title":"Checking the ECG signal","text":"<ul> <li> The period and the envelope of the signal should remain constant.</li> <li> <p> We are placing the ECG electrodes in lead-1 mode, which should give an ECG signal that looks vaguely like the familiar QRS shape (see below).     Typically, the signal does not look as neat as on the schema because the magnetic fields of the MR interfere with the electrodes (even if they are MR-compatible electrodes).</p> <p></p> </li> <li> <p> Check the corresponding box in the issue collecting notes about the session.</p> </li> </ul>"},{"location":"data-collection/scanning/#acquire-a-localizer-aahead_scout","title":"Acquire a localizer (AAhead_scout)","text":"<ul> <li> <p> Indicate the participant that the scanning will soon start:</p> Tell the participant that we are starting <p>Hey [NAME], we are about to start our first scan run.</p> <p>This is going to be a long session, so please make sure you are feeling as comfortable as you possibly can in there. Remember not to cross your legs or hold your hands together and check your back is also comfortable. I'm going to ask you to take a deep breath now, so I can check the respiration belt is properly set up. If it is too tight, please let me know.</p> <p>[Allow a few moments for the participant to breathe while you check the recordings]</p> <p>Okay, we seem to be able to track your respiration. Is the respiration belt too restraining? This is also a good moment to swallow, and to check your neck and head are in a comfortable position.</p> <p>For this first part, all you have to do is stay still; you can relax and close your eyes if it helps.</p> <p>Are you ready?</p> </li> <li> <p> Wait for the participant confirmation and set the speaker off afterward.</p> </li> <li> Launch the <code>AAhead_scout_64ch-head-coil</code> protocol by pressing Continue .</li> </ul> <p>Once the localizer is concluded:</p> <ul> <li> <p> Click on the image stack icon (something like \ud83d\uddc7, with an object on the top stack) and drag the image with a 1 onto the image viewer.     That will open the interpolated localizer on the viewer.</p> <p></p> </li> <li> <p> In the issue collecting notes about the session, check the box confirming that the localizer has been acquired. </p> <ul> <li> If the quality looks good, check the box stating <code>Localizer looked ok</code>. If not, follow the paragraph below.</li> </ul> </li> </ul>"},{"location":"data-collection/scanning/#if-the-localizer-presents-very-low-quality","title":"If the localizer presents very low quality","text":"<p>The localizer may present very low quality if the head-coil has not been properly initiated by the scanner</p> <ul> <li> In the issue collecting notes about the session, specifically under anat issues select the problem and describe it in detail in the anatomical scan notes section. </li> <li> Enter the scanning room, extract the participant from the scanner by pressing the home () button.</li> <li> Tell the participant that you need to reset the head coil</li> <li> Unplug and replug the head coil</li> <li> Check that the coil has been properly detected in the scanner's monitor</li> <li> Re-insert the participant in the scanner</li> <li> Re-run the <code>AAhead_scout_{32,64}ch-head-coil</code> protocol.</li> </ul>"},{"location":"data-collection/scanning/#acquire-a-high-resolution-anatomical-image","title":"Acquire a high-resolution, anatomical image","text":"<ul> <li> <p> Launch the <code>anat-T1w__mprage</code> protocol by pressing Continue .</p> <p>While you are still running the MPRAGE sequence</p> <ul> <li> Open the parameters of the sequence named <code>fmap-phasediff__gre</code> and ensure that under Contrast \u2937 Reconstruction the option Magnitude et phase is selected. This is crucial so that both the magnitude and the phase difference field map images are saved.</li> <li> Repeat the configuration of Magnitude et phase for all sequences name <code>fmap-epi_acq-bold_dir-{RL,LR,PA,AP}__*</code>.</li> <li> Repeat the configuration of Magnitude et phase for all sequences name <code>func-bold_task-{bht,qct,rest}_dir-{RL,LR,PA,AP}__cmrr_me4_sms4</code>.</li> <li> Open the <code>dwi-dwi_dir-{RL,LR,PA,AP}__279dir_monopolar</code> sequence and under the section Diff., uncheck all the derivatives except for Diff. Weighted Image.</li> <li> Open the <code>fmap-epi_acq-b0_dir-{RL,LR,PA,AP}__*</code> sequences and under the section Diff., uncheck all the derivatives except for Diff. Weighted Image.</li> </ul> </li> <li> <p> In the issue collecting notes about the session, check the box confirming that the T1w image has been acquired. </p> <ul> <li> If the quality looks good, check the box stating <code>T1w looked okay</code>.     If not, please follow the instructions to repeat the scan and report the problem in the session notes.</li> </ul> </li> </ul>"},{"location":"data-collection/scanning/#acquire-the-dmri-epi-fieldmaps","title":"Acquire the dMRI EPI fieldmaps","text":"<ul> <li> Adjust the FoV of the <code>fmap-epi_acq-b0_dir-{RL,LR,PA,AP}__6dir_monopolar*</code> sequences.</li> <li> Verify again the <code>fmap-epi_acq-b0_dir-{RL,LR,PA,AP}__6dir_monopolar</code> parameters under section Diff. All the derivatives MUST be unchecked except for Diff. Weighted Image.</li> <li> <p> Inform the participant that the diffusion scan will follow.</p> Only for the participant of Cohort I <p>Hey Oscar, we are ready to proceed with the diffusion scan. The BIOPAC is functional and AcqKnowledge is properly registering the respiration belt and ECG. The gas analyzer is ON, but it is still warming up. The psychopy computer is ready. Are you ready?</p> Participant of Cohort II <p>Hey [NAME], the next block is a bit long. First, we will run four short sequences of less than one minute and then a long block of around 30 minutes.</p> <p>You can close your eyes and even sleep if you wish.</p> <p>I'm going to give you a short time (ten seconds or so) to swallow, and perhaps accommodate your back or your arms. However, please try not to move your head.</p> <p>It is critical that you don't move, especially at all at the very beginning and the next 20 seconds after you hear the first blipping sounds.</p> <p>Try to minimize swallowing and eye movements (for example, blinking) and maintain comfortable and shallow breathing. Remember to breathe through your nose, not through your mouth, so the expired CO<sub>2</sub> can be measured with the cannula.</p> <p>Are you ready?</p> </li> <li> <p> Launch the DWI-EPI sequence <code>fmap-epi_acq-b0_dir-{RL,LR,PA,AP}__6dir_monopolar</code> for B<sub>0</sub> field mapping by pressing Continue .</p> </li> </ul> <p>While the fieldmaps are running:</p> <ul> <li> Adjust the FoV of the <code>dwi-dwi_dir-{RL,LR,PA,AP}__279dir_monopolar</code> sequence, and</li> <li> <p> prepare the execution of the fixation program on the stimuli laptop (\u2588\u2588\u2588), which will be played during the DWI by typing the following on a terminal:</p> Make sure to have the correct environment loaded before invoking the task <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <pre><code>cd ~/workspace/HCPh-fMRI-tasks\npython task-fixation_dwi.py\n</code></pre> <p>A modal dialog will ask you for the number of trial (automatically calculated, DO NOT modify) and the session number.</p> <p>The following two steps MUST be executed in this order</p> <pre><code>- [ ] Drag and drop the modal dialog into the scanner's projector screen.\n- [ ] Update the session number with the corresponding number.\n</code></pre> </li> </ul> <p>At this point, the GA should have finished the warm-up so you can verify it is working</p> <ul> <li> Ask the participant to take three deep breathes, to then go back to a comfortable, normal respiration pace.</li> <li> Check on the AcqKnoledge window that the three breathes are distinctly registered (taking into account that there may be 10-25 seconds of delay because of the tubing).</li> </ul>"},{"location":"data-collection/scanning/#acquire-the-diffusion-mri-run","title":"Acquire the diffusion MRI run","text":"<ul> <li> Verify again the <code>dwi-dwi_dir-{RL,LR,PA,AP}__279dir_monopolar</code> parameters under section Diff. All the derivatives MUST be unchecked except for Diff. Weighted Image.</li> <li> <p> Inform the participant that before the long dMRI block, the ET must be calibrated.</p> Starting the dMRI block after calibrating the eye tracker <p>Hey [NAME], is everything alright thus far?</p> <p>[Allow some time for response]</p> <p>Before we start the long dMRI block, we need to calibrate the eye-tracker device, which follows your right eye during experiments.</p> <p>Your are going to see a round fixation point, and the point is going to move randomly over the screen space. Please follow it with your gaze, trying to look at it as stable as possible and without moving your head.</p> <p>Are you ready?</p> </li> <li> <p> On the stimuli laptop (\u2588\u2588\u2588), check the correct session number is set and hit OK.</p> The OK button MUST be clicked with this modal dialog on the projector's screen <p>Otherwise, the wrong screen will be selected by Psychopy</p> </li> <li> <p> Proceed with the ET calibration.     The ET control menu will appear after hitting OK on the modal dialog.</p> </li> <li> Launch the diffusion <code>dwi-dwi_dir-{RL,LR,PA,AP}__279dir_monopolar</code> sequence by pressing Continue .</li> </ul> <p>While the dMRI is running:</p> <ul> <li> Adjust the FoV for the following sequence (GRE fieldmap).</li> </ul> <p>When the dMRI concludes:</p> <ul> <li> <p> Wait for the current task program to finish on \u2588\u2588\u2588.</p> <p>If you must interrupt the task program, check first that the EDF files have been copied.</p> </li> </ul>"},{"location":"data-collection/scanning/#acquire-the-gre-fieldmap","title":"Acquire the GRE fieldmap","text":"<ul> <li> In the corresponding issue for the collection of notes about the session, check the box confirming that the diffusion sequence has been acquired.     Don't forget to report any observations there.</li> <li> Launch the GRE (phase difference) sequence <code>fmap-phasediff__gre</code> for B<sub>0</sub> field mapping by pressing Continue .</li> </ul> <p>While the GRE fieldmap is running:</p> <ul> <li> Adjust the FoV for the positive-control-task (<code>func-bold_task-qct_dir-{RL,LR,PA,AP}__cmrr_me4_sms4</code>) fMRI sequence,</li> <li> verify that in the next sequence parameters under Contrast&gt;Reconstruction the option Magnitude et phase is selected,</li> <li> verify the Number of measurements with respect to the task's timing (2min 38s),</li> <li> verify that the EDF file with the ET recordings corresponding to the dMRI have been stored, and</li> <li> <p> prepare the execution of the QCT by executing the following on a terminal:</p> Make sure to have the correct environment loaded before invoking the task <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <pre><code>cd ~/workspace/HCPh-fMRI-tasks\npython task-qct_bold.py\n</code></pre> <p>A modal dialog will ask you for the number of trial (automatically calculated, DO NOT modify) and the session number.</p> <p>The following two steps MUST be executed in this order</p> <pre><code>- [ ] Drag and drop the modal dialog into the scanner's projector screen.\n- [ ] Update the session number with the corresponding number.\n</code></pre> </li> <li> <p> In the issue collecting notes about the session, check the boxes confirming that each fieldmap has been acquired and that you check that the physiological signal are still recording.     Don't forget to report any observations there.</p> </li> </ul>"},{"location":"data-collection/scanning/#acquire-the-functional-mri-block","title":"Acquire the functional MRI block","text":"<ul> <li> <p> Inform the participant about the fMRI block</p> Starting the fMRI block <p>Hey [NAME], we are now to move into measuring the activity of your brain.</p> <p>Is everything alright thus far?</p> <p>[Allow some time for response]</p> <p>Before we start, we are going to check if the eye-tracker is still accurate.</p> <p>Your are going to see a fixed, round fixation point. Please focus your gaze on it, trying to look at it as stable as possible and without moving your head.</p> <p>If the eye-tracker is very off, we will re-calibrate it.</p> <p>Are you ready?</p> </li> <li> <p> Wait for confirmation, respond to follow-up comments.</p> </li> <li> <p> On the stimuli laptop (\u2588\u2588\u2588), check the correct session number is set and hit OK.</p> The OK button MUST be clicked with this modal dialog on the projector's screen <p>Otherwise, the wrong screen will be selected by Psychopy</p> </li> <li> <p> Initiate the ET drift correction procedure.     The ET control menu will appear after hitting OK on the modal dialog.</p> </li> </ul>"},{"location":"data-collection/scanning/#quality-control-task-qct","title":"Quality-control task (QCT)","text":"<ul> <li> Verify that the task's program is awaiting the scanner's trigger to start.</li> <li> <p> Inform the participant that we will proceed with the quality-control task (QCT). Repeat task instructions.</p> Starting the positive control task <p>Hey [NAME], thanks for your collaboration with the eye tracking calibration.</p> <p>The following block will collect some behavioral data and requires your collaboration. You will be exposed to several activities.</p> <p>Whenever you see a red circle, please fix your gaze on it, wherever it is shown on the screen. If the red circle moves, we ask you to follow it with your eyes.</p> <p>Some other times, you'll see either \"RIGHT\" or \"LEFT\" written on the screen. During those times, please tap your thumb and the other fingers of your right or left hand as indicated on the screen.</p> <p>Before we start, please leave the alarm button on your tummy to free your hand for finger tapping. Please do not hesitate to grab it in case you need to squeeze it.</p> </li> <li> <p> Launch the <code>func-bold_task-qct_dir-{RL,LR,PA,AP}__cmrr_me4_sms4</code> protocol by pressing Continue .</p> </li> <li> Confirm that the task program starts on \u2588\u2588\u2588 after the calibration scans.</li> </ul> <p>While the QCT is running:</p> <ul> <li> Adjust the FoV for the following sequence,</li> <li> double check that it has the setting Magnitude et phase selected in the drop-down menu under Contrast&gt;Reconstruction.</li> </ul> <p>Once the QCT has concluded:</p> <ul> <li> <p> Wait for the current task program to finish on \u2588\u2588\u2588.</p> <p>If you must interrupt the task program, check first that the EDF files have been copied.</p> </li> <li> <p> In the corresponding issue for the collection of notes about the session, check the box confirming that the quality control task fMRI has been acquired and that you check that the physiological signals are still being recorded.     Don't forget to report any observations there.</p> </li> </ul>"},{"location":"data-collection/scanning/#bold-fieldmaps","title":"BOLD fieldmaps","text":"<ul> <li> Launch the BOLD-EPI sequence <code>fmap-epi_acq-bold_dir-{RL,LR,PA,AP}__cmrr_me4_sms4</code> for B<sub>0</sub> field mapping by pressing Continue .</li> </ul> <p>While the BOLD fieldmaps are running:</p> <ul> <li> Adjust the FoV for the following sequence,</li> <li> verify the Number of measurements with respect to the task's timing (20min 6s), and</li> <li> double check that it has the setting Magnitude et phase selected in the drop-down menu under Contrast&gt;Reconstruction.</li> </ul> <p>Do not attempt to initiate the next task program before fieldmaps conclude</p> <p>The BOLD fieldmaps will be sending trigger pulses that will make the process almost impossible.</p> <p>Once the BOLD fieldmaps are concluded:</p> <ul> <li> <p> Prepare the execution of the RSfMRI by executing the following on a terminal:</p> Make sure to have the correct environment loaded before invoking the task <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <pre><code>cd ~/workspace/HCPh-fMRI-tasks\npython task-rest_bold.py\n</code></pre> <p>A modal dialog will ask you for the number of trial (automatically calculated, DO NOT modify) and the session number.</p> <p>The following steps MUST be executed in this order</p> <pre><code>- [ ] Drag and drop the modal dialog into the scanner's projector screen.\n- [ ] Update the session number with the corresponding number.\n</code></pre> </li> <li> <p> On the stimuli laptop (\u2588\u2588\u2588), check the correct session number is set and hit OK.</p> The OK button MUST be clicked with this modal dialog on the projector's screen <p>Otherwise, the wrong screen will be selected by Psychopy</p> </li> </ul>"},{"location":"data-collection/scanning/#resting-state-fmri","title":"Resting state fMRI","text":"<ul> <li> <p> Inform the participant:</p> Drift-check ET before continuing <p>Thanks [NAME], that was a short behavioral task.</p> <p>Before moving on, we will run another check of the eye tracker, please focus your sight on the fixation point.</p> <p>Is everything alright?</p> </li> <li> <p> Wait for confirmation, respond to follow-up comments</p> </li> <li> Initiate the ET drift correction procedure.     The ET control menu must have appeared after hitting OK on the modal dialog.<ul> <li> Once the ET is calibrated, verify that the task is left and awaiting for the sequence's trigger to start.</li> </ul> </li> <li> <p> Inform the participant that the next sequence is resting-state fMRI (RSfMRI).</p> Starting the resting-state block <p>Hey [NAME], we are about to start resting-state fMRI.</p> <p>For this scan, all you have to do is stay still, and look at the movie. Please do not close your eyes, and it is particularly critical that you don't move at all in the initial moments of the acquisition block.</p> <p>Are you ready?</p> </li> <li> <p> Launch the RSfMRI sequence <code>func-bold_task-rest_dir-{RL,LR,PA,AP}__cmrr_me4_sms4</code> by pressing Continue .</p> </li> <li> Confirm that the task program starts on \u2588\u2588\u2588 after the calibration scans.</li> </ul> <p>While the RSfMRI is running:</p> <ul> <li> Adjust the FoV for the following sequence,</li> <li> verify the Number of measurements with respect to the task's timing (5min 41s), and</li> <li> double check that it has the setting Magnitude et phase selected in the drop-down menu under Contrast&gt;Reconstruction.</li> </ul> <p>Once the RSfMRI is concluded:</p> <ul> <li> <p> Wait for the current task program to finish on \u2588\u2588\u2588.</p> <p>If you must interrupt the task program, check first that the EDF files have been copied.</p> </li> <li> <p> In the corresponding issue for the collection of notes about the session, check the box confirming that the quality control task fMRI has been acquired and that you check that the physiological signals are still being recorded.     Don't forget to report any observations there.</p> </li> <li> <p> Prepare the execution of the BHT by executing the following on a terminal:</p> Make sure to have the correct environment loaded before invoking the task <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <pre><code>cd ~/workspace/HCPh-fMRI-tasks\npython task-bht_bold.py\n</code></pre> <p>A modal dialog will ask you for the number of trial (automatically calculated, DO NOT modify) and the session number.</p> <p>The following steps MUST be executed in this order</p> <pre><code>- [ ] Drag and drop the modal dialog into the scanner's projector screen.\n- [ ] Update the session number with the corresponding number.\n</code></pre> </li> <li> <p> On the stimuli laptop (\u2588\u2588\u2588), check the correct session number is set and hit OK.</p> The OK button MUST be clicked with this modal dialog on the projector's screen <p>Otherwise, the wrong screen will be selected by Psychopy</p> </li> </ul>"},{"location":"data-collection/scanning/#breath-holding-task-bht","title":"Breath-holding task (BHT)","text":"<ul> <li> <p> Inform the participant:</p> Drift-check ET before continuing <p>Thanks [NAME], that was a long behavioral task.</p> <p>Before moving on, we will run another check of the eye tracker, please focus your sight on the fixation point.</p> <p>Is everything alright?</p> </li> <li> <p> Wait for confirmation, respond to follow-up comments</p> </li> <li> Initiate the ET drift correction procedure.     The ET control menu must have appeared after hitting OK on the modal dialog.<ul> <li> Once the ET is drift-checked and no calibration is needed, verify that the ET menu is removed and the task program awaits for the sequence's trigger to start.</li> </ul> </li> <li> <p> Inform the participant that the next sequence is breath-holding task fMRI.     Repeat the instructions for the task.</p> Starting the breath-holding task <p>Hey [NAME], we will proceed now with a breath-holding task.</p> <p>I remind you that you have to breathe following the cues of the colored rectangle.</p> <p>Green means \"BREATHE IN\", orange means \"BREATHE OUT\" and red means \"HOLD YOUR BREATH\".</p> <p>Remember to not follow the breathing instructions during the first block and to exhale the small amount of air you have remaining at the end of the hold.</p> <p>Are you ready?</p> </li> <li> <p> Launch the <code>func-bold_task-bht_dir-{RL,LR,PA,AP}__cmrr_me4_sms4</code> sequence by pressing Continue .</p> </li> <li> Confirm that the task program starts on \u2588\u2588\u2588 after the calibration scans.</li> </ul> <p>While the BHT is running:</p> <ul> <li> Determine whether there is enough time to run the anatomical T2-weighted run.     If so,<ul> <li> adjust the FoV for the following sequence; or alternatively</li> <li> wait for the sequence to complete.</li> </ul> </li> </ul> <p>Once the BHT is concluded:</p> <ul> <li> <p> Wait for the current task program to finish on \u2588\u2588\u2588.</p> <p>If you must interrupt the task program, check first that the EDF files have been copied.</p> </li> <li> <p> Check the box confirming that it has been acquired in the issue collecting notes about the session.     Don't forget to report any observations there.</p> </li> </ul>"},{"location":"data-collection/scanning/#acquire-a-t2w-image-if-time-permits","title":"Acquire a T2w image (if time permits)","text":"<ul> <li> Launch the <code>anat-T2w__flair</code> protocol by pressing Continue , or</li> <li> skip the T<sub>2</sub>-weighted collection.</li> </ul>"},{"location":"data-collection/scanning/#stop-physiology-collection","title":"Stop physiology collection","text":"<p>The following step MAY be done while the T2w is running.</p> <ul> <li> <p> Stop the AcqKnowledge recording on the \u2588\u2588\u2588 computer.</p> <p>Allow some 60s after the BHT has concluded before stopping AcqKnowledge</p> </li> </ul> <p>The following steps MAY be done while the T2w is running IF (and only if) there's no back-to-back session upon conclusion of the current</p> <ul> <li> Switch the BIOPAC MP160 module off (WAIT ~60s after the BHT).</li> <li> Turn off the pump of the GA.</li> <li> Switch the GA off.</li> <li> Put the exhaust cap back.</li> <li> Exit the EyeLink 1000 Plus Host PC application by clicking on the Exit EyeLink button, that will exit and leave you in the MS-DOS prompt.</li> <li> Push the switch-off button of the ET PC (MS-DOS does not have a shutdown command, so you just physically switch off the box).</li> </ul>"},{"location":"data-collection/scanning/#concluding-the-session","title":"Concluding the session","text":"<ul> <li> <p> Inform the participant:</p> Session is finished <p>Thanks [NAME], the session has concluded and we will shortly let you out of the scanner.</p> </li> </ul>"},{"location":"data-collection/scanning/#session-completed","title":"Session completed","text":"<p>The exam is over, you can proceed with the tear-down protocol.</p>"},{"location":"data-collection/setup/","title":"Before data collection starts","text":""},{"location":"data-collection/setup/#scanner","title":"Scanner","text":"<p>Once finalized the protocol development (before the first session of the first participant), the protocol(s) MUST be frozen and remain unchanged throughout the data collection effort.</p> <ul> <li> Create the necessary protocols as described in the protocol management section.</li> </ul>"},{"location":"data-collection/setup/#hardware-installation-of-instruments","title":"Hardware: installation of instruments","text":"<p>Below is the overall setup of the instruments:</p> Stable configuration of the pyshiological and eye-tracking recording elements. Most of the recording devices are located on a rack in the access panel cupboard of the Control Room."},{"location":"data-collection/setup/#install-the-biopac","title":"Install the BIOPAC","text":"<ul> <li>      Set up the line frequency switches on the back of the BIOPAC amplifier depending on your country frequency to reduce noise.     Both switches should be DOWN if your country's line frequency is 50Hz.     Both switches should be UP if your country's line frequency line is 60Hz.</li> <li> Check that the RB (DA100C) and ECG (ECG100C) channels are set to channel 1 and channel 2, respectively.     </li> <li> Connect the MP160, SPT100D, AMI100C, DA100C, and ECG100C together if it has not been done yet.</li> <li> Plug in the Ethernet (the plug is on the back side of the BIOPAC), and leave it ready to connect the recording PC.     </li> <li> Ensure that the Mode switch of the MMBT-S Trigger Interface Box adapter (pink color box) is set on the P position.</li> <li> Connect the micro-USB B end of a long USB-A to micro-USB B cable into the appropriate input socket of the MMBT-S Trigger Interface Box adapter (N-shaped pink-color box).     Leave the USB-A open end accessible for connection to the stimuli presentation computer \u2588\u2588\u2588.</li> <li> <p> Connect the parallel cable to the 25-pin socket at the back of the SPT100D of the BIOPAC and to the parallel port of the MMBT-S (N-shaped pink box).</p> Connection of digital signals </li> <li> <p> Pass the RB's tube (AFT30-XL 10 m) through the access cylinder with the help of one person inside the Scanning Room.</p> </li> <li> Connect the RB's tube proximal end to the TSD160A's inlet marked with the minus (-) symbol.</li> <li> Connect the parallel port end of the cable that comes out of the MECMRI-2 amplifier to the filter welded onto the access panel.     </li> <li> Inside the Scanning Room, connect the MRI-compatible cable where the ECG leads will be connected to the parallel port weld to the access panel.</li> <li> Plug the power cord to the back socket of the BIOPAC and onto the multiple power socket extension.</li> </ul>"},{"location":"data-collection/setup/#install-the-ga","title":"Install the GA","text":"<ul> <li> Set the GA on the middle shelf of the rack.</li> <li> Pass the RB's short tube (AFT30-L 4 m) through the access cylinder with the help of someone else at the Scanning Room end.</li> <li> Connect the proximal end of the composite oxygen tube to one inlet of DM-060-24 desiccant chamber.</li> <li> Connect the free inlet of the dessicant chamber to the MLA0343 drying tube.</li> <li> <p> Remove the cap of the gas input (Sample In, front panel of the GA).     </p> </li> <li> <p> Connect the MLA0110 flow valve to the gas inlet of the GA.</p> <p>The MLA0110 flow valve MUST be replaced after some ten sessions.</p> </li> <li> <p> Connect the MLA0343 drying tube to the MLA0110 flow valve.     </p> </li> </ul> <p>The MLA0343 drying tube and the DM-060-24 desiccant chamber MUST be replaced when their inside color turns into pink.</p> <ul> <li> Plug the power cord to the back socket of the GA and onto the multiple power socket extension.     </li> <li> Connect the coaxial end of one BNC-jack cable to the CO<sub>2</sub> output in the back of the GA and connect the other end (jack plug) into the input end of the INISO/A filter.     </li> <li> Connect one end (RJ-11 to RJ-11) to the output of the INISO/A filter you just installed.</li> <li> Connect the other RJ-11 end into channel 3 of the AMI100C module.     </li> <li> Connect the coaxial end of the other BNC-jack cable to the O<sub>2</sub> output in the back of the GA and connect the other end (jack plug) into the input end of the INISO/A filter.</li> <li> Connect one end (RJ-11 to RJ-11) to the output of the INISO/A filter you just installed.</li> <li> Connect the other RJ-11 end into channel 4 of the AMI100C module.</li> </ul>"},{"location":"data-collection/setup/#install-the-et-computer","title":"Install the ET computer","text":"<ul> <li> Install the ET computer on the bottom shelf.</li> <li> Install the screen and peripherals (keyboard, mouse) on the top shelf, and connect them to the PC.</li> <li> Connect the power cord of the PC to the power multiple-socket extension.</li> <li> <p> Pass the optic fiber (orange wire) and the power cable (the one with a fabric sheet) through the access cylinder with the help of someone else inside the Scanning Room.</p> This operation requires two people <p>One person will feed the cables from the control room interface of the access cupboard. The other person will gently pull the two cables from inside. Both people will lift the cable to avoid its abrasion with the edges of the metallic cylinder, which is the passage between exterior and interior of the scanner room. Once the sliding of the cable is finished, leave the extremities inside the scanner room in the left-top corner, far from the scanner because they are magnetic.</p> <p></p> </li> </ul>"},{"location":"data-collection/setup/#cleanup-inside-the-scanning-room","title":"Cleanup inside the scanning room","text":"<p>Several tubes and cables will be now hanging from the access cylinder at the Scanning Room end.</p> <ul> <li> Roll these cables and tubes and store them organized in the cupboard, ready for their connection when needed.</li> <li> The RB may be stored with these cables and tubes to.</li> </ul>"},{"location":"data-collection/setup/#software","title":"Software","text":""},{"location":"data-collection/setup/#preparing-the-physiology-recording-laptop","title":"Preparing the physiology recording laptop (\u2588\u2588\u2588)","text":"<ul> <li> Ensure you have the AcqKnowledge software USB license key. Plug the USB key to the multiport adapter for Mac and plug that adapter to the computer \u2588\u2588\u2588 as shown in the picture below. It needs to stay plugged at all times during the acquisition. </li> <li> Install the BIOPAC recording software (AcqKnowledge).</li> <li> Open the AcqKnowledge software.</li> <li> <p> Create a template graph file (<code>EXP_BASE.gtl</code>)</p> <p>Creating the AcqKnowledge's template graph file</p> <ul> <li> Creating a graph file requires the BIOPAC system powered up and connected to the \u2588\u2588\u2588 computer.</li> <li> Add the RB module<ul> <li> Check the channel on top switch of the unit: the DA100C MUST be set on channel 1.</li> <li> Under the tab Analog, click on Add new module.</li> <li> Find the name of the BIOPAC unit corresponding to the DA100C.</li> <li> Set the module settings (gain, filters, etc.) corresponding to those of the configuration switches in the front of the module.</li> <li> When prompted to enter the calibration points, map the interval [-5, 0] to [0, 10]. You invert the sign of the interval for the interpretation to be more clear.</li> </ul> </li> <li> Add the ECG module<ul> <li> Check the channel on top switch of the unit: the ECG100C MRI MUST be set on channel 2.</li> <li> Under the tab Analog, click on Add new module.</li> <li> Find the name of the BIOPAC unit corresponding to the ECG100C.</li> <li> Set the module settings (gain, filters, etc.) corresponding to those of the configuration switches in the front of the module.</li> <li> When prompted to enter [calibration?], for the ECG you should map the interval ?? to ??.</li> </ul> </li> <li> Add the GA module<ul> <li> Confirm that the CO<sub>2</sub> output of the GA is connected through the ANISO filter to the channel 3 of the AMI100C module.</li> <li> Under the tab Analog, click on Add new module.</li> <li> Select Custom and then indicate it is connected to channel 3 by selecting AMI/HLT - in3.</li> <li> When prompted to enter the calibration points, map the interval [0.03, 1.0] to [0, 10.0].</li> </ul> </li> <li> Add the Digital inputs<ul> <li> Under the tab Digital, click on Add new module.</li> <li> The parallel cable feeds into ports D8-D15.</li> </ul> </li> <li> Configure the sampling frequency</li> <li> Configure the experiment length (at least 2.5 hours)</li> <li> Configure whether you want to collect directly to hard disk and autosave settings</li> <li> Save the experiment, making sure you choose a \"graph template file\" (with extension <code>.gtl</code>)</li> </ul> </li> </ul>"},{"location":"data-collection/setup/#preparing-the-stimuli-presentation-laptop","title":"Preparing the stimuli presentation laptop (\u2588\u2588\u2588)","text":"<p>The stimuli presentation laptop and any other box you want to use for debugging and development will require a few additional software packages to be available.</p>"},{"location":"data-collection/setup/#installing-eyelink-eye-tracker-software","title":"Installing EyeLink (eye tracker software)","text":"<p>The EyeLink software MUST be installed BEFORE Pychopy</p> <ul> <li> <p> Log on \u2588\u2588\u2588 with the username \u2588\u2588\u2588 and password <code>*****</code>.</p> </li> <li> <p> Enable Canonical's universe repository with the following command:     <pre><code>sudo add-apt-repository universe\nsudo apt update\n</code></pre></p> </li> <li> Install and update the ca-certificates package:     <pre><code>sudo apt update\nsudo apt install ca-certificates\n</code></pre></li> <li> Add the SR Research Software Repository signing key:     <pre><code>curl -sS https://apt.sr-research.com/SRResearch_key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/sr-research.gpg\n</code></pre></li> <li> Add the SR Research Software Repository as an Aptitude source:     <pre><code>sudo add-apt-repository 'deb [arch=amd64] https://apt.sr-research.com SRResearch main'\n</code></pre></li> <li> Install the EyeLink Developers Kit:     <pre><code>sudo apt install eyelink-display-software\n</code></pre></li> <li> Install the EyeLink Data Viewer:     <pre><code>sudo apt install eyelink-dataviewer\n</code></pre></li> </ul>"},{"location":"data-collection/setup/#installing-our-synchronization-server","title":"Installing our synchronization server","text":"<p>During the session, we run a synchronization server that acts as a hub for the signals (triggers, task events, etc.) that define the experiment. For the best experience, we daemonize the synchronization service (meaning, we make it a service of the operative system that runs in the background). To install it as a service, please follow the documentation in the appendix</p> <ul> <li> Locate the latest version of the synchronization service on your system.     It is within the SOPs repository, at <code>&lt;path&gt;/code/synchronization/forward-trigger-service.py</code>.</li> <li> Install the necessary libraries as root:     <pre><code>sudo python3 -m pip install -r &lt;path&gt;/code/synchronization/requirements.txt\n</code></pre></li> <li> <p> Test the service is properly installed:     <pre><code>sudo python3 code/synchronization/forward-trigger-service.py --disable-mmbt-check\n</code></pre></p> <p>Use the <code>--disable-mmbt-check</code> flag only if you do not plan to connect the MMBT-S trigger box</p> </li> <li> <p> Test operation with our test client:</p> <p>Check the server's log file at <code>/var/log/forward-trigger-service.log</code></p> <p>Open a separate terminal on a separate window Then, open and follow the log file: <pre><code>less +F /var/log/forward-trigger-service.log\n</code></pre></p> <p>Return to the original terminal, keeping the other window visible and execute: <pre><code>python code/synchronization/forward-trigger-client.py\n</code></pre></p> <p>The log file should now have added two lines like: <pre><code>2023-10-12 14:44:31.788 - INFO - Data received: &lt;b'\\x02'&gt;\n2023-10-12 14:44:31.788 - INFO - Forwarded &lt;b'\\x02'&gt;\n</code></pre></p> </li> </ul> Testing the service without the MMBT-S connected <p>Testing the service without the MMBT-S trigger box connected requires emmulating <code>/dev/ttyACM0</code>:</p> <ul> <li> Ensure <code>socat</code> and <code>screen</code> are installed (if not already):       <pre><code>sudo apt-get update\nsudo apt-get install socat screen\n</code></pre></li> <li> Create a virtual serial port and establish a symbolic link to <code>/dev/ttyACM0</code> using the following command:       <pre><code>sudo socat PTY,link=/tmp/virtual_serial_port PTY,link=/dev/ttyACM0,group-late=dialout,mode=666,b9600\n</code></pre></li> <li> <p> With <code>screen</code>, listen to the new virtual serial port:       <pre><code>screen /dev/ttyACM0\n</code></pre></p> <p>!!! tip \"Alternatively, you can check the server's log file at <code>/var/log/forward-trigger-service.log</code>\"</p> </li> <li> <p> Press s and verify that <code>^A</code> appears in the screen terminal.</p> </li> </ul>"},{"location":"data-collection/setup/#prepare-the-psychopy-experiments","title":"Prepare the Psychopy experiments","text":"<p>The appendix has some guides on how to install Psychopy.</p> <ul> <li> Log on \u2588\u2588\u2588 with the username \u2588\u2588\u2588 and password <code>*****</code>.</li> </ul> Make sure to load the correct environment <ul> <li> Deactivate conda (if active):     <pre><code>conda deactivate\n</code></pre></li> <li> Load the new virtual environment:     <pre><code>source $HOME/psychopyenv/bin/activate\n</code></pre></li> </ul> <ul> <li> Fork the HCPh-fMRI-tasks repository under your user on GitHub.</li> <li> Clone the HCPh-fMRI-tasks repository:     <pre><code>git clone git@github.com:&lt;your-gh-username&gt;/HCPh-fMRI-tasks.git\n</code></pre></li> <li> Set-up the original repository as upstream remote:     <pre><code>git remote add upstream git@github.com:theaxonlab/HCPh-fMRI-tasks.git\n</code></pre></li> <li> Open Psychopy and (optionally) a experiment file corresponding to a task by typing the following command in the terminal:     <pre><code>psychopy --no-splash -b task-qct_bold.psyexp\n</code></pre></li> <li> For each task, check the following:<ul> <li> <code>task-qct_bold.psyexp</code> (quality-control task, QCT):<ul> <li> time it to confirm the length, and</li> <li> check the task runs properly.</li> </ul> </li> <li> <code>task-rest_bold.psyexp</code> (resting-state fMRI):<ul> <li> time it to confirm the length, and</li> <li> check that the movie is played.</li> </ul> </li> <li> <code>task-bht_bold.psyexp</code> (breath-holding task, BHT):<ul> <li> time it to confirm the length, and</li> <li> check the task runs properly.</li> </ul> </li> <li> <code>task-fixation_dwi.psyexp</code> (fixation point during DWI):<ul> <li> time it to confirm the length, and</li> <li> check the task runs properly.</li> </ul> </li> </ul> </li> </ul>"},{"location":"data-collection/setup/#calibration-of-the-ga","title":"Calibration of the GA","text":"<p>The AcqKnowledge software must be re-calibrated every two months, approximately.</p> A gas mixture bottle with a known CO<sub>2</sub> and O<sub>2</sub> concentrations is necessary <p>CO<sub>2</sub> concentration must be between 5% and 10%, while O<sub>2</sub> within 5% and 21%. A second reference mixture is necessary, and room air can be used, knowing that atmospheric contents by volume are 0.039 \u00b10.001% for CO<sub>2</sub> and 20.946 \u00b10.003% for O<sub>2</sub>.</p> <ul> <li> Connect the BIOPAC to the Physiology recording laptop (\u2588\u2588\u2588) as described in this section.</li> <li> Connect the AcqKnowledge License Key into a USB Port of the Physiology recording laptop (\u2588\u2588\u2588).</li> <li> Open AcqKnowledge software on the Physiology recording laptop (\u2588\u2588\u2588).</li> <li> Open the template graph file (<code>EXP_BASE.gtl</code>)</li> <li> Edit the configuration of the inputs 3 (connected to the CO<sub>2</sub> output of the GA) and 4 (connected to the O<sub>2</sub> output of the GA).     Lower and upper calibration points can be set by sampling the input a number of times with the AcqKnowledge utility.</li> <li> Overwrite the template graph file <code>EXP_BASE.gtl</code>.</li> </ul>"},{"location":"data-collection/tear-down/","title":"Session tear-down","text":""},{"location":"data-collection/tear-down/#showing-the-participant-out","title":"Showing the participant out","text":"<ul> <li> <p> Enter the scanner room, and announce yourself to the participant:</p> <p>Hi [NAME], thanks a lot for your collaboration. We will get you out in a second.</p> </li> <li> <p> Extract the participant following the standard procedure.</p> </li> <li> Remove the upper side of the head coil:<ul> <li> Unplug the head coil from the bed connector.</li> <li> Lift the lever that releases the upper part of the coil and put it aside (e.g., inside the bore or on a chair next to the scanner).</li> </ul> </li> <li> Remove the tape band across the coil and touching the participants forehead.</li> <li> Lift the nasal cannula and put it away so the participant can sit down.</li> <li> Assist the participant to remove the padding elements around their head.</li> <li> Help the participant sit down.</li> <li> Instruct the participant to remove the earplugs and dispose of them.</li> <li> <p> Ask them about the experience:</p> Get feedback about the session from the participant <p>[NAME], how was your experience? Have you been able to feel comfortable throughout the session? What advice, indication do you feel we could've provided you for a better experience?</p> </li> <li> <p> Disconnect the tube from the RB and then lift the velcro attachment to remove the RB.</p> </li> <li> Prepare the belt on the bed to be removed from the room when you show the participant out.</li> <li> Help the participant carefully remove the ECG leads.</li> <li> Disconnect the three ECG terminals from the cable and put them in their pouch.</li> <li> Disconnect the last section of the cannula and dispose of it in the trash can.</li> <li> Help the participant step down and accompany them out to the control room.</li> <li> Help the participant recover their personal belongings and change clothes if necessary.</li> <li> Solicit more feedback on participant's comfort for future sessions.</li> <li> Ask the participant to fill out the <code>After scan</code> part of the covariates collection on the issue you opened earlier.</li> <li> Solicit tickets and receipts for transportation.</li> <li> Give the participant the corresponding compensation for the participation and transportation.</li> <li> Ask the participant to sign the receipt of the amount of the financial compensation.</li> </ul>"},{"location":"data-collection/tear-down/#clearing-up-the-scanning-room","title":"Clearing up the Scanning Room","text":""},{"location":"data-collection/tear-down/#et-arm-et-cables-infrared-mirror-and-stimuli-screen","title":"ET arm, ET cables, infrared mirror and stimuli screen","text":"<ul> <li> Unplug the two cables (signal and power) connected to the ET arm.</li> <li> Roll the cables and put them in the cupboard inside the Scanning room.</li> <li> Remove the mirror frame from its rails mounted on the head coil and lay it on the bed.</li> <li> <p> Put the gloves on and cover the infrared mirror for storage.</p> <p>The infrared mirror MUST be manipulated with clean gloves at all times.</p> </li> <li> <p> Take the projector's screen off and store it in its designated shelf.</p> </li> <li> Disconnect the ECG cable from the filter of the access panel, roll the cable.</li> <li> Roll the RB tube and the GA tube and store them in the cupboard.</li> </ul>"},{"location":"data-collection/tear-down/#readying-the-scanner-for-the-next-session","title":"Readying the scanner for the next session","text":"<p>Every setting altered for the experiment MUST be put back to its original status at the end of the experiment (e.g., position of the bed, coil, emergency button, padding elements, etc.)</p> <ul> <li> <p> Put the used bed-sheet and the blanket inside the soiled linen bag.</p> <p>Put them away in the trash if they are disposable</p> </li> <li> <p> Dispose all single-use sanitary protections.</p> </li> <li> Put the pillows back in their designated storage places.</li> <li> Remove the head coil and put it in the scanner's bore.</li> <li> Remove the back padding elements and put them back in their designated storage.</li> <li> Reinstall the spine coil.</li> <li> <p> Wipe the bed and the head coil (bottom and upper parts).</p> <p>Cleaning wipes are available on shelf in the Scanning Room.</p> </li> <li> <p> Lock the head coil back with its bottom part without plugging the connectors.</p> </li> <li> <p> Put the head coil away with the other head-coils on the shelf next to the scanner.</p> <p>If the next user is already there or you know the current coil will be also used in the next session, plug it back into the bed socket.</p> </li> <li> <p> Return the bed to its Home position by pressing the  button (more info).</p> </li> <li> Take the ET arm outside to the Control Room and place it in a stable place.</li> <li> Take the infrared outside to the Control Room and store it in the ET/fMRI box.</li> <li> Take the plexiglass panel outside to the control room.</li> <li> Exit and close the external door.</li> </ul>"},{"location":"data-collection/tear-down/#clearing-up-the-control-room","title":"Clearing up the Control Room","text":""},{"location":"data-collection/tear-down/#finalize-the-boxing-of-the-et-elements","title":"Finalize the boxing of the ET elements","text":"<ul> <li> Put the lens cover.</li> <li> Unscrew the ET lens, while ALWAYS keeping one hand under the lens while screwing/unscrewing it and put it back into its pouch.     </li> <li> <p> Store the ET arm in its designated box.</p> <p>REMEMBER | the infrared mirror is inside that box already: DO NOT crush the mirror.</p> </li> <li> <p> Store the fMRI box back in room \u2588\u2588\u2588.</p> </li> </ul>"},{"location":"data-collection/tear-down/#finalize-the-boxing-of-other-physiological-recording-instruments","title":"Finalize the boxing of other physiological recording instruments","text":"<ul> <li> Disconnect the bundle of cables coming out of the access panel in the Control Room (Ethernet from the ET PC, USB from MMBT-S Interface and power strip cable plug).</li> <li> Roll the bundle and place it at the bottom shelf.</li> <li> Disconnect the Ethernet cable of the BIOPAC from the \u2588\u2588\u2588 computer.</li> <li> Disconnect the AcqKnowledge USB License Key from the \u2588\u2588\u2588 computer and bag it (pink bag next to the BIOPAC unit).</li> <li> Retrieve the \u2588\u2588\u2588 computer from the closet and put it on the control desk.<ul> <li> Retrieve the power cord and plug if they are set.</li> </ul> </li> </ul>"},{"location":"data-collection/tear-down/#finalizing-the-support-laptops","title":"Finalizing the support laptops","text":"<ul> <li> Unplug from \u2588\u2588\u2588 the USB cable coming from the SyncBox.</li> <li> Switch the SyncBox off, and make sure you leave it connected exactly as you found it.</li> <li> Unplug from \u2588\u2588\u2588 the HDMI cable from the display switch.</li> <li> Check that you leave the display switch as you found it.</li> <li> Switch off the \u2588\u2588\u2588 computer.</li> <li> Exit the Amphetamine session and lock the screen of the \u2588\u2588\u2588 computer.</li> </ul>"},{"location":"data-collection/tear-down/#switching-off-the-projector","title":"Switching off the projector","text":"<ul> <li> Take the plexiglass panel back into room \u2588\u2588\u2588.</li> <li> Switch the projector off before exiting room \u2588\u2588\u2588.</li> </ul> <p>If no more sessions are scheduled afterward:</p> <ul> <li> Turn off the MRI system.</li> </ul>"},{"location":"data-collection/tear-up/","title":"Session preparation","text":"<p>The following section describes how to prepare the session on the day of scan, BEFORE the participant arrives.</p>"},{"location":"data-collection/tear-up/#setting-up-experiment-instruments-in-the-control-room","title":"Setting up experiment instruments in the Control Room","text":"<p>Switching the GA on early is critical to allow time for its warm-up period (~25 min)</p> <ul> <li> Arrive to the Control Room at least 30 min ahead the session start time.</li> <li> If necessary, boot the scanner up</li> <li> Unroll the bundle of cables that will cross the corridor (one RJ-45/Ethernet-ended for the ET, one mini-USB B -ended, and one standard Swiss power plug, i.e., type J) and stick it to the floor.</li> <li> Connect the standard type J plug of the bundle to a suitable power outlet.     This plug comes from the multiple-socket power cord extension feeding the physiological recording hardware.</li> </ul>"},{"location":"data-collection/tear-up/#setting-up-the-ga","title":"Setting up the GA","text":"<ul> <li> <p> Check the color of the MLA0343 drying tube and the DM-060-24 desiccant chamber.</p> <p>The MLA0343 drying tube and the DM-060-24 desiccant chamber MUST be replaced when their inside color turns into pink.</p> </li> <li> <p> Remove the cap from the exhaust outlet and check it is free of obstruction.</p> <p>An obstructed exhaust can damage the device!</p> </li> <li> <p> Check that the pump switch is OFF (upward), set it off if needed.</p> </li> <li> <p> Check that the cap on the Sample In inlet is removed and that the MLA0110 valve is connected to it.</p> <p>The pump switch MUST BE OFF when the cap is on and when switching the GA on</p> </li> <li> <p> Turn the device ON (back panel switch).</p> </li> <li> Set the flow control knob at the front of the GA to the maximum.</li> </ul>"},{"location":"data-collection/tear-up/#setting-up-the-biopac-system-and-physiological-recording-sensors","title":"Setting up the BIOPAC system and physiological recording sensors","text":"<ul> <li> Disable the Wi-Fi connection on the physiology recording computer (\u2588\u2588\u2588).</li> <li> Plug the AcqKnowledge software USB license key to the multiport adaptor.</li> <li> Plug the open end of the data link from the BIOPAC (RJ-45 to RJ-45, Ethernet) to the RJ-45 socket of the multiport adaptor.</li> <li> <p> Plug the multiport adaptor to the physiology recording computer (\u2588\u2588\u2588) as shown in the picture below.</p> <p></p> </li> </ul> <p>The data link and the license key need to stay plugged at all times during the acquisition</p> <ul> <li> Turn BIOPAC's MP160 on with the switch on its back panel.</li> <li> Open the AcqKnowledge software</li> <li> Select Create new graph from recently used file \u2937 select <code>EXP_BASE.gtl</code> and click Open.</li> <li> Initiate an Amphetamin session to prevent the computer from going to sleep or locking the screen:<ul> <li> Click on the pill icon on the Mac's status bar</li> <li> Select New session \u2937 While is running \u2937 Acqknowledge.</li> </ul> </li> </ul>"},{"location":"data-collection/tear-up/#setting-up-the-stimuli-presentation-and-synchronization-laptop","title":"Setting up the stimuli presentation and synchronization laptop","text":"<ul> <li> Place the laptop (\u2588\u2588\u2588) on the designated desk.</li> <li> <p> Connect the \u2588\u2588\u2588 laptop to the screen switch box (see picture below) with the corresponding HDMI cable. This should project your screen on the screen of CHUV's tower \u2588\u2588\u2588.     </p> </li> <li> <p> Connect the RJ-45/Ethernet cable from the ET computer into the RJ-45 socket of the stimuli laptop (\u2588\u2588\u2588).</p> </li> <li> Plug the power adaptor to the laptop, and the adaptor to the power outlet on the wall.</li> <li> <p> Switch the laptop on.</p> The stimuli laptop (\u2588\u2588\u2588) MUST be turned on AFTER the HDMI cable is connected <p>Otherwise, the monitors will not correctly be identified by Ubuntu and Psychopy will likely fail to present the stimuli in the projector's screen.</p> <p>If the monitor does not automatically switch the source of the screen, you can use the button below to switch it.</p> <p></p> </li> <li> <p> Log-in with the username \u2588\u2588\u2588 and password <code>*****</code>.</p> </li> <li> Switch the SyncBox on.</li> <li> <p> Connect the SyncBox to the laptop with the USB cable.     It is normally plugged into CHUV's stimuli workstation, it must be re-plugged in there after the session.</p> </li> <li> <p> Connect the MMBT-S Trigger Interface Box adapter (which is the USB-A cable of the bundle you initially set across the corridor) to one of the USB ports of the laptop \u2588\u2588\u2588.</p> <p>The MMBT-S MUST be connected to the laptop AFTER the trigger USB cable coming from the SyncBox. </p> </li> </ul> <p>Your laptop connections should now look like this:</p> <p></p> <ul> <li> Configure the display settings of the stimuli presentation laptop \u2588\u2588\u2588 in extended mode, with the secondary screen at a resolution of 800\u00d7600.</li> <li> <p> Check that the service to synchronize the triggers is up with <code>sudo systemctl status forward-trigger</code>.</p> <p>If the service is down, manually force its start</p> <ul> <li> Run <code>sudo systemctl start forward-trigger</code></li> <li> Recheck the status with <code>sudo systemctl status forward-trigger</code>.</li> </ul> <p>These commands are executed with <code>sudo</code></p> <p>The console will prompt you for the common user password: <code>*****</code></p> </li> <li> <p> Open a terminal ( + t) and open the service's log in follow mode:     <pre><code>less +F /var/log/forward-trigger.log\n</code></pre></p> </li> </ul>"},{"location":"data-collection/tear-up/#check-synchronization","title":"Check synchronization","text":"<ul> <li> Hit the Start button of AcqKnowledge.</li> <li> Enter the Synchronization mode by selecting it and pushing the enter button .</li> <li> Hit the down arrow button  until you find Send triggerpulse to PC</li> <li> Push the enter button  every time you want to send an s character.</li> <li> Check that the \u2588\u2588\u2588 laptop types those triggers (e.g., on an open editor receiving keypresses, or the shell prompt, or looking at your open log).</li> <li> Check that the AcqKnowledge session running on ** is properly registering the trigger too in the corresponding digital channel.</li> </ul>"},{"location":"data-collection/tear-up/#finalize-setting-up","title":"Finalize setting up","text":"<ul> <li> Stop the AcqKnowledge recording and ready a new session.</li> <li> <p> Start a new SyncBox Synchronization session:</p> <ul> <li> Push the up arrow button  until you find Start Session</li> <li> Push the enter button  and the syncbox will be now waiting for the scanner's trigger signal to forward it.</li> </ul> </li> </ul>"},{"location":"data-collection/tear-up/#transitional-steps-before-entering-the-scanning-room","title":"Transitional steps before entering the Scanning Room","text":""},{"location":"data-collection/tear-up/#setting-up-the-projector","title":"Setting up the projector","text":"<p>If someone is already scanning, ask first if you can switch the projector on already</p> <ul> <li> Go to room \u2588\u2588\u2588, where the projector is installed.</li> <li> Switch the projector ON by hitting the power button, located on its right side.</li> <li> <p> Verify the aim of the projector's beam by looking through the tube into the Scanning Room.</p> The projector's position SHALL NOT be modified unless it is evidently off <p>Only in the case that the projector beam is not correctly targeting the projection screen inside the Scanning Room, which is possible if someone accidentally altered the configuration, you may adjust its position as follows:</p> <ul> <li> Adjust the projector tilt to center the projection if it does not properly aim the panel inside the scanner's bore.     E.g., change the height of the paper pile that supports it (see images, FENS papers).</li> </ul> The tube is the part through which you should check the quality of the projection </li> <li> <p> Verify the projection corresponds to the Psychopy laptop (\u2588\u2588\u2588) screen.</p> </li> <li> Before you exit room \u2588\u2588\u2588, grab the plexiglass panel where the ET arm will be placed inside the scanner.</li> <li> Take the panel to the Control Room.</li> </ul>"},{"location":"data-collection/tear-up/#prepare-the-et-arm","title":"Prepare the ET arm","text":"<ul> <li> Go to room \u2588\u2588\u2588 and bring the blue box labeled Eye-Tracker only for fMRI into the scanning room.     This box contains the ET arm with the camera and infrared lamp mounted on it, lenses, and the special infrared mirror.     The box should be found in the first cabinet on the left section of the cupboard.</li> <li> <p> Take the MR-compatible lens out its safe pouch inside the ET box.</p> The appropriate lens is found in a correspondingly labeled bag (left) and it is the only one with two gold screws (right). </li> <li> <p> Install the MR-compatible lens, after removing any other present lens.     If other lens is present, put it back into its plastic bag inside the lenses box after unscrewing and removal.</p> <p>The lens MUST be handled with care</p> <p></p> <ol> <li>The lens MUST be installed in the Control Room, BEFORE taking the ET arm inside the Scanner Room.</li> <li>One of your hands MUST be under the lens at all times while screwing/unscrewing it, to avoid accidentally dropping a lens.</li> <li>Screws holding the lens MUST be properly tightened at this point because the vibration of the scanner may loosen them and the screw(s) may drop during the session.</li> </ol> </li> <li> <p> Place the ET arm in a safe place in the Control Room until the plexiglass panel is ready.</p> </li> </ul>"},{"location":"data-collection/tear-up/#preparing-the-scanning-room","title":"Preparing the Scanning Room","text":"<p>Check with the previous user whether you can come in the Scanning Room</p>"},{"location":"data-collection/tear-up/#setting-up-the-et","title":"Setting up the ET","text":"<ul> <li> Bring the plexiglass panel inside the scanning room and place it at the end of the scanner's bore.     A sign indicates the top side that MUST face up.     The plastic feet must face down to avoid the panel to slide.     To ensure the repeatible positioning of the ET, place the end of the plexiglass such that its edge aligns with the edge of the illuminated MRI rails.</li> <li> Exit the Scanning Room and fetch the ET arm.</li> <li> <p> Enter the Scanning Room and place the ET arm on top of the plexiglass panel with the two posterior feet of the ET arm aligned within the two corner markers made of scotch tape.</p> <p>Hold the ET arm FIRMLY, because the magnetic field imposes some resistance.</p> </li> <li> <p> Unroll and connect the cables (two plugs for the black, one plug for the orange).     </p> </li> <li> Take the half-circle one-direction screen from the table behind the scanner and put it on the back of the scanner, behind the ET system (don't push the plexiglass yet)     </li> </ul>"},{"location":"data-collection/tear-up/#setting-up-the-coils","title":"Setting up the coils","text":"<ul> <li> If any head coil from the last exam is still plugged, remove it:<ul> <li> If it is the 64-channel coil, you can just temporarily move it into the scanner's bore.</li> <li> Otherwise, store it on the shelf where the other coils are and bring the 64-channel one in the proximity of the bed (e.g., inside the scanner's bore).     Make sure to remove other coil's fitting element.</li> </ul> </li> <li> Remove the spine coil by lifting the corresponding latch, then sliding it toward the head of the bed, lift it from the bed, and place it on the floor ensuring it is not obstructing any passage or unstable.</li> <li> Place the two back padding elements filling the spine coil socket.</li> <li> Place the 64-channel head-and-neck coil into its socket at the head end of the bed.</li> </ul>"},{"location":"data-collection/tear-up/#setting-up-the-physiological-recordings","title":"Setting up the physiological recordings","text":"<ul> <li> Cover the MRI bed with a clean sheet.</li> <li> Unroll the tubes (RB and respiratory gases) and cables (ECG), which will be stored in the access cupboard.</li> <li> Check that the composite tube to collect respiratory gases through the cannula does not have any bubbles.</li> <li> <p> Extend them (respiration probing tubes and ECG cable) through the floor in an \"L-shaped\" trajectory to the scanner's bore.     Use sticky tape to fix them to the floor.</p> <p>Minimize loosely hanging sections of the tube for the collection of respiratory gases.</p> <p>When the tubing is hanging, pressure waves may alter the recorded gas concentration.</p> </li> <li> <p> Connect the distal end of the extension tube to the cannula with a joint connector.</p> </li> <li> Leave the cannula on the bed ready for the participant.</li> <li> Prepare the RB (stored in the cupboard) and leave it on the bed.</li> </ul>"},{"location":"data-collection/tear-up/#attach-the-dedicated-infrared-mirror-to-the-coil","title":"Attach the dedicated infrared mirror to the coil","text":"<ul> <li> Exit the Scanning Room.</li> <li> Fit in a pair of new latex gloves.</li> <li> Extract the dedicated infrared mirror from the ET box, CAREFULLY.</li> <li> Remove the mirror protection EXTRA-CAREFULLY.</li> <li> Take the mirror, enter the Scanning Room, and lock the mirror onto the frame of the head-coil.</li> </ul> <p>If interested in the legacy protocol, check this section</p>"},{"location":"data-collection/tear-up/#final-checks-inside-the-scanning-room","title":"Final checks inside the scanning room","text":"<ul> <li> <p> Prepare padding: under-knee padding, neck-and-head padding, under-elbows padding, head-sides padding, top-head wedge padding.</p> <ul> <li> Wrap a sanitary cover around each padding.</li> <li> <p> Place a double neck-and-head padding inside the coil, to ensure the eyes are close to the coil's windows:</p> Padding should be chosen and adjusted to each participant depending on their head size so that their nose is only 1-2mm away from the anterior part of the coil. The anterior part of the head coil will be tight around the participant's nose, so ensure they are nonetheless comfortable. </li> </ul> </li> <li> <p> Prepare a blanket to cover the participant.</p> </li> <li> Prepare a new pair of earplugs.</li> <li> Connect the ECG leads to the hub and leave it prepared on the bed.</li> <li> Check the RB, ECG, and nasal cannula are prepared.</li> <li> <p> Completely disable the light inside of the scanner and the ventilation of the scanning room using the scanner's interface.</p> <p>Disable the light and ventilation to facilitate the best performance of the ET</p> </li> </ul>"},{"location":"data-collection/tear-up/#finalize-et-setup","title":"Finalize ET setup","text":"<ul> <li> Switch on the ET's PC using the power-on button at its front.</li> <li> Select \"Eyelink\" when given the option of which operating system to launch.</li> <li> Verify the IP address assigned to the Ethernet interface of the \u2588\u2588\u2588 laptop is correct.<ul> <li> Check the output of the following command and verify that IP/mask is 100.1.1.2/24, and the protocol is IP version 4.     <pre><code>ifconfig -a\n</code></pre></li> <li> Check whether the link is properly established.     The ET should respond to echos sent from a terminal with:     <pre><code>ping 100.1.1.1\n</code></pre></li> </ul> </li> </ul>"},{"location":"data-collection/tear-up/#documentation-and-secondary-instruments","title":"Documentation and secondary instruments","text":"<ul> <li> Prepare the informed consent form (first session only)</li> <li> Prepare an MRI safety screener (EN|FR)</li> <li> Prepare a pen and a receipt form that the participant will sign when they are given the compensation</li> <li> Check you have the AcqKnowledge software USB license key</li> <li> Prepare a pregnancy test (Only female participants on their first session)</li> <li> Prepare a thermometer</li> <li> Prepare a blood pressure meter</li> <li> Prepare scrubs and MR-compatible glasses if applicable</li> <li> Prepare a pack of sterile cotton gauze, a bottle of medical alcohol, the Nuprep skin preparation gel (white/blue tubes), and three new electrodes.</li> </ul>"},{"location":"data-collection/tear-up/#start-a-new-session-log-form","title":"Start a new session log form","text":"<p>Collect comments and annotations about the session using GitHub issues. A laptop should be available to fill the issue.</p> <ul> <li> Click this link, or alternatively</li> <li> manually open a GitHub Issue at the SOPs repository:<ul> <li> Under the section <code>Issues</code>, click on New issue</li> <li> This should lead you to a page that looks like this     <ul> <li> Click on Get started on the issue template <code>Scan session</code>.</li> </ul> </li> </ul> </li> <li> Modify the title of the issue by replacing <code>yyy</code> with the session index.     If you don't remember the session index of today, check the session index table.</li> <li> Verify that your phone is on ringing mode so the participants can reach you.</li> <li> Check the time regularly to be on time to meet with the participant at the predefined location</li> </ul>"},{"location":"data-collection/tear-up/#start-a-new-session-log-for-the-collection-of-covariates","title":"Start a new session log for the collection of covariates","text":"<ul> <li> Click this link, or alternatively</li> <li> <p> manually open a GitHub Issue at the questionnaire repository:</p> <ul> <li> Under the section <code>Issues</code>, click on New issue</li> </ul> </li> <li> <p> Fill the date of the scan as well as the PE for this session (accessible in the schedule)</p> </li> <li> <p> Fill in weather details of the scanning day based MeteoSwiss in 1003 Lausanne.</p> <ul> <li> Report the maximum and minimum temperature in degrees celsius.</li> <li> Report the wind speed at the time of scanning in km/h.</li> <li> Report the precipitation type and amount (in mm).</li> <li> Report the outside atmospheric pressure (in hPa) and relative humidity (in %).</li> <li> Report the hours of daylight (rounded to the number of hours).</li> </ul> How to find the precipitation information on MeteoSwiss <p>Here is what the MeteoSwiss interface looks like on a computer.     </p> <p>In the screenshot above, the information to be reported would be:</p> <ul> <li>Minimum outside temperature for the day of the scan (\u00b0C): 14\u00b0C</li> <li>Maximum outside temperature for the day of the scan (\u00b0C): 23\u00b0C</li> <li>Wind speed (km/h): 2.7 km/h</li> <li>Precipitation (mm): 0mm</li> <li>Hours of daylight (h): 11h (18:54-07:44=11:10h roundup)</li> </ul> <p>Scrolling down, you will find additional measurement values that look like:     </p> <p>Here the relevant additional information is:</p> <ul> <li>Current outside atmospheric pressure (hPa): 963 hPa</li> <li>Current outside relative humidity (%): 75.8%</li> </ul> </li> <li> <p> Fill in the details related to the MR and scanner room.</p> <ul> <li> Report the MR room temperature (\u00b0C) and relative humidity (%)</li> </ul> Location of the MR room thermometer <p>The thermometer in the MR room can be found on the left of the operator window when inside the scanner room (see below).</p> <p></p> <ul> <li> Report MR helium level (%)<ul> <li> In the top bar of the MR console, click on <code>System</code>&gt;<code>Control</code>.</li> <li> In the window that just opened, click on the section <code>MR Scanner</code>.</li> <li> Report Helium Fill Level in percentage.</li> </ul> </li> </ul> </li> </ul>"},{"location":"data-management/mriqc/","title":"QC of unprocessed data","text":""},{"location":"data-management/mriqc/#executing-mriqc","title":"Executing MRIQC","text":"<ul> <li> Run MRIQC.     <pre><code>#Assign the variable to the last session ID\nlastsession=01\ndatalad containers-run \\\n    --container-name mriqc \\\n    --input sourcedata \\\n    --output ./derivatives/mriqc-23.1.0 \\\n    \"{inputs} {outputs} participant --session-id ${lastsession} -w ${HOME}/tmp/hcph-derivatives/mriqc-23.1.0 --mem 40G\"\n</code></pre></li> <li> Push the new derivatives to the remote storage.     <pre><code>datalad push --to ria-storage\ndatalad push --to origin\n</code></pre></li> <li> Screen the T1w, DWI and BOLD visual reports</li> <li> Schedule an extra session after the initially-planned scanning period to reacquire it if either the dMRI or the RSfMRI quality is insufficient.</li> </ul>"},{"location":"data-management/physio-to-bids/","title":"Converting HCPh's physio into BIDS","text":"In\u00a0[1]: Copied! <pre>%matplotlib inline\n\nfrom pathlib import Path\nfrom json import dumps\nimport string\nimport numpy as np\nfrom scipy.signal import fftconvolve\nfrom matplotlib import pyplot as plt\nimport pandas as pd\n\nfrom bioread import read_file\n\nplt.rcParams[\"figure.figsize\"] = (20, 2.5)\n</pre> %matplotlib inline  from pathlib import Path from json import dumps import string import numpy as np from scipy.signal import fftconvolve from matplotlib import pyplot as plt import pandas as pd  from bioread import read_file  plt.rcParams[\"figure.figsize\"] = (20, 2.5) <p>In the file <code>schedule.tsv</code>, we will keep the lookup table of AcqKnowledge files generated and their corresponding session. Some sessions (like 13) required restarting AcqKnowledge or some other issue and produced several runs as a consequence, we'll need to have special care with those.</p> In\u00a0[2]: Copied! <pre>biopac_lookup = pd.read_csv(\"schedule.tsv\", sep='\\t', na_values=\"n/a\", dtype={\"Run\": \"Int8\"})\nbiopac_lookup\n</pre> biopac_lookup = pd.read_csv(\"schedule.tsv\", sep='\\t', na_values=\"n/a\", dtype={\"Run\": \"Int8\"}) biopac_lookup Out[2]: session day PE AcqKnowledge Run 0 1 2023-10-20 LR session2023-10-20T18:06:05.acq &lt;NA&gt; 1 2 2023-10-20 LR NaN &lt;NA&gt; 2 3 2023-10-21 LR session2023-10-21T09:07:18.acq &lt;NA&gt; 3 4 2023-10-21 RL session2023-10-21T11:12:24.acq &lt;NA&gt; 4 5 2023-10-22 PA session2023-10-22T09:36:48.acq &lt;NA&gt; 5 6 2023-10-22 PA session2023-10-22T11:22:53.acq &lt;NA&gt; 6 7 2023-10-23 LR session2023-10-23T19:31:18.acq &lt;NA&gt; 7 8 2023-10-23 RL session2023-10-23T21:18:42.acq &lt;NA&gt; 8 9 2023-10-24 AP session2023-10-24T19:24:56.acq &lt;NA&gt; 9 10 2023-10-24 RL session2023-10-24T21:24:40.acq &lt;NA&gt; 10 11 2023-10-25 AP session2023-10-25T20:20:54.acq 1 11 11 2023-10-25 AP session2023-10-25T21:22:50.acq 2 12 12 2023-10-25 PA NaN &lt;NA&gt; 13 13 2023-10-26 PA session2023-10-26T19:16:00.acq 1 14 13 2023-10-26 PA session2023-10-26T21:25:29.acq 2 15 13 2023-10-26 PA session2023-10-26T21:44:06.acq 3 16 14 2023-10-26 LR NaN &lt;NA&gt; 17 15 2023-10-27 AP session2023-10-27T19:09:15.acq &lt;NA&gt; 18 16 2023-10-27 RL session2023-10-27T21:01:57.acq &lt;NA&gt; 19 17 2023-10-28 PA session2023-10-28T17:19:04.acq &lt;NA&gt; 20 18 2023-10-28 LR session2023-10-28T19:18:02.acq &lt;NA&gt; 21 19 2023-10-29 PA session2023-10-29T17:15:43.acq &lt;NA&gt; 22 20 2023-10-29 RL session2023-10-29T19:08:34.acq &lt;NA&gt; 23 21 2023-10-30 RL session2023-10-30T19:08:03.acq &lt;NA&gt; 24 22 2023-10-30 AP session2023-10-30T20:56:42.acq &lt;NA&gt; 25 23 2023-10-31 AP session2023-10-31T19:26:31.acq &lt;NA&gt; 26 24 2023-10-31 AP session2023-10-31T21:35:54.acq &lt;NA&gt; 27 25 2023-11-01 RL session2023-11-01T19:19:20.acq &lt;NA&gt; 28 26 2023-11-01 PA session2023-11-01T21:08:31.acq &lt;NA&gt; 29 27 2023-11-02 AP session2023-11-02T19:27:03.acq &lt;NA&gt; 30 28 2023-11-02 RL session2023-11-02T21:05:57.acq &lt;NA&gt; 31 29 2023-11-03 PA session2023-11-03T19:12:36.acq &lt;NA&gt; 32 30 2023-11-03 AP NaN &lt;NA&gt; 33 31 2023-11-04 PA NaN &lt;NA&gt; 34 32 2023-11-04 AP NaN &lt;NA&gt; 35 33 2023-11-05 LR NaN &lt;NA&gt; 36 34 2023-11-05 LR NaN &lt;NA&gt; 37 35 2023-11-06 LR NaN &lt;NA&gt; 38 36 2023-11-06 RL NaN &lt;NA&gt; <p>Now, let's set some constants and extract the corresponding AcqKnowledge file. Update the <code>session</code> variable here to change what you are converting.</p> In\u00a0[3]: Copied! <pre>DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/BIOPAC\")\nBIDS_PATH = Path(\"/data/datasets/hcph\")\nRECALIBRATED_SESSION = 23\nFIRST_O2_SESSION = 11 #The cable to record O2 signal has been received midway through the acquisition\nMISSING_RB = (29, )\n\nparticipant = \"001\"\nsession = 28\nsession_excluded = False\n\nbiopac_session = biopac_lookup[biopac_lookup.session == session]\n\nif len(biopac_session) != 1:\n    raise RuntimeError\n\npe = biopac_session.PE.values[0]\n\nif session_excluded:\n    print(\"SESSION IS MARKED EXCLUDED!!!!!\")\n</pre> DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/BIOPAC\") BIDS_PATH = Path(\"/data/datasets/hcph\") RECALIBRATED_SESSION = 23 FIRST_O2_SESSION = 11 #The cable to record O2 signal has been received midway through the acquisition MISSING_RB = (29, )  participant = \"001\" session = 28 session_excluded = False  biopac_session = biopac_lookup[biopac_lookup.session == session]  if len(biopac_session) != 1:     raise RuntimeError  pe = biopac_session.PE.values[0]  if session_excluded:     print(\"SESSION IS MARKED EXCLUDED!!!!!\") <p>Prepare repeated metadata across JSON files. These JSON files may be consolidated at the top level of the BIDS structure for the most part.</p> In\u00a0[4]: Copied! <pre>CARD_JSON = {\n    \"Columns\": [\"ecg\"],\n    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n    \"ecg\": {\n        \"Description\": \"continuous measurements of Lead I electrocardiogram\",\n        \"Units\": \"mV\",\n        \"Model\": \"ECG100C MRI &amp; MECMRI-2 amplifier\",\n    },\n}\n\nRESP_JSON = {\n    \"Columns\": [\"belt\", \"CO2\", \"O2\"],\n    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n    \"belt\": {\n        \"Description\": \"continuous breathing measurement by negative differential pressure with a respiration belt\",\n        \"Units\": \"cm H20\",\n        \"Model\": \"DA100C TSD160A transducer\",\n    },\n    \"CO2\": {\n        \"Description\": \"continuous breathing measurement: absolute CO2 concentration\",\n        \"Units\": \"%\",\n        \"Model\": \"ML206\",\n        \"Manufacturer\": \"AD Instruments Pty. Ltd., Sydney, Australia\"\n    },\n    \"O2\": {\n        \"Description\": \"continuous breathing measurement: absolute O2 concentration\",\n        \"Units\": \"%\",\n        \"Model\": \"ML206\",\n        \"Manufacturer\": \"AD Instruments Pty. Ltd., Sydney, Australia\"\n    }\n}\n\nif session &lt; FIRST_O2_SESSION:\n    RESP_JSON.pop(\"O2\", None)\n    RESP_JSON[\"Columns\"].remove(\"O2\")\n    \nif session in MISSING_RB:\n    RESP_JSON.pop(\"belt\")\n    RESP_JSON[\"Columns\"].remove(\"belt\")\n</pre> CARD_JSON = {     \"Columns\": [\"ecg\"],     \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",     \"ecg\": {         \"Description\": \"continuous measurements of Lead I electrocardiogram\",         \"Units\": \"mV\",         \"Model\": \"ECG100C MRI &amp; MECMRI-2 amplifier\",     }, }  RESP_JSON = {     \"Columns\": [\"belt\", \"CO2\", \"O2\"],     \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",     \"belt\": {         \"Description\": \"continuous breathing measurement by negative differential pressure with a respiration belt\",         \"Units\": \"cm H20\",         \"Model\": \"DA100C TSD160A transducer\",     },     \"CO2\": {         \"Description\": \"continuous breathing measurement: absolute CO2 concentration\",         \"Units\": \"%\",         \"Model\": \"ML206\",         \"Manufacturer\": \"AD Instruments Pty. Ltd., Sydney, Australia\"     },     \"O2\": {         \"Description\": \"continuous breathing measurement: absolute O2 concentration\",         \"Units\": \"%\",         \"Model\": \"ML206\",         \"Manufacturer\": \"AD Instruments Pty. Ltd., Sydney, Australia\"     } }  if session &lt; FIRST_O2_SESSION:     RESP_JSON.pop(\"O2\", None)     RESP_JSON[\"Columns\"].remove(\"O2\")      if session in MISSING_RB:     RESP_JSON.pop(\"belt\")     RESP_JSON[\"Columns\"].remove(\"belt\") <p>We use the <code>bioread</code> package to load in the AcqKnowledge files.</p> In\u00a0[5]: Copied! <pre>session_data = read_file(str(DATA_PATH / biopac_session.AcqKnowledge.values[0]))\nchannels = session_data.channels\n</pre> session_data = read_file(str(DATA_PATH / biopac_session.AcqKnowledge.values[0])) channels = session_data.channels <p>Now, let's peek into the data. First, we check the frequency is 5 kHz. Then, we visualize the trigger channel and extract the onset location.</p> In\u00a0[6]: Copied! <pre>freq = session_data.channels[4].samples_per_second\ntimeseries = session_data.channels[4].time_index\n\nfreq, len(timeseries)\n</pre> freq = session_data.channels[4].samples_per_second timeseries = session_data.channels[4].time_index  freq, len(timeseries) Out[6]: <pre>(5000.0, 26252576)</pre> In\u00a0[7]: Copied! <pre>plt.plot(timeseries, session_data.channels[4].data);\n</pre> plt.plot(timeseries, session_data.channels[4].data); In\u00a0[8]: Copied! <pre>data = session_data.channels[4].data\ntrigger_events = np.hstack((0, np.diff(data)))\nplt.plot(timeseries, trigger_events);\n</pre> data = session_data.channels[4].data trigger_events = np.hstack((0, np.diff(data))) plt.plot(timeseries, trigger_events); In\u00a0[9]: Copied! <pre>trigger_onsets = trigger_events.copy()\ntrigger_onsets[trigger_onsets &lt; 0] = 0\nplt.plot(timeseries, trigger_onsets);\n</pre> trigger_onsets = trigger_events.copy() trigger_onsets[trigger_onsets &lt; 0] = 0 plt.plot(timeseries, trigger_onsets); <p>Let's extract the onset of each run. The following cell should show a number 4 as the output. If it is higher, manually delete onsets by index. If it is lower, do not delete onsets and check because this could be a partial file.</p> In\u00a0[10]: Copied! <pre>trigger_locations = np.hstack((0, np.argwhere(trigger_onsets &gt; 0)[:, 0]))\ntrigger_spacings = np.diff(trigger_locations)\n\n# 120s is 2m (the shortest task, QCT)\nbetween_seq = trigger_locations[1:][trigger_spacings &gt; freq * 20]\n\nseq_limits = np.zeros_like(trigger_onsets)\nseq_limits[between_seq] = 1\n\nplt.plot(timeseries, trigger_onsets);\nplt.plot(timeseries, seq_limits);\n\nprint(len(between_seq))\n</pre> trigger_locations = np.hstack((0, np.argwhere(trigger_onsets &gt; 0)[:, 0])) trigger_spacings = np.diff(trigger_locations)  # 120s is 2m (the shortest task, QCT) between_seq = trigger_locations[1:][trigger_spacings &gt; freq * 20]  seq_limits = np.zeros_like(trigger_onsets) seq_limits[between_seq] = 1  plt.plot(timeseries, trigger_onsets); plt.plot(timeseries, seq_limits);  print(len(between_seq)) <pre>6\n</pre> <p>If the correct triggers are preserved, the plot below should show an orange trigger at the beginning of the blocks we are interested in (DWI, QCT, rest, BHT) and maybe some additional blocks which we will remove manually below.</p> <p>We are not interested in extracting the physiological recordings during the fieldmap scans. Thus, we manually delete the trigger corresponding to the fieldmap blocks.</p> In\u00a0[\u00a0]: Copied! <pre># between_seq = np.delete(between_seq, (0, 1, 2, 4, 6, 7, 8))  # session 16\n# between_seq = np.delete(between_seq, (0, 3, 4))  # session 15\n# between_seq = np.delete(between_seq, (0, 1, 4, 5, -1))  # session 9\n# between_seq = np.delete(between_seq, (2, 3, -1))\n# between_seq = np.delete(between_seq, (0, 2, 3, 4, 5, 7, 8, 9))  # session 1\nbetween_seq = np.delete(between_seq, (2, 3))\n\nseq_limits = np.zeros_like(trigger_onsets)\nseq_limits[between_seq] = 1\n\nplt.plot(timeseries, trigger_onsets);\nplt.plot(timeseries, seq_limits);\n</pre> # between_seq = np.delete(between_seq, (0, 1, 2, 4, 6, 7, 8))  # session 16 # between_seq = np.delete(between_seq, (0, 3, 4))  # session 15 # between_seq = np.delete(between_seq, (0, 1, 4, 5, -1))  # session 9 # between_seq = np.delete(between_seq, (2, 3, -1)) # between_seq = np.delete(between_seq, (0, 2, 3, 4, 5, 7, 8, 9))  # session 1 between_seq = np.delete(between_seq, (2, 3))  seq_limits = np.zeros_like(trigger_onsets) seq_limits[between_seq] = 1  plt.plot(timeseries, trigger_onsets); plt.plot(timeseries, seq_limits); In\u00a0[12]: Copied! <pre>seq_onsets = [timeseries[i] for i in between_seq]\nseq_onsets\n</pre> seq_onsets = [timeseries[i] for i in between_seq] seq_onsets Out[12]: <pre>[797.3890303737443, 3146.4201198518617, 3516.1335339348007, 4803.284582964315]</pre> In\u00a0[13]: Copied! <pre>dummies = 87 * 2 + 29\n\nfirst_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[0])[0, 0] + dummies]\nt_0 = timeseries[first_trigger]\n\nfirst_timepoint = int(between_seq[0] - 600 * freq)\nt_start = timeseries[first_timepoint]\n\nlast_timepoint = between_seq[1] if len(between_seq) &gt; 1 else len(timeseries) - 1\nt_stop = timeseries[last_timepoint]\n</pre> dummies = 87 * 2 + 29  first_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[0])[0, 0] + dummies] t_0 = timeseries[first_trigger]  first_timepoint = int(between_seq[0] - 600 * freq) t_start = timeseries[first_timepoint]  last_timepoint = between_seq[1] if len(between_seq) &gt; 1 else len(timeseries) - 1 t_stop = timeseries[last_timepoint] <p>Because DWI and trigger have both the same sampling frequency, this below could be simpler, but let's keep it to apply it later with other signals with different frequency. Basically, we convert trigger indexes to time, and then, using the timeseries of the particular channel, we find the what that trigger index would be, had the trigger timeseries been acquired at this other channel frequency instead.</p> In\u00a0[14]: Copied! <pre>ch_index = 1\nchannels = session_data.channels\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\ndwi_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\ndwi_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\ndwi_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[dwi_idx_start:dwi_idx_stop] - dwi_onset\ndwi_ch_data = ch_data[dwi_idx_start:dwi_idx_stop]\ndwi_trigger = data[first_timepoint:last_timepoint]\ndwi_idx_start, dwi_idx_stop, dwi_onset, x_sec[0], x_sec[-1], len(x_sec)\n</pre> ch_index = 1 channels = session_data.channels ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  dwi_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] dwi_idx_start = (np.abs(ch_timeseries - t_start)).argmin() dwi_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[dwi_idx_start:dwi_idx_stop] - dwi_onset dwi_ch_data = ch_data[dwi_idx_start:dwi_idx_stop] dwi_trigger = data[first_timepoint:last_timepoint] dwi_idx_start, dwi_idx_stop, dwi_onset, x_sec[0], x_sec[-1], len(x_sec) Out[14]: <pre>(986945,\n 15732100,\n 827.8770315350779,\n -630.4880240162345,\n 2318.5428883167765,\n 14745155)</pre> <p>Let's now plot the ECG (blue) and trigger (orange) at the beginning of the DWI (at $t=0$, marked by the red tick). It is clear how the ECG signal has been collected for a long while before the DWI, and then, at about 30 sec before the DWI first orientation onset, we see how the triggers corresponding to each slice of calibration kick in. There are 2 volumes $\\times$ 87 slices/volume (total 174 onsets) that are very fast at the beginning, followed by 29 triggers at a lower rate (one \"dummy\" or reference volume, acquired with the same SMS factor 3 of the rest of the DWI).</p> In\u00a0[15]: Copied! <pre>plt.plot(x_sec, dwi_ch_data)\nplt.plot(x_sec, dwi_trigger / 50)\nplt.vlines(0, -0.4, 0.4, colors=\"r\")\nplt.xlim((-40, 1))\n</pre> plt.plot(x_sec, dwi_ch_data) plt.plot(x_sec, dwi_trigger / 50) plt.vlines(0, -0.4, 0.4, colors=\"r\") plt.xlim((-40, 1)) Out[15]: <pre>(-40.0, 1.0)</pre> In\u00a0[16]: Copied! <pre>dwi_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"dwi\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_acq-highres_dir-{pe}_recording-cardiac_physio.tsv.gz\"\ndwi_sidecar = CARD_JSON.copy()\ndwi_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n(dwi_cardio_filepath.parent / dwi_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(dwi_sidecar, indent=2))\n\npd.DataFrame({\"ecg\": dwi_ch_data}).to_csv(\n    dwi_cardio_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> dwi_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"dwi\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_acq-highres_dir-{pe}_recording-cardiac_physio.tsv.gz\" dwi_sidecar = CARD_JSON.copy() dwi_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], }) (dwi_cardio_filepath.parent / dwi_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(dwi_sidecar, indent=2))  pd.DataFrame({\"ecg\": dwi_ch_data}).to_csv(     dwi_cardio_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) <p>Let's move on to the respiration belt.</p> In\u00a0[17]: Copied! <pre>dwi_resp_data = {}\n\nch_freq = channels[0].samples_per_second\nch_timeseries = channels[0].time_index\nch_data = channels[0].data\n\ndwi_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\ndwi_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\ndwi_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[dwi_idx_start:dwi_idx_stop] - dwi_onset\ndwi_resp_data[\"belt\"] = ch_data[dwi_idx_start:dwi_idx_stop]\n\nassert channels[2].samples_per_second == ch_freq\nif session &gt;= FIRST_O2_SESSION:\n    assert channels[3].samples_per_second == ch_freq\n\ndwi_resp_data[\"CO2\"] = channels[2].data[dwi_idx_start:dwi_idx_stop]\ndwi_resp_data[\"O2\"] = channels[3].data[dwi_idx_start:dwi_idx_stop]\n\nif session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off\n    dwi_resp_data[\"CO2\"] = dwi_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045\n    dwi_resp_data[\"O2\"] = (dwi_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10\n</pre> dwi_resp_data = {}  ch_freq = channels[0].samples_per_second ch_timeseries = channels[0].time_index ch_data = channels[0].data  dwi_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] dwi_idx_start = (np.abs(ch_timeseries - t_start)).argmin() dwi_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[dwi_idx_start:dwi_idx_stop] - dwi_onset dwi_resp_data[\"belt\"] = ch_data[dwi_idx_start:dwi_idx_stop]  assert channels[2].samples_per_second == ch_freq if session &gt;= FIRST_O2_SESSION:     assert channels[3].samples_per_second == ch_freq  dwi_resp_data[\"CO2\"] = channels[2].data[dwi_idx_start:dwi_idx_stop] dwi_resp_data[\"O2\"] = channels[3].data[dwi_idx_start:dwi_idx_stop]  if session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off     dwi_resp_data[\"CO2\"] = dwi_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045     dwi_resp_data[\"O2\"] = (dwi_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10 In\u00a0[18]: Copied! <pre>plt.plot(x_sec, dwi_resp_data[\"belt\"])\nplt.vlines(0, -7.5, -5, colors=\"r\")\nplt.xlim((-40, 1))\n</pre> plt.plot(x_sec, dwi_resp_data[\"belt\"]) plt.vlines(0, -7.5, -5, colors=\"r\") plt.xlim((-40, 1)) Out[18]: <pre>(-40.0, 1.0)</pre> <p>Now, let's have a look at the gaz analyzer signal.</p> In\u00a0[19]: Copied! <pre>plt.plot(x_sec, dwi_resp_data[\"CO2\"])\nif session &gt;= FIRST_O2_SESSION:\n    plt.plot(x_sec, dwi_resp_data[\"O2\"] - 20.946)\nplt.vlines(0, 0, 0.4, colors=\"r\")\nplt.xlim((-40, 1))\n</pre> plt.plot(x_sec, dwi_resp_data[\"CO2\"]) if session &gt;= FIRST_O2_SESSION:     plt.plot(x_sec, dwi_resp_data[\"O2\"] - 20.946) plt.vlines(0, 0, 0.4, colors=\"r\") plt.xlim((-40, 1)) Out[19]: <pre>(-40.0, 1.0)</pre> In\u00a0[20]: Copied! <pre>dwi_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"dwi\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_acq-highres_dir-{pe}_recording-respiratory_physio.tsv.gz\"\ndwi_sidecar = RESP_JSON.copy()\ndwi_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n\n(dwi_resp_filepath.parent / dwi_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(dwi_sidecar, indent=2))\n\npd.DataFrame(dwi_resp_data).to_csv(\n    dwi_resp_filepath,\n    compression=\"gzip\",\n    columns=dwi_sidecar[\"Columns\"],\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> dwi_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"dwi\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_acq-highres_dir-{pe}_recording-respiratory_physio.tsv.gz\" dwi_sidecar = RESP_JSON.copy() dwi_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], })  (dwi_resp_filepath.parent / dwi_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(dwi_sidecar, indent=2))  pd.DataFrame(dwi_resp_data).to_csv(     dwi_resp_filepath,     compression=\"gzip\",     columns=dwi_sidecar[\"Columns\"],     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) <p>Finally, let's write all digital signals in a third file:</p> In\u00a0[21]: Copied! <pre>dwi_triggers_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"dwi\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_acq-highres_dir-{pe}_stim.tsv.gz\"\n\nchannel_idx = list(range(4, len(channels)))\n\ncolumns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]\n\ndwi_trigger_data = {\n    name: channels[ch_i].data[first_timepoint:last_timepoint]\n    for name, ch_i in zip(columns, channel_idx)\n}\n\ndwi_sidecar = {\n    \"SamplingFrequency\": channels[4].samples_per_second,\n    \"StartTime\": t_start - t_0,\n    \"Columns\": columns,\n    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n}\n\nfor col, chid in zip(columns, channel_idx):\n    dwi_sidecar[col] = {\n        \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",\n        \"Units\": \"V\",\n        \"Model\": \"SPT100D\",\n    }\ndwi_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"\n\n(dwi_triggers_filepath.parent / dwi_triggers_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(dwi_sidecar, indent=2))\n\n\npd.DataFrame(dwi_trigger_data).to_csv(\n    dwi_triggers_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> dwi_triggers_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"dwi\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_acq-highres_dir-{pe}_stim.tsv.gz\"  channel_idx = list(range(4, len(channels)))  columns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]  dwi_trigger_data = {     name: channels[ch_i].data[first_timepoint:last_timepoint]     for name, ch_i in zip(columns, channel_idx) }  dwi_sidecar = {     \"SamplingFrequency\": channels[4].samples_per_second,     \"StartTime\": t_start - t_0,     \"Columns\": columns,     \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\", }  for col, chid in zip(columns, channel_idx):     dwi_sidecar[col] = {         \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",         \"Units\": \"V\",         \"Model\": \"SPT100D\",     } dwi_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"  (dwi_triggers_filepath.parent / dwi_triggers_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(dwi_sidecar, indent=2))   pd.DataFrame(dwi_trigger_data).to_csv(     dwi_triggers_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[22]: Copied! <pre>dummies = 0\n\nfirst_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[-1])[0, 0] + dummies]\nt_0 = timeseries[first_trigger]\n\nfirst_timepoint = int(between_seq[-1] - 120 * freq)\nt_start = timeseries[first_timepoint]\n\nlast_timepoint = len(timeseries) - 1\nt_stop = timeseries[last_timepoint]\n</pre> dummies = 0  first_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[-1])[0, 0] + dummies] t_0 = timeseries[first_trigger]  first_timepoint = int(between_seq[-1] - 120 * freq) t_start = timeseries[first_timepoint]  last_timepoint = len(timeseries) - 1 t_stop = timeseries[last_timepoint] <p>Again as in the DWI section, we find what that trigger index would be, had the trigger timeseries been acquired at this other channel frequency instead.</p> In\u00a0[23]: Copied! <pre>ch_index = 1\nchannels = session_data.channels\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\nbht_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\nbht_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\nbht_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[bht_idx_start:bht_idx_stop] - bht_onset\nbht_ch_data = ch_data[bht_idx_start:bht_idx_stop]\nbht_trigger = data[first_timepoint:last_timepoint]\nbht_idx_start, bht_idx_stop, bht_onset, x_sec[0], x_sec[-1], len(x_sec)\n</pre> ch_index = 1 channels = session_data.channels ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  bht_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] bht_idx_start = (np.abs(ch_timeseries - t_start)).argmin() bht_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[bht_idx_start:bht_idx_stop] - bht_onset bht_ch_data = ch_data[bht_idx_start:bht_idx_stop] bht_trigger = data[first_timepoint:last_timepoint] bht_idx_start, bht_idx_stop, bht_onset, x_sec[0], x_sec[-1], len(x_sec) Out[23]: <pre>(23416422,\n 26252575,\n 4803.284582964315,\n -120.00000457098031,\n 447.2304170356774,\n 2836153)</pre> <p>And we plot the ECG signal along with the trigger. Note that fMRI sequence sends a trigger every volume, unlike the DWI sequence which sends it every slice, so the triggers are more spaced.</p> In\u00a0[24]: Copied! <pre>plt.plot(x_sec, bht_ch_data)\nplt.plot(x_sec, bht_trigger / 50)\nplt.vlines(0, -0.4, 0.4, colors=\"r\")\nplt.xlim((-5, 10))\n</pre> plt.plot(x_sec, bht_ch_data) plt.plot(x_sec, bht_trigger / 50) plt.vlines(0, -0.4, 0.4, colors=\"r\") plt.xlim((-5, 10)) Out[24]: <pre>(-5.0, 10.0)</pre> In\u00a0[25]: Copied! <pre>bht_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-bht_dir-{pe}_recording-cardiac_physio.tsv.gz\"\nbht_sidecar = CARD_JSON.copy()\nbht_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n(bht_cardio_filepath.parent / bht_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(bht_sidecar, indent=2))\n\npd.DataFrame({\"ecg\": bht_ch_data}).to_csv(\n    bht_cardio_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> bht_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-bht_dir-{pe}_recording-cardiac_physio.tsv.gz\" bht_sidecar = CARD_JSON.copy() bht_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], }) (bht_cardio_filepath.parent / bht_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(bht_sidecar, indent=2))  pd.DataFrame({\"ecg\": bht_ch_data}).to_csv(     bht_cardio_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[26]: Copied! <pre>bht_resp_data = {}\n\nch_index = 0\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\nbht_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\nbht_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\nbht_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[bht_idx_start:bht_idx_stop] - bht_onset\nbht_resp_data[\"belt\"] = ch_data[bht_idx_start:bht_idx_stop]\n\nassert channels[2].samples_per_second == ch_freq\nif session &gt;= FIRST_O2_SESSION:\n    assert channels[3].samples_per_second == ch_freq\n\nbht_resp_data[\"CO2\"] = channels[2].data[bht_idx_start:bht_idx_stop]\nbht_resp_data[\"O2\"] = channels[3].data[bht_idx_start:bht_idx_stop]\n\nif session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off\n    bht_resp_data[\"CO2\"] = bht_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045\n    bht_resp_data[\"O2\"] = (bht_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10\n</pre> bht_resp_data = {}  ch_index = 0 ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  bht_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] bht_idx_start = (np.abs(ch_timeseries - t_start)).argmin() bht_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[bht_idx_start:bht_idx_stop] - bht_onset bht_resp_data[\"belt\"] = ch_data[bht_idx_start:bht_idx_stop]  assert channels[2].samples_per_second == ch_freq if session &gt;= FIRST_O2_SESSION:     assert channels[3].samples_per_second == ch_freq  bht_resp_data[\"CO2\"] = channels[2].data[bht_idx_start:bht_idx_stop] bht_resp_data[\"O2\"] = channels[3].data[bht_idx_start:bht_idx_stop]  if session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off     bht_resp_data[\"CO2\"] = bht_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045     bht_resp_data[\"O2\"] = (bht_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10 In\u00a0[27]: Copied! <pre>plt.plot(x_sec, bht_resp_data[\"belt\"])\nplt.plot(x_sec, bht_resp_data[\"CO2\"])\n# if session &gt;= FIRST_O2_SESSION:\n#     plt.plot(x_sec, bht_resp_data[\"O2\"] - 18)\n#plt.xlim((100, 160))\nplt.ylim((0, 4))\n</pre> plt.plot(x_sec, bht_resp_data[\"belt\"]) plt.plot(x_sec, bht_resp_data[\"CO2\"]) # if session &gt;= FIRST_O2_SESSION: #     plt.plot(x_sec, bht_resp_data[\"O2\"] - 18) #plt.xlim((100, 160)) plt.ylim((0, 4)) Out[27]: <pre>(0.0, 4.0)</pre> In\u00a0[28]: Copied! <pre>bht_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-bht_dir-{pe}_recording-respiratory_physio.tsv.gz\"\nbht_sidecar = RESP_JSON.copy()\nbht_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n\n(bht_resp_filepath.parent / bht_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(bht_sidecar, indent=2))\n\npd.DataFrame(bht_resp_data).to_csv(\n    bht_resp_filepath,\n    compression=\"gzip\",\n    columns=bht_sidecar[\"Columns\"],\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> bht_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-bht_dir-{pe}_recording-respiratory_physio.tsv.gz\" bht_sidecar = RESP_JSON.copy() bht_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], })  (bht_resp_filepath.parent / bht_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(bht_sidecar, indent=2))  pd.DataFrame(bht_resp_data).to_csv(     bht_resp_filepath,     compression=\"gzip\",     columns=bht_sidecar[\"Columns\"],     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[29]: Copied! <pre>bht_trigg_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-bht_dir-{pe}_stim.tsv.gz\"\n\nchannel_idx = list(range(4, len(channels)))\n\ncolumns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]\n\nbht_sidecar = {\n    \"SamplingFrequency\": channels[4].samples_per_second,\n    \"StartTime\": t_start - t_0,\n    \"Columns\": columns,\n    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n}\n\nfor col, chid in zip(columns, channel_idx):\n    bht_sidecar[col] = {\n        \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",\n        \"Units\": \"V\",\n        \"Model\": \"SPT100D\",\n    }\nbht_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"\n\n(bht_trigg_filepath.parent / bht_trigg_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(bht_sidecar, indent=2))\n\nbht_trigger_data = {\n    name: channels[ch_i].data[first_timepoint:last_timepoint]\n    for name, ch_i in zip(columns, channel_idx)\n}\n\npd.DataFrame(bht_trigger_data).to_csv(\n    bht_trigg_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> bht_trigg_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-bht_dir-{pe}_stim.tsv.gz\"  channel_idx = list(range(4, len(channels)))  columns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]  bht_sidecar = {     \"SamplingFrequency\": channels[4].samples_per_second,     \"StartTime\": t_start - t_0,     \"Columns\": columns,     \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\", }  for col, chid in zip(columns, channel_idx):     bht_sidecar[col] = {         \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",         \"Units\": \"V\",         \"Model\": \"SPT100D\",     } bht_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"  (bht_trigg_filepath.parent / bht_trigg_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(bht_sidecar, indent=2))  bht_trigger_data = {     name: channels[ch_i].data[first_timepoint:last_timepoint]     for name, ch_i in zip(columns, channel_idx) }  pd.DataFrame(bht_trigger_data).to_csv(     bht_trigg_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[30]: Copied! <pre>dummies = 0\n\nfirst_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[-2])[0, 0] + dummies]\nt_0 = timeseries[first_trigger]\n\nfirst_timepoint = int(between_seq[-2] - 120 * freq)\nt_start = timeseries[first_timepoint]\n\nlast_timepoint = between_seq[-1]\nt_stop = timeseries[last_timepoint]\n</pre> dummies = 0  first_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[-2])[0, 0] + dummies] t_0 = timeseries[first_trigger]  first_timepoint = int(between_seq[-2] - 120 * freq) t_start = timeseries[first_timepoint]  last_timepoint = between_seq[-1] t_stop = timeseries[last_timepoint] In\u00a0[31]: Copied! <pre>ch_index = 1\nchannels = session_data.channels\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\nrest_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\nrest_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\nrest_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[rest_idx_start:rest_idx_stop] - rest_onset\nrest_ch_data = ch_data[rest_idx_start:rest_idx_stop]\nrest_trigger = data[first_timepoint:last_timepoint]\nrest_idx_start, rest_idx_stop, rest_onset, x_sec[0], x_sec[-1], len(x_sec)\n</pre> ch_index = 1 channels = session_data.channels ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  rest_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] rest_idx_start = (np.abs(ch_timeseries - t_start)).argmin() rest_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[rest_idx_start:rest_idx_stop] - rest_onset rest_ch_data = ch_data[rest_idx_start:rest_idx_stop] rest_trigger = data[first_timepoint:last_timepoint] rest_idx_start, rest_idx_stop, rest_onset, x_sec[0], x_sec[-1], len(x_sec) Out[31]: <pre>(16980667,\n 24016422,\n 3516.1335339348007,\n -120.00000457098031,\n 1287.1508490295064,\n 7035755)</pre> In\u00a0[32]: Copied! <pre>plt.plot(x_sec, rest_ch_data)\nplt.plot(x_sec, rest_trigger / 50)\nplt.vlines(0, -0.4, 0.4, colors=\"r\")\nplt.xlim((-5, 10))\n</pre> plt.plot(x_sec, rest_ch_data) plt.plot(x_sec, rest_trigger / 50) plt.vlines(0, -0.4, 0.4, colors=\"r\") plt.xlim((-5, 10)) Out[32]: <pre>(-5.0, 10.0)</pre> In\u00a0[33]: Copied! <pre>rest_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-rest_dir-{pe}_recording-cardiac_physio.tsv.gz\"\nrest_sidecar = CARD_JSON.copy()\nrest_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n(rest_cardio_filepath.parent / rest_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(rest_sidecar, indent=2))\n\npd.DataFrame({\"ecg\": rest_ch_data}).to_csv(\n    rest_cardio_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> rest_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-rest_dir-{pe}_recording-cardiac_physio.tsv.gz\" rest_sidecar = CARD_JSON.copy() rest_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], }) (rest_cardio_filepath.parent / rest_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(rest_sidecar, indent=2))  pd.DataFrame({\"ecg\": rest_ch_data}).to_csv(     rest_cardio_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[34]: Copied! <pre>rest_resp_data = {}\n\nch_index = 0\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\nrest_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\nrest_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\nrest_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[rest_idx_start:rest_idx_stop] - rest_onset\nrest_resp_data[\"belt\"] = ch_data[rest_idx_start:rest_idx_stop]\n\nassert channels[2].samples_per_second == ch_freq\nif session &gt;= FIRST_O2_SESSION:\n    assert channels[3].samples_per_second == ch_freq\n\nrest_resp_data[\"CO2\"] = channels[2].data[rest_idx_start:rest_idx_stop]\nrest_resp_data[\"O2\"] = channels[3].data[rest_idx_start:rest_idx_stop]\n\nif session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off\n    rest_resp_data[\"CO2\"] = rest_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045\n    rest_resp_data[\"O2\"] = (rest_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10\n</pre> rest_resp_data = {}  ch_index = 0 ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  rest_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] rest_idx_start = (np.abs(ch_timeseries - t_start)).argmin() rest_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[rest_idx_start:rest_idx_stop] - rest_onset rest_resp_data[\"belt\"] = ch_data[rest_idx_start:rest_idx_stop]  assert channels[2].samples_per_second == ch_freq if session &gt;= FIRST_O2_SESSION:     assert channels[3].samples_per_second == ch_freq  rest_resp_data[\"CO2\"] = channels[2].data[rest_idx_start:rest_idx_stop] rest_resp_data[\"O2\"] = channels[3].data[rest_idx_start:rest_idx_stop]  if session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off     rest_resp_data[\"CO2\"] = rest_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045     rest_resp_data[\"O2\"] = (rest_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10 In\u00a0[\u00a0]: Copied! <pre>plt.plot(x_sec, rest_resp_data[\"belt\"])\nplt.plot(x_sec, rest_resp_data[\"CO2\"])\nif session &gt;= FIRST_O2_SESSION:\n    #Offset the O2 signal by 10 units for better visualization\n    plt.plot(x_sec, rest_resp_data[\"O2\"] - 10)\n\nplt.vlines(0, -0.4, 0.4, colors=\"r\")\n</pre> plt.plot(x_sec, rest_resp_data[\"belt\"]) plt.plot(x_sec, rest_resp_data[\"CO2\"]) if session &gt;= FIRST_O2_SESSION:     #Offset the O2 signal by 10 units for better visualization     plt.plot(x_sec, rest_resp_data[\"O2\"] - 10)  plt.vlines(0, -0.4, 0.4, colors=\"r\") Out[\u00a0]: <pre>&lt;matplotlib.collections.LineCollection at 0x7fd74a36c310&gt;</pre> <p>In the plot above, the respiration belt is plotted in blue, the CO2 signal in orange and the O2 signal in green.</p> In\u00a0[36]: Copied! <pre>rest_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-rest_dir-{pe}_recording-respiratory_physio.tsv.gz\"\nrest_sidecar = RESP_JSON.copy()\nrest_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n\n(rest_resp_filepath.parent / rest_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(rest_sidecar, indent=2))\n\npd.DataFrame(rest_resp_data).to_csv(\n    rest_resp_filepath,\n    compression=\"gzip\",\n    columns=rest_sidecar[\"Columns\"],\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> rest_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-rest_dir-{pe}_recording-respiratory_physio.tsv.gz\" rest_sidecar = RESP_JSON.copy() rest_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], })  (rest_resp_filepath.parent / rest_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(rest_sidecar, indent=2))  pd.DataFrame(rest_resp_data).to_csv(     rest_resp_filepath,     compression=\"gzip\",     columns=rest_sidecar[\"Columns\"],     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[37]: Copied! <pre>rest_trigg_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-rest_dir-{pe}_stim.tsv.gz\"\n\nchannel_idx = list(range(4, len(channels)))\n\ncolumns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]\n\nrest_sidecar = {\n    \"SamplingFrequency\": channels[4].samples_per_second,\n    \"StartTime\": t_start - t_0,\n    \"Columns\": columns,\n    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n}\n\nfor col, chid in zip(columns, channel_idx):\n    rest_sidecar[col] = {\n        \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",\n        \"Units\": \"V\",\n        \"Model\": \"SPT100D\",\n    }\nrest_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"\n\n(rest_trigg_filepath.parent / rest_trigg_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(rest_sidecar, indent=2))\n\nrest_trigger_data = {\n    name: channels[ch_i].data[first_timepoint:last_timepoint]\n    for name, ch_i in zip(columns, channel_idx)\n}\n\npd.DataFrame(rest_trigger_data).to_csv(\n    rest_trigg_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> rest_trigg_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-rest_dir-{pe}_stim.tsv.gz\"  channel_idx = list(range(4, len(channels)))  columns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]  rest_sidecar = {     \"SamplingFrequency\": channels[4].samples_per_second,     \"StartTime\": t_start - t_0,     \"Columns\": columns,     \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\", }  for col, chid in zip(columns, channel_idx):     rest_sidecar[col] = {         \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",         \"Units\": \"V\",         \"Model\": \"SPT100D\",     } rest_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"  (rest_trigg_filepath.parent / rest_trigg_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(rest_sidecar, indent=2))  rest_trigger_data = {     name: channels[ch_i].data[first_timepoint:last_timepoint]     for name, ch_i in zip(columns, channel_idx) }  pd.DataFrame(rest_trigger_data).to_csv(     rest_trigg_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[38]: Copied! <pre>dummies = 0\n\nfirst_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[-3])[0, 0] + dummies]\nt_0 = timeseries[first_trigger]\n\nfirst_timepoint = int(between_seq[-3] - 120 * freq)\nt_start = timeseries[first_timepoint]\n\nlast_timepoint = between_seq[-2]\nt_stop = timeseries[last_timepoint]\n</pre> dummies = 0  first_trigger = trigger_locations[np.argwhere(trigger_locations == between_seq[-3])[0, 0] + dummies] t_0 = timeseries[first_trigger]  first_timepoint = int(between_seq[-3] - 120 * freq) t_start = timeseries[first_timepoint]  last_timepoint = between_seq[-2] t_stop = timeseries[last_timepoint] In\u00a0[39]: Copied! <pre>ch_index = 1\nchannels = session_data.channels\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\nqct_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\nqct_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\nqct_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[qct_idx_start:qct_idx_stop] - qct_onset\nqct_ch_data = ch_data[qct_idx_start:qct_idx_stop]\nqct_trigger = data[first_timepoint:last_timepoint]\n\n# plot it\nplt.plot(x_sec, qct_ch_data)\nplt.plot(x_sec, qct_trigger / 50)\nplt.vlines(0, -0.4, 0.4, colors=\"r\")\nplt.xlim((-5, 10))\n</pre> ch_index = 1 channels = session_data.channels ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  qct_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] qct_idx_start = (np.abs(ch_timeseries - t_start)).argmin() qct_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[qct_idx_start:qct_idx_stop] - qct_onset qct_ch_data = ch_data[qct_idx_start:qct_idx_stop] qct_trigger = data[first_timepoint:last_timepoint]  # plot it plt.plot(x_sec, qct_ch_data) plt.plot(x_sec, qct_trigger / 50) plt.vlines(0, -0.4, 0.4, colors=\"r\") plt.xlim((-5, 10)) Out[39]: <pre>(-5.0, 10.0)</pre> In\u00a0[40]: Copied! <pre>qct_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-qct_dir-{pe}_recording-cardiac_physio.tsv.gz\"\nqct_sidecar = CARD_JSON.copy()\nqct_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n(qct_cardio_filepath.parent / qct_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(qct_sidecar, indent=2))\n\npd.DataFrame({\"ecg\": qct_ch_data}).to_csv(\n    qct_cardio_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> qct_cardio_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-qct_dir-{pe}_recording-cardiac_physio.tsv.gz\" qct_sidecar = CARD_JSON.copy() qct_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], }) (qct_cardio_filepath.parent / qct_cardio_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(qct_sidecar, indent=2))  pd.DataFrame({\"ecg\": qct_ch_data}).to_csv(     qct_cardio_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[41]: Copied! <pre>qct_resp_data = {}\n\nch_index = 0\nch_freq = channels[ch_index].samples_per_second\nch_timeseries = channels[ch_index].time_index\nch_data = channels[ch_index].data\n\nqct_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()]\nqct_idx_start = (np.abs(ch_timeseries - t_start)).argmin()\nqct_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()\n\nx_sec = ch_timeseries[qct_idx_start:qct_idx_stop] - qct_onset\nqct_resp_data[\"belt\"] = ch_data[qct_idx_start:qct_idx_stop]\n\nassert channels[2].samples_per_second == ch_freq\nif session &gt;= FIRST_O2_SESSION:\n    assert channels[3].samples_per_second == ch_freq\n\nqct_resp_data[\"CO2\"] = channels[2].data[qct_idx_start:qct_idx_stop]\nqct_resp_data[\"O2\"] = channels[3].data[qct_idx_start:qct_idx_stop]\n\nif session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off\n    qct_resp_data[\"CO2\"] = qct_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045\n    qct_resp_data[\"O2\"] = (qct_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10\n\nplt.plot(x_sec, qct_resp_data[\"belt\"])\nplt.plot(x_sec, qct_resp_data[\"CO2\"])\nif session &gt;= FIRST_O2_SESSION:\n    plt.plot(x_sec, qct_resp_data[\"O2\"] - 10)\nplt.vlines(0, -0.4, 0.4, colors=\"r\")\n</pre> qct_resp_data = {}  ch_index = 0 ch_freq = channels[ch_index].samples_per_second ch_timeseries = channels[ch_index].time_index ch_data = channels[ch_index].data  qct_onset = ch_timeseries[(np.abs(ch_timeseries - t_0)).argmin()] qct_idx_start = (np.abs(ch_timeseries - t_start)).argmin() qct_idx_stop = (np.abs(ch_timeseries - t_stop)).argmin()  x_sec = ch_timeseries[qct_idx_start:qct_idx_stop] - qct_onset qct_resp_data[\"belt\"] = ch_data[qct_idx_start:qct_idx_stop]  assert channels[2].samples_per_second == ch_freq if session &gt;= FIRST_O2_SESSION:     assert channels[3].samples_per_second == ch_freq  qct_resp_data[\"CO2\"] = channels[2].data[qct_idx_start:qct_idx_stop] qct_resp_data[\"O2\"] = channels[3].data[qct_idx_start:qct_idx_stop]  if session &lt; RECALIBRATED_SESSION:  # Before session 23, calibration was a bit off     qct_resp_data[\"CO2\"] = qct_resp_data[\"CO2\"] * (8.0 - 0.045)  / 0.8 + 0.045     qct_resp_data[\"O2\"] = (qct_resp_data[\"O2\"] - 0.1) * 10.946 / (20.946 + 0.1) + 10  plt.plot(x_sec, qct_resp_data[\"belt\"]) plt.plot(x_sec, qct_resp_data[\"CO2\"]) if session &gt;= FIRST_O2_SESSION:     plt.plot(x_sec, qct_resp_data[\"O2\"] - 10) plt.vlines(0, -0.4, 0.4, colors=\"r\") Out[41]: <pre>&lt;matplotlib.collections.LineCollection at 0x7fd98e0b1790&gt;</pre> In\u00a0[42]: Copied! <pre>qct_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-qct_dir-{pe}_recording-respiratory_physio.tsv.gz\"\nqct_sidecar = RESP_JSON.copy()\nqct_sidecar.update({\n    \"SamplingFrequency\": ch_freq,\n    \"StartTime\": x_sec[0],\n})\n\n(qct_resp_filepath.parent / qct_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(qct_sidecar, indent=2))\n\npd.DataFrame(qct_resp_data).to_csv(\n    qct_resp_filepath,\n    compression=\"gzip\",\n    columns=qct_sidecar[\"Columns\"],\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> qct_resp_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-qct_dir-{pe}_recording-respiratory_physio.tsv.gz\" qct_sidecar = RESP_JSON.copy() qct_sidecar.update({     \"SamplingFrequency\": ch_freq,     \"StartTime\": x_sec[0], })  (qct_resp_filepath.parent / qct_resp_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(qct_sidecar, indent=2))  pd.DataFrame(qct_resp_data).to_csv(     qct_resp_filepath,     compression=\"gzip\",     columns=qct_sidecar[\"Columns\"],     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[43]: Copied! <pre>qct_trigg_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-qct_dir-{pe}_stim.tsv.gz\"\n\nchannel_idx = list(range(4, len(channels)))\n\ncolumns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]\n\nqct_sidecar = {\n    \"SamplingFrequency\": channels[4].samples_per_second,\n    \"StartTime\": t_start - t_0,\n    \"Columns\": columns,\n    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n}\n\nfor col, chid in zip(columns, channel_idx):\n    qct_sidecar[col] = {\n        \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",\n        \"Units\": \"V\",\n        \"Model\": \"SPT100D\",\n    }\nqct_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"\n\n(qct_trigg_filepath.parent / qct_trigg_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(qct_sidecar, indent=2))\n\nqct_trigger_data = {\n    name: channels[ch_i].data[first_timepoint:last_timepoint]\n    for name, ch_i in zip(columns, channel_idx)\n}\n\npd.DataFrame(qct_trigger_data).to_csv(\n    qct_trigg_filepath,\n    compression=\"gzip\",\n    header=False,\n    sep=\"\\t\",\n    na_rep=\"n/a\",\n)\n</pre> qct_trigg_filepath = BIDS_PATH / f\"sub-{participant}\" / f\"ses-{'excl' if session_excluded else ''}{session:03d}\" / \"func\" / f\"sub-{participant}_ses-{'excl' if session_excluded else ''}{session:03d}_task-qct_dir-{pe}_stim.tsv.gz\"  channel_idx = list(range(4, len(channels)))  columns = [\"trigger\"] + [f\"digital_ch{line}\" for line in range(5, len(channels))]  qct_sidecar = {     \"SamplingFrequency\": channels[4].samples_per_second,     \"StartTime\": t_start - t_0,     \"Columns\": columns,     \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\", }  for col, chid in zip(columns, channel_idx):     qct_sidecar[col] = {         \"Description\": f\"{''.join(filter(lambda x: x in string.printable, session_data.channel_headers[chid]['szCommentText'].decode().strip()))}: digital pulse signal generated with Psychopy\",         \"Units\": \"V\",         \"Model\": \"SPT100D\",     } qct_sidecar[\"trigger\"][\"Description\"] = \"continuous measurement of the scanner trigger signal\"  (qct_trigg_filepath.parent / qct_trigg_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(qct_sidecar, indent=2))  qct_trigger_data = {     name: channels[ch_i].data[first_timepoint:last_timepoint]     for name, ch_i in zip(columns, channel_idx) }  pd.DataFrame(qct_trigger_data).to_csv(     qct_trigg_filepath,     compression=\"gzip\",     header=False,     sep=\"\\t\",     na_rep=\"n/a\", ) In\u00a0[\u00a0]: Copied! <pre>n_trigg_dwi = 87 * 2 + 29 + 280 * 29\n\nfirst_dwi = np.argwhere(trigger_locations == between_seq[0])[0, 0]\nlast_dwi = trigger_locations[first_dwi + n_trigg_dwi]\n\nseq_limits[last_dwi + int(7 * freq)] = 1\n\nplt.plot(timeseries, trigger_onsets);\nplt.plot(timeseries, seq_limits);\nplt.xlim((last_dwi / freq - 70, last_dwi / freq + 28))\n</pre> n_trigg_dwi = 87 * 2 + 29 + 280 * 29  first_dwi = np.argwhere(trigger_locations == between_seq[0])[0, 0] last_dwi = trigger_locations[first_dwi + n_trigg_dwi]  seq_limits[last_dwi + int(7 * freq)] = 1  plt.plot(timeseries, trigger_onsets); plt.plot(timeseries, seq_limits); plt.xlim((last_dwi / freq - 70, last_dwi / freq + 28)) In\u00a0[\u00a0]: Copied! <pre>boxcar = np.ones(round(freq * (7 / 29)) + 5)\nenvelope = fftconvolve(trigger_locations, boxcar)\nenvelope = envelope[len(boxcar) // 2:-(len(boxcar) // 2 - 1 + len(boxcar) % 2)]\nplt.plot(timeseries, envelope)\n</pre> boxcar = np.ones(round(freq * (7 / 29)) + 5) envelope = fftconvolve(trigger_locations, boxcar) envelope = envelope[len(boxcar) // 2:-(len(boxcar) // 2 - 1 + len(boxcar) % 2)] plt.plot(timeseries, envelope) In\u00a0[\u00a0]: Copied! <pre>env_copy = envelope.copy()\nenv_copy[env_copy &lt; 10] = 0\nenv_copy[env_copy &gt; 0] = 1\n</pre> env_copy = envelope.copy() env_copy[env_copy &lt; 10] = 0 env_copy[env_copy &gt; 0] = 1 In\u00a0[\u00a0]: Copied! <pre>plt.plot(timeseries, env_copy)\n</pre> plt.plot(timeseries, env_copy) In\u00a0[\u00a0]: Copied! <pre>from scipy.ndimage import binary_closing\n</pre> from scipy.ndimage import binary_closing In\u00a0[\u00a0]: Copied! <pre>amplitude = binary_closing(trigger_locations, structure=np.ones(int(freq * 1.6)))\nplt.plot(timeseries, amplitude)\n</pre> amplitude = binary_closing(trigger_locations, structure=np.ones(int(freq * 1.6))) plt.plot(timeseries, amplitude) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"data-management/physio-to-bids/#converting-hcphs-physio-into-bids","title":"Converting HCPh's physio into BIDS\u00b6","text":"<p>This notebook shows how to convert from AcqKnowledge into BIDS. First, let's import some necessary libraries.</p>"},{"location":"data-management/physio-to-bids/#converting-physio-corresponding-to-the-dwi-run","title":"Converting physio corresponding to the DWI run\u00b6","text":"<p>Cardiac signal (ECG) is stored in channel 2 of our AcqKnowledge files (i.e., index 1 in Python, which is zero-based).</p> <p>First, let's calculate in the particular ECG channel, the indexes at which we are going to clip the cardiac signal around each imaging run.</p> <p>For DWI, we will clip the files between <code>dwi_idx_start</code> and <code>dwi_idx_stop</code>. In this case, for DWI we need to take into account that the sequence sends triggers during calibration (2 x 87 slices single slice mode, plus 29 for one multi-slice volume). With this information, we will be able to calculate <code>dwi_onset</code> as the timepoint (in seconds) when the DWI sequence started acquiring the first final volume.</p>"},{"location":"data-management/physio-to-bids/#converting-the-physio-corresponding-to-bht-into-bids","title":"Converting the physio corresponding to BHT  into BIDS\u00b6","text":""},{"location":"data-management/physio-to-bids/#converting-the-physio-corresponding-to-rsfmri-into-bids","title":"Converting the physio corresponding to RSfMRI  into BIDS\u00b6","text":""},{"location":"data-management/physio-to-bids/#converting-the-physio-corresponding-to-qct-into-bids","title":"Converting the physio corresponding to QCT  into BIDS\u00b6","text":""},{"location":"data-management/physio-to-bids/#scraps","title":"Scraps\u00b6","text":"<p>Some code that could become interesting some day.</p>"},{"location":"data-management/post-session/","title":"Post-session retrieval and BIDS","text":""},{"location":"data-management/post-session/#within-48h-after-the-first-session","title":"Within 48h after the FIRST session","text":"<p>Anatomical images must be screened for incidental findings within 48h after the first session</p> <ul> <li> Send the T1-weighted and T2-weighted scan to \u2588\u2588\u2588 for screening and incidental findings.</li> <li> Indicate on our recruits spreadsheet that the participant's first session has been submitted for screening.</li> <li> Wait for response from \u2588\u2588\u2588 and note down the result of the screening in our our recruits spreadsheet.</li> </ul> <p>To do so, you'll need to first download the data from PACS and then convert the data into BIDS.</p> <p>What to do when there are incidental findings</p> <ul> <li> Discuss with \u2588\u2588\u2588 how to proceed with the participant.</li> <li> Exclude the participant from the study if \u2588\u2588\u2588 evaluates they don't meet the participation (inclusion and exclusion) criteria.</li> </ul>"},{"location":"data-management/post-session/#within-one-week-after-the-completed-session","title":"Within one week after the completed session","text":""},{"location":"data-management/post-session/#download-the-data-from-the-pacs-with-pacsman-only-authorized-users","title":"Download the data from the PACS with PACSMAN (only authorized users)","text":"<ul> <li> Log-in into the PACSMAN computer  (\u2588\u2588\u2588)</li> <li> Mount a remote filesystem through sshfs:     <pre><code>sshfs &lt;hostname&gt;:/data/datasets/hcph-pilot-sourcedata \\\n               $HOME/data/hcph-pilot \\\n      &lt;args&gt;\n</code></pre></li> <li> Edit the query file <code>vim $HOME/queries/last-session.csv</code> (most likely, just update with the session's date) mydata-onesession.csv<pre><code>PatientID,StudyDate\n2022_11_07*,20230503\n</code></pre></li> <li> Prepare and run PACSMAN, pointing the output to the mounted directory.     <pre><code>pacsman --save -q $HOME/queries/last-session.csv \\\n       --out_directory $HOME/data/hcph-pilot/ \\\n       --config /opt/PACSMAN/files/config.json\n</code></pre></li> <li> Remove write permissions on the newly downloaded data:     <pre><code>chmod -R a-w $HOME/data/hcph-pilot/sub-01/ses-*\n</code></pre></li> <li> Unmount the remote filesystem:     <pre><code>sudo umount $HOME/data/hcph-pilot\n</code></pre></li> </ul>"},{"location":"data-management/post-session/#retrieve-physiological-recordings-from","title":"Retrieve physiological recordings (from \u2588\u2588\u2588\u2588)","text":""},{"location":"data-management/post-session/#copy-original-dicom-datasets-into-the-archive-of-stockage-horus","title":"Copy original DICOM datasets into the archive of Stockage hOrus","text":"<ul> <li> <p> Setup a cron job to execute automatically the synchronization:</p> <pre><code>crontab -e\n[ within your file editor add the following line ]\n0 2 * * * rsync -avurP /data/datasets/hcph-pilot-sourcedata* &lt;user&gt;@&lt;host&gt;:&lt;path&gt;/sourcedata-pilot &amp;&gt; $HOME/var/log/data-curnagl.log\n</code></pre> </li> </ul>"},{"location":"data-management/post-session/#within-two-weeks-after-the-completed-session","title":"Within two weeks after the completed session","text":""},{"location":"data-management/post-session/#convert-imaging-data-to-bids-with-heudiconv","title":"Convert imaging data to BIDS with HeuDiConv","text":"<p>We use HeuDiConv to convert from the DICOM format generated by the scanner. In addition, starting from the piloting session five, we abide by ReproIn conventions. To support backward compatibility (and some extra, currently unsupported features by the original heuristic file), we have our own heuristic file.</p> Our custom heuristic file <p>Our heuristic file largely derives from ReproIn's at the time of writing. The heuristic has a a <code>protocols2fix: dict[str | re.Pattern[str], list[tuple[str, str]]]</code> (lines 113-148), where replacement patterns to permit backward compatibility are written.</p> <pre><code># emacs: -*- mode: python; py-indent-offset: 4; indent-tabs-mode: nil -*-\n# vi: set ft=python sts=4 ts=4 sw=4 et:\n#\n# Copyright 2023 The Axon Lab &lt;theaxonlab@gmail.com&gt;\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# We support and encourage derived works from this project, please read\n# about our expectations at\n#\n#     https://www.nipreps.org/community/licensing/\n#\n# STATEMENT OF CHANGES: This file is derived from sources licensed under the Apache-2.0 terms,\n# and this file has been changed.\n# The original file this work derives from is found at:\n# https://github.com/nipy/heudiconv/blob/55524168b02519bbf0a3a1c94cafb29a419728a0/heudiconv/heuristics/reproin.py\n#\n# ORIGINAL WORK'S ATTRIBUTION NOTICE:\n#\n#     Copyright [2014-2019] [Heudiconv developers]\n#\n#     Licensed under the Apache License, Version 2.0 (the \"License\");\n#     you may not use this file except in compliance with the License.\n#     You may obtain a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#     Unless required by applicable law or agreed to in writing, software\n#     distributed under the License is distributed on an \"AS IS\" BASIS,\n#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#     See the License for the specific language governing permissions and\n#     limitations under the License.\n\"\"\"Reproin heuristic.\"\"\"\n\nfrom __future__ import annotations\n\nfrom warnings import warn\nfrom collections import Counter\nimport logging\nimport re\n\nimport pydicom as dcm\n\nfrom heudiconv.utils import SeqInfo\nfrom heudiconv.heuristics.reproin import (\n    _apply_substitutions,\n    get_study_hash,\n    get_study_description,\n)\n\nlgr = logging.getLogger(\"heudiconv\")\n\n\nDWI_RES = {\n    \"1.6mm-iso\": \"highres\",\n    \"2mm-iso\": \"lowres\",\n}\n\n\nIGNORE_PROTOCOLS = (\n    \"DEV\",\n    \"LABEL\",\n    \"REPORT\",\n    \"ADC\",\n    \"TRACEW\",\n    \"FA\",\n    \"ColFA\",\n    \"B0\",\n    \"TENSOR\",\n    \"10meas\",  # dismiss a trial of fmap acquisition\n    \"testJB\",  # dismiss a test trial of the cmrr sequence\n)\n\nbids_regex = re.compile(r\"_(?=(dir|acq|task|run)-([A-Za-z0-9]+))\")\n\n\n# Terminology to harmonise and use to name variables etc\n# experiment\n#  subject\n#   [session]\n#    exam (AKA scanning session) - currently seqinfo, unless brought together from multiple\n#     series  (AKA protocol?)\n#      - series_spec - deduced from fields the spec (literal value)\n#      - series_info - the dictionary with fields parsed from series_spec\n\n# Which fields in seqinfo (in this order) to check for the ReproIn spec\nseries_spec_fields = (\"protocol_name\", \"series_description\")\n\n# dictionary from accession-number to runs that need to be marked as bad\n# NOTE: even if filename has number that is 0-padded, internally no padding\n# is done\nfix_accession2run: dict[str, list[str]] = {\n    # e.g.:\n    # 'A000035': ['^8-', '^9-'],\n}\n\n# A dictionary containing fixes/remapping for sequence names per study.\n# Keys are md5sum of study_description from DICOMs, in the form of PI-Experimenter^protocolname\n# You can use `heudiconv -f reproin --command ls --files  PATH\n# to list the \"study hash\".\n# Values are list of tuples in the form (regex_pattern, substitution).\n# If the  key is an empty string`''''`, it would apply to any study.\nprotocols2fix: dict[str | re.Pattern[str], list[tuple[str, str]]] = {\n    \"\": [\n        (\"t1_mprage_pre_Morpho\", \"anat-T1w_acq-morphobox__mprage\"),\n        (\n            \"micro_struct_137dir_BIPOLAR_b3000_1.6mm-iso\",\n            \"dwi-dwi_acq-highres_dir-unknown__137dir_bipolar\",\n        ),\n        (\n            \"micro_struct_137dir_BIPOLAR_b3000_1.6mm-iso\",\n            \"dwi-dwi_acq-highres_dir-unknown__137dir_bipolar\",\n        ),\n        (\n            \"micro_struct_137dir_BIPOLAR_b3000_2mm-iso\",\n            \"dwi-dwi_acq-lowres_dir-unknown__137dir_bipolar\",\n        ),\n        (\"gre_field_mapping_1.6mmiso\", \"fmap-phasediff__gre\"),\n        (\n            \"cmrr_mbep2d_bold_me4_sms4_fa75_750meas\",\n            \"func-bold_task-rest__750meas\",\n        ),\n        (\n            \"cmrr_mbep2d_bold_me4_sms4_fa80\",\n            \"func-bold_task-rest_acq-fa80__cmrr\",\n        ),\n        (\n            \"cmrr_mbep2d_bold_me4_testJB\",\n            \"func-bold_task-rest_acq-testJB__cmrr\",\n        ),\n        (\n            \"cmrr_mbep2d_bold_fmap_fa80\",\n            \"fmap-epi_acq-bold_dir-unknown__cmrr_mbepd2d_fa80\",\n        ),\n        (\"cmrr_mbep2d_bold_me4_sms4\", \"func-bold_task-qct__cmrr\"),\n        (\"_task-qc_\", \"_task-qct_\"),\n        (\"anat-T2w__flair\", \"anat-FLAIR__spcir\"),\n        (\"AAHead_Scout_.*\", \"anat-scout\"),\n    ]\n    # e.g., QA:\n    # '43b67d9139e8c7274578b7451ab21123':\n    #     [\n    #      ('BOLD_p2_s4_3\\.5mm', 'func_task-rest_acq-p2-s4-3.5mm'),\n    #      ('BOLD_', 'func_task-rest'),\n    #      ('_p2_s4',        '_acq-p2-s4'),\n    #      ('_p2', '_acq-p2'),\n    #     ],\n    # '':  # for any study example with regexes used\n    #     [\n    #         ('AAHead_Scout_.*', 'anat-scout'),\n    #         ('^dti_.*', 'dwi'),\n    #         ('^.*_distortion_corr.*_([ap]+)_([12])', r'fmap-epi_dir-\\1_run-\\2'),\n    #         ('^(.+)_ap.*_r(0[0-9])', r'func_task-\\1_run-\\2'),\n    #         ('^t1w_.*', 'anat-T1w'),\n    #         # problematic case -- multiple identically named pepolar fieldmap runs\n    #         # I guess we will just sacrifice ability to detect canceled runs here.\n    #         # And we cannot just use _run+ since it would increment independently\n    #         # for ap and then for pa.  We will rely on having ap preceding pa.\n    #         # Added  _acq-mb8  so they match the one in funcs\n    #         ('func_task-discorr_acq-ap', r'fmap-epi_dir-ap_acq-mb8_run+'),\n    #         ('func_task-discorr_acq-pa', r'fmap-epi_dir-pa_acq-mb8_run='),\n    # ]\n}\n\n# list containing StudyInstanceUID to skip -- hopefully doesn't happen too often\ndicoms2skip: list[str] = [\n    # e.g.\n    # '1.3.12.2.1107.5.2.43.66112.30000016110117002435700000001',\n]\n\nDEFAULT_FIELDS = {\n    # Let it just be in each json file extracted\n    \"Acknowledgements\": \"See README.md.\",\n}\n\nPOPULATE_INTENDED_FOR_OPTS = {\n    \"matching_parameters\": [\"ImagingVolume\", \"Shims\"],\n    \"criterion\": \"Closest\",\n}\n\n\ndef filter_dicom(dcmdata: dcm.dataset.Dataset) -&gt; bool:\n    \"\"\"Return True if a DICOM dataset should be filtered out, else False\"\"\"\n    return True if dcmdata.StudyInstanceUID in dicoms2skip else False\n\n\ndef filter_files(_fn: str) -&gt; bool:\n    \"\"\"Return True if a file should be kept, else False.\n\n    ATM reproin does not do any filtering. Override if you need to add some\n    \"\"\"\n    return not _fn.endswith((\".csv\", \".dvs\"))\n\n\ndef fix_canceled_runs(seqinfo: list[SeqInfo]) -&gt; list[SeqInfo]:\n    \"\"\"Function that adds cancelme_ to known bad runs which were forgotten\"\"\"\n    if not fix_accession2run:\n        return seqinfo  # nothing to do\n    for i, s in enumerate(seqinfo):\n        accession_number = s.accession_number\n        if accession_number and accession_number in fix_accession2run:\n            lgr.info(\n                \"Considering some runs possibly marked to be \"\n                \"canceled for accession %s\",\n                accession_number,\n            )\n            # This code is reminiscent of prior logic when operating on\n            # a single accession, but left as is for now\n            badruns = fix_accession2run[accession_number]\n            badruns_pattern = \"|\".join(badruns)\n            if re.match(badruns_pattern, s.series_id):\n                lgr.info(\"Fixing bad run {0}\".format(s.series_id))\n                fixedkwargs = dict()\n                for key in series_spec_fields:\n                    fixedkwargs[key] = \"cancelme_\" + getattr(s, key)\n                seqinfo[i] = s._replace(**fixedkwargs)\n    return seqinfo\n\n\ndef fix_dbic_protocol(seqinfo: list[SeqInfo]) -&gt; list[SeqInfo]:\n    \"\"\"Ad-hoc fixup for existing protocols.\n\n    It will operate in 3 stages on `protocols2fix` records.\n    1. consider a record which has md5sum of study_description\n    2. apply all substitutions, where key is a regular expression which\n       successfully searches (not necessarily matches, so anchor appropriately)\n       study_description\n    3. apply \"catch all\" substitutions in the key containing an empty string\n\n    3. is somewhat redundant since `re.compile('.*')` could match any, but is\n    kept for simplicity of its specification.\n    \"\"\"\n\n    study_hash = get_study_hash(seqinfo)\n    study_description = get_study_description(seqinfo)\n\n    # We will consider first study specific (based on hash)\n    if study_hash in protocols2fix:\n        _apply_substitutions(\n            seqinfo, protocols2fix[study_hash], \"study (%s) specific\" % study_hash\n        )\n    # Then go through all regexps returning regex \"search\" result\n    # on study_description\n    for sub, substitutions in protocols2fix.items():\n        if isinstance(sub, re.Pattern) and sub.search(study_description):\n            _apply_substitutions(\n                seqinfo, substitutions, \"%r regex matching\" % sub.pattern\n            )\n    # and at the end - global\n    if \"\" in protocols2fix:\n        _apply_substitutions(seqinfo, protocols2fix[\"\"], \"global\")\n\n    return seqinfo\n\n\ndef fix_seqinfo(seqinfo: list[SeqInfo]) -&gt; list[SeqInfo]:\n    \"\"\"Just a helper on top of both fixers\"\"\"\n    # add cancelme to known bad runs\n    seqinfo = fix_canceled_runs(seqinfo)\n    seqinfo = fix_dbic_protocol(seqinfo)\n    return seqinfo\n\n\ndef create_key(template, outtype=(\"nii.gz\",), annotation_classes=None):\n    if template is None or not template:\n        raise ValueError(\"Template must be a valid format string\")\n    return template, outtype, annotation_classes\n\n\ndef infotodict(seqinfo):\n    \"\"\"Heuristic evaluator for determining which runs belong where\n\n    allowed template fields - follow python string module:\n\n    item: index within category\n    subject: participant id\n    seqitem: run number during scanning\n    subindex: sub index within group\n    \"\"\"\n    seqinfo = fix_seqinfo(seqinfo)\n    lgr.info(\"Processing %d seqinfo entries\", len(seqinfo))\n\n    t1w = create_key(\n        \"sub-{subject}/{session}/anat/sub-{subject}_{session}_acq-{acquisition}{run_entity}_T1w\"\n    )\n    t2w = create_key(\n        \"sub-{subject}/{session}/anat/sub-{subject}_{session}_acq-{acquisition}{run_entity}_T2w\"\n    )\n    t2_flair = create_key(\n        \"sub-{subject}/{session}/anat/sub-{subject}_{session}{run_entity}_FLAIR\"\n    )\n    dwi = create_key(\n        \"sub-{subject}/{session}/dwi/sub-{subject}_{session}_acq-{acq}_dir-{dir}{run_entity}_dwi\"\n    )\n    mag = create_key(\n        \"sub-{subject}/{session}/fmap/sub-{subject}_{session}{run_entity}_magnitude\"\n    )\n    phdiff = create_key(\n        \"sub-{subject}/{session}/fmap/sub-{subject}_{session}{run_entity}_phasediff\"\n    )\n    epi = create_key(\n        \"sub-{subject}/{session}/fmap/sub-{subject}_{session}\"\n        \"_acq-{acquisition}_dir-{dir}{run_entity}{part_entity}_epi\"\n    )\n    func = create_key(\n        \"sub-{subject}/{session}/func/sub-{subject}_{session}\"\n        \"_task-{task}{acq_entity}{dir_entity}{run_entity}{part_entity}_bold\"\n    )\n    sbref = create_key(\n        \"sub-{subject}/{session}/func/sub-{subject}_{session}_task-{task}{run_entity}_sbref\"\n    )\n\n    info = {\n        t1w: [],\n        t2w: [],\n        t2_flair: [],\n        dwi: [],\n        mag: [],\n        phdiff: [],\n        epi: [],\n        func: [],\n        sbref: [],\n    }\n    epi_mags = []\n    bold_mags = []\n\n    for s in seqinfo:\n        \"\"\"\n        The namedtuple `s` contains the following fields:\n\n        * total_files_till_now\n        * example_dcm_file\n        * series_id\n        * dcm_dir_name\n        * unspecified2\n        * unspecified3\n        * dim1\n        * dim2\n        * dim3\n        * dim4\n        * TR\n        * TE\n        * protocol_name\n        * is_motion_corrected\n        * is_derived\n        * patient_id\n        * study_description\n        * referring_physician_name\n        * series_description\n        * image_type\n        \"\"\"\n\n        # Ignore derived data and reports\n        if (\n            s.is_derived == \"True\"\n            or s.is_derived is True\n            or s.dcm_dir_name.split(\"_\")[-1] in IGNORE_PROTOCOLS\n        ):\n            continue\n\n        thisitem = {\n            \"item\": s.series_id,\n        }\n        thiskey = None\n        thisitem.update({k: v for k, v in bids_regex.findall(s.protocol_name)})\n        thisitem[\"run_entity\"] = f\"{thisitem.pop('run', '')}\"\n\n        if s.protocol_name.lower().startswith(\"anat-t1w\"):\n            thiskey = t1w\n            acquisition_present = thisitem.pop(\"acq\", None)\n            thisitem[\"acquisition\"] = (\n                (\"original\" if s.dcm_dir_name.endswith(\"_ND\") else \"undistorted\")\n                if not acquisition_present\n                else acquisition_present\n            )\n        elif s.protocol_name.lower().startswith(\"anat-t2w\"):\n            thiskey = t2w\n            acquisition_present = thisitem.pop(\"acq\", None)\n            thisitem[\"acquisition\"] = (\n                (\"original\" if s.dcm_dir_name.endswith(\"_ND\") else \"undistorted\")\n                if not acquisition_present\n                else \"unspecified\"\n            )\n        elif s.protocol_name.lower().startswith(\"anat-flair\"):\n            thiskey = t2_flair\n        elif s.protocol_name.startswith(\"dwi-dwi\"):\n            thiskey = dwi\n        elif s.protocol_name.startswith(\"fmap-phasediff\"):\n            thiskey = phdiff if \"P\" in s.image_type else mag\n        elif s.protocol_name.startswith(\"fmap-epi\"):\n            thiskey = epi\n            thisitem[\"part_entity\"] = \"\"\n            thisitem[\"acquisition\"] = (\n                \"b0\" if s.sequence_name.endswith(\"ep_b0\") else \"bold\"\n            )\n\n            # Check whether phase was written out:\n            # 1. A magnitude needs to exist immediately before in the dicom info\n            # 2. Magnitude and phase must have the same number of volumes\n            series_id_idx, series_id_name = s.series_id.split(\"-\", 1)\n            prev_series_id = f\"{int(series_id_idx) - 1}-{series_id_name}-{s.series_files}\"\n            if prev_series_id in epi_mags:\n                thisitem[\"part_entity\"] = \"_part-phase\"\n                info[thiskey][epi_mags.index(prev_series_id)][\"part_entity\"] = \"_part-mag\"\n\n            epi_mags.append(f\"{s.series_id}-{s.series_files}\")\n\n        elif s.protocol_name.startswith(\"func-bold\"):\n            # Likely an error\n            if s.series_files &lt; 100:\n                warn(\n                    f\"Dropping exceedingly short BOLD file with {s.series_files} time points.\"\n                )\n                continue\n\n            thiskey = func\n\n            thisitem[\"part_entity\"] = \"\"\n            # Some functional runs may come with acq\n            func_acq = thisitem.pop(\"acq\", None)\n            thisitem[\"acq_entity\"] = \"\" if not func_acq else f\"_acq-{func_acq}\"\n\n            # Some functional runs may come with dir\n            func_dir = thisitem.pop(\"dir\", None)\n            thisitem[\"dir_entity\"] = \"\" if not func_dir else f\"_dir-{func_dir}\"\n\n            # Check whether phase was written out:\n            # 1. A magnitude needs to exist immediately before in the dicom info\n            # 2. Magnitude and phase must have the same number of volumes\n            series_id_idx, series_id_name = s.series_id.split(\"-\", 1)\n            prev_series_id = f\"{int(series_id_idx) - 1}-{series_id_name}-{s.series_files}\"\n            if prev_series_id in bold_mags:\n                thisitem[\"part_entity\"] = \"_part-phase\"\n                info[thiskey][bold_mags.index(prev_series_id)][\"part_entity\"] = \"_part-mag\"\n\n            bold_mags.append(f\"{s.series_id}-{s.series_files}\")\n\n        if thiskey is not None:\n            info[thiskey].append(thisitem)\n\n    for mod, items in info.items():\n        if len(items) &lt; 2:\n            continue\n\n        info[mod] = _assign_run_on_repeat(items)\n\n    return info\n\n\ndef _assign_run_on_repeat(modality_items):\n    \"\"\"\n    Assign run IDs for repeated inputs for a given modality.\n\n    Examples\n    --------\n    &gt;&gt;&gt; _assign_run_on_repeat([\n    ...     {\"item\": \"discard1\", \"acq\": \"bold\", \"dir\": \"PA\"},\n    ...     {\"item\": \"discard2\", \"acq\": \"bold\", \"dir\": \"AP\"},\n    ...     {\"item\": \"discard3\", \"acq\": \"bold\", \"dir\": \"PA\"},\n    ... ])  # doctest: +NORMALIZE_WHITESPACE\n    [{'item': 'discard1', 'acq': 'bold', 'dir': 'PA', 'run_entity': '_run-1'},\n     {'item': 'discard2', 'acq': 'bold', 'dir': 'AP'},\n     {'item': 'discard3', 'acq': 'bold', 'dir': 'PA', 'run_entity': '_run-2'}]\n\n    &gt;&gt;&gt; _assign_run_on_repeat([\n    ...     {\"item\": \"discard1\", \"acq\": \"bold\", \"dir\": \"PA\"},\n    ...     {\"item\": \"discard2\", \"acq\": \"bold\", \"dir\": \"AP\"},\n    ...     {\"item\": \"discard3\", \"acq\": \"bold\", \"dir\": \"PA\"},\n    ...     {\"item\": \"discard4\", \"acq\": \"bold\", \"dir\": \"AP\"},\n    ... ])  # doctest: +NORMALIZE_WHITESPACE\n    [{'item': 'discard1', 'acq': 'bold', 'dir': 'PA', 'run_entity': '_run-1'},\n     {'item': 'discard2', 'acq': 'bold', 'dir': 'AP', 'run_entity': '_run-1'},\n     {'item': 'discard3', 'acq': 'bold', 'dir': 'PA', 'run_entity': '_run-2'},\n     {'item': 'discard4', 'acq': 'bold', 'dir': 'AP', 'run_entity': '_run-2'}]\n\n    &gt;&gt;&gt; _assign_run_on_repeat([\n    ...     {\"item\": \"discard1\", \"acq\": \"bold\", \"dir\": \"PA\", \"run\": \"1\"},\n    ...     {\"item\": \"discard2\", \"acq\": \"bold\", \"dir\": \"AP\"},\n    ...     {\"item\": \"discard3\", \"acq\": \"bold\", \"dir\": \"PA\", \"run\": \"2\"},\n    ... ])  # doctest: +NORMALIZE_WHITESPACE\n    [{'item': 'discard1', 'acq': 'bold', 'dir': 'PA', 'run': '1'},\n     {'item': 'discard2', 'acq': 'bold', 'dir': 'AP'},\n     {'item': 'discard3', 'acq': 'bold', 'dir': 'PA', 'run': '2'}]\n\n    &gt;&gt;&gt; _assign_run_on_repeat([\n    ...     {\"item\": \"discard1\", \"acq\": \"bold\", \"dir\": \"PA\", \"run_entity\": \"_run-1\"},\n    ...     {\"item\": \"discard2\", \"acq\": \"bold\", \"dir\": \"AP\"},\n    ...     {\"item\": \"discard3\", \"acq\": \"bold\", \"dir\": \"PA\", \"run_entity\": \"_run-2\"},\n    ... ])  # doctest: +NORMALIZE_WHITESPACE\n    [{'item': 'discard1', 'acq': 'bold', 'dir': 'PA', 'run_entity': '_run-1'},\n     {'item': 'discard2', 'acq': 'bold', 'dir': 'AP'},\n     {'item': 'discard3', 'acq': 'bold', 'dir': 'PA', 'run_entity': '_run-2'}]\n\n    &gt;&gt;&gt; _assign_run_on_repeat([\n    ...     {\"item\": \"discard1\", \"acq\": \"bold\", \"dir\": \"PA\", \"part_entity\": \"_part-mag\"},\n    ...     {\"item\": \"discard2\", \"acq\": \"bold\", \"dir\": \"PA\", \"part_entity\": \"_part-phase\"},\n    ...     {\"item\": \"discard3\", \"acq\": \"bold\", \"dir\": \"AP\", \"part_entity\": \"_part-mag\"},\n    ...     {\"item\": \"discard4\", \"acq\": \"bold\", \"dir\": \"AP\", \"part_entity\": \"_part-phase\"},\n    ... ])  # doctest: +NORMALIZE_WHITESPACE\n    [{'item': 'discard1', 'acq': 'bold', 'dir': 'PA', 'part_entity': '_part-mag'},\n     {'item': 'discard2', 'acq': 'bold', 'dir': 'PA', 'part_entity': '_part-phase'},\n     {'item': 'discard3', 'acq': 'bold', 'dir': 'AP', 'part_entity': '_part-mag'},\n     {'item': 'discard4', 'acq': 'bold', 'dir': 'AP', 'part_entity': '_part-phase'}]\n\n    \"\"\"\n    modality_items = modality_items.copy()\n\n    str_patterns = [\n        \"_\".join([f\"{s[0]}-{s[1]}\" for s in item.items() if s[0] != \"item\"])\n        for item in modality_items\n    ]\n    strcount = Counter(str_patterns)\n\n    for string, count in strcount.items():\n        if count &lt; 2:\n            continue\n\n        runid = 1\n\n        for index, item_string in enumerate(str_patterns):\n            if string == item_string:\n                modality_items[index].update(\n                    {\n                        \"run_entity\": f\"_run-{runid}\",\n                    }\n                )\n                runid += 1\n\n    return modality_items\n</code></pre> <p>During piloting, we changed a number of settings</p> <p>For example, the first four sessions did not follow Reproin conventions and filenames varied substantially. Please note the <code>protocols2fix</code> variable in our heuristic file, where the compatibility is implemented.</p> <ul> <li> <p> Run HeuDiConv with our heuristic file <code>&lt;path&gt;/code/heudiconv/reproin.py</code>:</p> Executing HeuDiConv<pre><code>#!/bin/bash\nheudiconv -s \"001\" -ss \"pilot001\" -b -l . -o /data/datasets/hcph/ \\\n          -f &lt;sops_clone_path&gt;/code/heudiconv/reproin.py \\\n          --files /data/datasets/hcph-pilot-sourcedata/\\\n                  sub-01/\\\n                  ses-18950702/\n</code></pre> <p>Session number MUST be updated manually</p> Example of the dataset organization <p>Piloting sessions 15 and 16 look like this:</p> <pre><code>\u251c\u2500\u2500 ses-pilot015\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 anat\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-original_T1w.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-original_T1w.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-undistorted_T1w.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-undistorted_T1w.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_T2w.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot015_T2w.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dwi\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-highres_dir-LR_dwi.bval\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-highres_dir-LR_dwi.bvec\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-highres_dir-LR_dwi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot015_acq-highres_dir-LR_dwi.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fmap\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-b0_dir-RL_epi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-b0_dir-RL_epi.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-bold_dir-RL_part-mag_epi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-bold_dir-RL_part-mag_epi.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-bold_dir-RL_part-phase_epi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_acq-bold_dir-RL_part-phase_epi.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_magnitude1.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_magnitude1.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_magnitude2.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_magnitude2.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_phasediff.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot015_phasediff.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 func\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_part-mag_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-bht_part-phase_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_part-mag_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-qct_part-phase_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot015_task-rest_part-mag_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot015_task-rest_part-phase_events.tsv\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot015_scans.tsv\n\u2514\u2500\u2500 ses-pilot016\n    \u251c\u2500\u2500 anat\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-original_T1w.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-original_T1w.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-undistorted_T1w.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-undistorted_T1w.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_T2w.json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot016_T2w.nii.gz\n    \u251c\u2500\u2500 dwi\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-highres_dir-RL_dwi.bval\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-highres_dir-RL_dwi.bvec\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-highres_dir-RL_dwi.json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot016_acq-highres_dir-RL_dwi.nii.gz\n    \u251c\u2500\u2500 fmap\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-AP_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-AP_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-LR_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-LR_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-PA_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-PA_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-RL_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-b0_dir-RL_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-AP_part-mag_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-AP_part-mag_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-AP_part-phase_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-AP_part-phase_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-LR_part-mag_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-LR_part-mag_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-LR_part-phase_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-LR_part-phase_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-PA_part-mag_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-PA_part-mag_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-PA_part-phase_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-PA_part-phase_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-RL_part-mag_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-RL_part-mag_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-RL_part-phase_epi.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_acq-bold_dir-RL_part-phase_epi.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_magnitude1.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_magnitude1.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_magnitude2.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_magnitude2.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_phasediff.json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot016_phasediff.nii.gz\n    \u251c\u2500\u2500 func\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-1_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-1_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-1_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-1_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-2_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-2_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-2_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-2_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-3_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-3_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-3_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-3_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-4_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-4_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-4_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_echo-4_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_part-mag_events.tsv\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-bht_part-phase_events.tsv\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-1_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-1_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-1_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-1_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-2_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-2_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-2_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-2_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-3_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-3_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-3_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-3_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-4_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-4_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-4_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_echo-4_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_part-mag_events.tsv\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-qct_part-phase_events.tsv\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-1_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-1_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-1_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-1_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-2_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-2_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-2_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-2_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-3_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-3_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-3_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-3_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-4_part-mag_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-4_part-mag_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-4_part-phase_bold.json\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_echo-4_part-phase_bold.nii.gz\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot016_task-rest_part-mag_events.tsv\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot016_task-rest_part-phase_events.tsv\n    \u2514\u2500\u2500 sub-001_ses-pilot016_scans.tsv\n</code></pre> We started to generate phase and magnitude only after session 15 <p>As a result, the piloting data up to session 14 will look more like:</p> <pre><code>\u251c\u2500\u2500 ses-pilot014\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 anat\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-original_T1w.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-original_T1w.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-undistorted_T1w.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-undistorted_T1w.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_T2w.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot014_T2w.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dwi\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-highres_dir-PA_dwi.bval\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-highres_dir-PA_dwi.bvec\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-highres_dir-PA_dwi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot014_acq-highres_dir-PA_dwi.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fmap\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-b0_dir-AP_epi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-b0_dir-AP_epi.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-bold_dir-PA_run-1_epi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-bold_dir-PA_run-1_epi.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-bold_dir-PA_run-2_epi.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_acq-bold_dir-PA_run-2_epi.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_magnitude1.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_magnitude1.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_magnitude2.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_magnitude2.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_phasediff.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot014_phasediff.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 func\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-1_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-1_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-2_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-2_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-3_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-3_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-4_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_echo-4_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-1_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-1_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-2_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-2_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-3_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-3_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-4_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_echo-4_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-1_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-1_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-1_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-2_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-2_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-3_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-3_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-4_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_echo-4_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-bht_run-2_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-1_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-1_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-2_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-2_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-3_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-3_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-4_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_echo-4_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-qct_events.tsv\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-1_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-1_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-2_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-2_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-3_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-3_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-4_bold.json\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-pilot014_task-rest_echo-4_bold.nii.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot014_task-rest_events.tsv\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-pilot014_scans.tsv\n</code></pre> </li> <li> <p> Delete incorrect files generated by HeuDiConv:     <pre><code>find sub-001/ -name \"*_part-mag_events.tsv\" -or -name \"*_part-phase_events.tsv\" | xargs rm\n</code></pre></p> </li> </ul>"},{"location":"data-management/post-session/#generate-bids-events-files","title":"Generate BIDS' events files","text":"<ul> <li> Execute the script <code>write_event_file.py</code> as shown below to generate task event files.     This script creates JSON and TSV files containing event information and generates PNG plots for each task, displaying both physiological data and corresponding events.     These plots are saved in the current directory.     The script must be executed with the following command, where <code>outputdir</code> is the output directory of phys2bids:     <pre><code>python write_event_file.py --path ./outputdir/sub-001/ses-pilot016/func/\n</code></pre></li> </ul> Example of a session with events files <p>The corresponding events files are highlighted below:</p> <pre><code>ses-024\n\u251c\u2500\u2500 anat\n\u251c\u2500\u2500 dwi\n\u251c\u2500\u2500 fmap\n\u251c\u2500\u2500 func\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_events.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_events.tsv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_events.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_events.tsv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_events.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_events.tsv\n\u2514\u2500\u2500 sub-001_ses-024_scans.tsv\n</code></pre>"},{"location":"data-management/post-session/#convert-physiological-recordings-into-bids-in-house","title":"Convert physiological recordings into BIDS (in-house)","text":"<ul> <li> Update the appropriate session number within cell 3 in the conversion Jupyter notebook.</li> <li> Execute the notebook.</li> </ul> Example of a session with physiological recordings <p>The execution of the notebook on session 24 yields the following new outputs (highlighted):</p> <pre><code>ses-024\n\u251c\u2500\u2500 anat\n\u251c\u2500\u2500 dwi\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_dwi.bval\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_dwi.bvec\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_dwi.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_dwi.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_recording-cardiac_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_recording-respiratory_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_stim.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-024_acq-highres_dir-AP_stim.tsv.gz\n\u251c\u2500\u2500 fmap\n\u251c\u2500\u2500 func\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_recording-cardiac_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_recording-cardiac_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_recording-respiratory_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_recording-respiratory_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_stim.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_stim.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_recording-cardiac_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_recording-respiratory_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_stim.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_stim.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_recording-cardiac_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_recording-respiratory_physio.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_stim.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_stim.tsv.gz\n\u2514\u2500\u2500 sub-001_ses-024_scans.tsv\n</code></pre>"},{"location":"data-management/post-session/#convert-eye-tracking-into-bids-with-bidsphysio","title":"Convert eye-tracking into BIDS with bidsphysio","text":"<p>Instead of the current specifications, we are using the following BEP</p> <ul> <li> Pull the latest docker image of esavary/bidsphysio with:     <pre><code>docker pull esavary/bidsphysio\n</code></pre></li> <li> Open <code>schedule.tsv</code> to find the phase encoding direction and the name of the <code>.EDF</code> file corresponding to the session you want to convert.</li> <li> Create a new folder named <code>metadata/</code> inside the folder containing the target <code>.EDF</code> file.     Copy the file containing information about the ET, named <code>info_ET.json</code> into the <code>metadata/</code> folder.</li> <li> Execute the ET to BIDS conversion on the dMRI data.     Run the following command for the corresponding file in the <code>schedule.tsv</code> file:     <pre><code>docker run -u $( id -u ):$( id -g ) --rm -it \\\n    -v &lt;path-to-EDF-data&gt;:/data \\\n    -v &lt;output-path-on-host&gt;:/output \\\n    --entrypoint=/opt/venv/bin/python bidsphysio /opt/venv/bin/edf2bidsphysio \\\n    --infile /data/fixation_2023-10-20_18h48.03.561_5_session_1.EDF \\\n    --bidsprefix /output/session01/dwi/sub-001_ses-001_acq-highres_dir-LR \\\n    -m /data/metadata/info_ET.json\n</code></pre></li> <li> Run the following command for the files corresponding to the functional tasks:     <pre><code>docker run -u $( id -u ):$( id -g ) --rm -it \\\n    -v &lt;path-to-EDF-data&gt;:/data \\\n    -v &lt;output-path-on-host&gt;:/output \\\n    --entrypoint=/opt/venv/bin/python bidsphysio /opt/venv/bin/edf2bidsphysio \\\n    --infile /data/qct_2023-10-20_19h40.38.964_2_session_1.EDF \\\n    --bidsprefix /output/session01/func/sub-001_ses-001_task-qct_dir-LR \\\n    -m /data/metadata/info_ET.json\n</code></pre></li> <li> Copy all <code>&lt;prefix&gt;_eyetrack.tsv.gz</code> and <code>&lt;prefix&gt;_eyetrack.json</code> generated into your copy of the DataLad dataset in BIDS.</li> </ul> <p>Do not copy all output files directly</p> <p>In addition to the eye-tracking data (<code>&lt;prefix&gt;_eyetrack.tsv.gz</code> file) and metadata (<code>&lt;prefix&gt;_eyetrack.json</code> file), the code also generates a TSV file containing all messages sent to the ET and the header of the <code>.EDF</code> file (with name <code>&lt;prefix&gt;_eventlist_raw.tsv</code>). Please do not copy these generated files into the DataLad dataset in BIDS.</p> Example of a session with eye-tracking recordings <p>The files corresponding to eye-tracking are highlighted below:</p> <pre><code>ses-024\n\u251c\u2500\u2500 anat\n\u251c\u2500\u2500 dwi\n\u251c\u2500\u2500 fmap\n\u251c\u2500\u2500 func\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_eyetrack.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-bht_dir-AP_eyetrack.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_eyetrack.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-qct_dir-AP_eyetrack.tsv.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-1_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-2_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-3_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-mag_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_echo-4_part-phase_bold.nii.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_eyetrack.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sub-001_ses-024_task-rest_dir-AP_eyetrack.tsv.gz\n\u2514\u2500\u2500 sub-001_ses-024_scans.tsv\n</code></pre>"},{"location":"data-management/post-session/#add-new-data-to-the-datalad-dataset","title":"Add new data to the DataLad dataset","text":"<p>As new sessions are collected, the corresponding BIDS structures MUST be saved within the DataLad dataset and pushed to remote storage systems:</p> <ul> <li> <p> Save the files in the dataset history using the command below.     Replace <code>&lt;session_id&gt;</code> below with the number of the session (e.g., <code>pilot017</code>):     <pre><code>datalad save -r -m \"add: session &lt;session_id&gt;\" sub-001/ses-&lt;session_id&gt;\n</code></pre></p> <p>Always double-check that data are annexed and the metadata committed to git</p> <p>Although the creation of a procedure should ensure data and metadata are added to the appropriate version control (Git or Git-Annex), it is possible that some metadata or data formats are not anticipated, or do not follow the general rules.</p> <p>A generally good strategy is to avoid recursion (i.e., do not use the <code>-r</code> flag), and leverage Bash's <code>find</code> and <code>xargs</code> tools. For example, the following command line selects metadata files that should be committed to Git within one session (<code>pilot020</code>) and saves them:</p> <pre><code>find sub-001/ses-pilot020 -name \"*.tsv\" -or -name \"*.json\" -or -name \"*.bvec\" -or -name \"*.bval\" | xargs datalad save --to-git -m '\"add(pilot020): new session metadata\"'\n</code></pre> <p>Correspondingly, we can store NIfTI data and physiological information:</p> <pre><code>find sub-001/ses-pilot020 -name \"*.nii.gz\" -or -name \"*_eyetrack.tsv.gz\" -or -name \"*_physio.tsv.gz\" -or -name \"*_stim.tsv.gz\" | xargs datalad save -m '\"add(pilot020): new session NIfTI data, eye tracking and physio\"'\n</code></pre> <p>Please read DataLad's <code>save</code> documentation</p> <p>If you overeagerly datalad-saved too many files</p> <p>You can revert the <code>datalad save</code> operation without deleting changes with:</p> <pre><code>git reset --mixed COMMIT\n</code></pre> <p>where <code>COMMIT</code> is the hash of the last commit you want to keep (all the later commits will be dropped).</p> <p>To check the commit hash where you can roll history back to, you may want to use:</p> <pre><code>git log -50 --oneline\n</code></pre> <p>Saving batches of sessions</p> <p>It is possible to save several sessions with the following Bash script by enumerating them in the array defined in the first line here:</p> <pre><code>SESSIONS=( 001 003 pilot21 ); \\\nfor SESSION in ${SESSIONS[@]}; do \\\n    find sub-001/ses-$SESSION -name \"*.tsv\" -or -name \"*.json\" -or -name \"*.bvec\" -or -name \"*.bval\" | xargs datalad save --to-git -m '\"add('\"$SESSION\"'): new session metadata\"'; \\\n    find sub-001/ses-$SESSION -name \"*.nii.gz\" -or -name \"*_eyetrack.tsv.gz\" -or -name \"*_physio.tsv.gz\" -or -name \"*_stim.tsv.gz\" | xargs datalad save -m '\"add('\"$SESSION\"'): new session NIfTI data, eye tracking and physio\"'; \\\ndone\n</code></pre> </li> <li> <p> Push the new data to the remote storage (if your git containing DataLad and the Git annex is different from <code>origin</code>, e.g., <code>github</code>, replace the name below):     <pre><code>datalad push --to ria-storage\ndatalad push --to origin\n</code></pre></p> <p>Always double-check that data in the annex are uploaded to the RIA store</p> </li> </ul>"},{"location":"data-management/post-session/#visual-assessment-of-unprocessed-data-with-mriqc","title":"Visual assessment of unprocessed data with MRIQC","text":"<p>Checking the data quality shortly after they are acquired increases the likelihood of catching systematic artifacts early enough to avert spreading throughout the whole dataset. It also modulates the burden of visual inspection over time, such that we avoid overwhelming raters with outbursts of images to assess. Better pacing in rating throughput also contributes to reducing raters' attrition and fatigue.</p> <ul> <li> Screen all the unprocessed data and assess them as described in the next section.</li> </ul>"},{"location":"data-management/preliminary/","title":"Before data acquisition (storage preparation)","text":"<p>DataLad must be version 0.19 or later</p> <p>This project maintains data under version control thanks to DataLad<sup>1</sup>. For instructions on how to setup DataLad on your PC, please refer to the official documentation. When employing high-performance computing (HPC), we provide some specific guidelines.</p> <p>Please read the DataLad Handbook, especially if you are new to this tool</p>"},{"location":"data-management/preliminary/#creating-a-datalad-dataset","title":"Creating a DataLad dataset","text":"<ul> <li> Designate a host and folder where data will be centralized.     In the context of this study, the primary copy of data will be downloaded into &lt;hostname&gt;, under the path <code>/data/datasets/hcph-pilot-sourcedata</code> for the piloting acquisitions and <code>/data/datasets/hcph-sourcedata</code> for the experimental data collection.</li> <li> <p> Install the <code>bids</code> DataLad procedure provided from this repository to facilitate the correct intake of data and metadata:</p> <pre><code>PYTHON_SITE_PACKAGES=$( python -c 'import sysconfig; print(sysconfig.get_paths()[\"purelib\"])' )\nln -s &lt;path&gt;/code/datalad/cfg_bids.py ${PYTHON_SITE_PACKAGES}/datalad/resources/procedures/\n</code></pre> DataLad's documentation does not recommend this approach <p>For safety, you can prefer to use DataLad's recommendations and place the <code>cfg_bids.py</code> file in some of the suggested paths.</p> </li> <li> <p> Check the new procedure is available as <code>bids</code>:</p> <pre><code>$ datalad run-procedure --discover\ncfg_bids (/home/oesteban/.miniconda/lib/python3.9/site-packages/datalad/resources/procedures/cfg_bids.py) [python_script]\ncfg_yoda (/home/oesteban/.miniconda/lib/python3.9/site-packages/datalad/resources/procedures/cfg_yoda.py) [python_script]\ncfg_metadatatypes (/home/oesteban/.miniconda/lib/python3.9/site-packages/datalad/resources/procedures/cfg_metadatatypes.py) [python_script]\ncfg_text2git (/home/oesteban/.miniconda/lib/python3.9/site-packages/datalad/resources/procedures/cfg_text2git.py) [python_script]\ncfg_noannex (/home/oesteban/.miniconda/lib/python3.9/site-packages/datalad/resources/procedures/cfg_noannex.py) [python_script]\n</code></pre> <p>Learn more about the YODA principles (DataLad Handbook)</p> </li> <li> <p> Create a DataLad dataset for the original dataset:</p> <pre><code>cd /data/datasets/\ndatalad create -c bids hcph-dataset\n</code></pre> </li> </ul> <ul> <li> <p> Configure a RIA store, where large files will be pushed (and pulled from when installing the dataset in other computers)     Creating a RIA sibling to store large files<pre><code>cd hcph-dataset\ndatalad create-sibling-ria -s ria-storage --alias hcph-dataset \\\n        --new-store-ok --storage-sibling=only \\\n        \"ria+ssh://&lt;username&gt;@&lt;hostname&gt;:&lt;path&gt;/dataset/\"\n</code></pre></p> </li> <li> <p> Configure a GitHub sibling, to host the Git history and the annex metadata:     Creating a GitHub sibling to store DataLad's infrastructure and dataset's metadata<pre><code>datalad siblings add --dataset . --name github \\\n        --pushurl git@github.com:&lt;organization&gt;/&lt;repo_name&gt;.git \\\n        --url https://github.com/&lt;organization&gt;/&lt;repo_name&gt;.git \\\n        --publish-depends ria-storage\n</code></pre></p> </li> <li> <p> Create a sub-dataset to host the MRIQC derivatives.     Remember to set the correct version of the container (in our case 23.1.0).     <pre><code>cd /data/datasets/hcph-dataset\ndatalad create -d . derivatives/mriqc-23.1.0\n</code></pre></p> </li> </ul>"},{"location":"data-management/preliminary/#client-side-operations-when-consuming-the-data","title":"Client side operations (when consuming the data)","text":""},{"location":"data-management/preliminary/#installing-the-datalad-dataset","title":"Installing the DataLad dataset","text":"<p>Wherever you want to process the data, you'll need to <code>datalad install</code> it before you can pull down (<code>datalad get</code>) the data. To access the metadata (e.g., sidecar JSON files of the BIDS structure), you'll need to have access to the git repository that corresponds to the data (https://github.com/&lt;organization&gt;/&lt;repo_name&gt;.git) To fetch the dataset from the RIA store, you will need your SSH key be added to the authorized keys.</p> Getting access to the RIA store <p>These steps must be done just once before you can access the dataset's data:</p> <ul> <li> Create a secure SSH key on the system(s) on which you want to install the dataset.</li> <li> Send the SSH public key you just generated (e.g., <code>~/.ssh/id_ed25519.pub</code>) over email to Oscar at *@****.</li> </ul> <ul> <li> <p> Install and get the dataset normally:</p> Installing the dataset without fetching data from annexInstalling the dataset and fetch all data from annex, with 8 parallel threads <pre><code>datalad install https://github.com/&lt;organization&gt;/&lt;repo_name&gt;.git\n</code></pre> <pre><code>datalad install -g -J 8 https://github.com/&lt;organization&gt;/&lt;repo_name&gt;.git\n</code></pre> </li> </ul>"},{"location":"data-management/preliminary/#synchronizing-your-datalad-dataset","title":"Synchronizing your DataLad dataset","text":"<p>Once the dataset is installed, new sessions will be added as data collection goes on. When a new session is added, your DataLad dataset will remain at the same point in history (meaning, it will become out-of-date).</p> <ul> <li> <p> Pull new changes in the git history.     DataLad will first fetch Git remotes and merge for you.</p> <pre><code>cd hcph-dataset/  # &lt;--- cd into the dataset's path\ndatalad update -r --how merge\n</code></pre> </li> <li> <p> If you need the data, now you can get the data as usual:</p> <pre><code>find sub-001/ses-pilot019 -name \"*.nii.gz\" | xargs datalad get -J 8\n</code></pre> </li> </ul>"},{"location":"data-management/preliminary/#adding-data-or-metadata","title":"Adding data or metadata","text":"<ul> <li> <p> Use <code>datalad save</code> indicating the paths you want to add, and include <code>--to-git</code> if the file contains only metadata (e.g., JSON files).</p> Adding data files (e.g., NIfTI and compressed TSV files)Adding metadata files <pre><code>find sub-001/ses-pilot019 -name \"*.nii\" -or -name \"*.nii.gz\" -or -name \"*.tsv.gz\" | \\\n    xargs datalad save -m '\"add(pilot019): new session data (NIfTI and compressed TSV)\"'\n</code></pre> <pre><code>find sub-001/ses-pilot019 -name \"*.json\" -or -name \"*.tsv\" -or -name \"*.bvec\" -or -name \"*.bval\" | \\\n    xargs datalad save -m '\"add(pilot019): new session metadata (JSON, TSV, bvec/bval)\"'\n</code></pre> </li> </ul>"},{"location":"data-management/preliminary/#registering-containers","title":"Registering containers","text":"<p>We use DataLad containers-run to execute software while keeping track of provenance. Prior to first use, containers must be added to DataLad as follows (example for MRIQC):</p> <ul> <li> <p> Register the MRIQC container to the dataset</p> Registering a Singularity containerRegistering a Docker container <pre><code>datalad containers-add \\\n    --call-fmt 'singularity exec -B {{${HOME}/tmp/}}:/tmp --cleanenv {img} {cmd}' \\\n    mriqc \\\n    --url docker://nipreps/mriqc:23.1.0\n</code></pre> Insert relevant arguments to the <code>singularity</code> command line with <code>--call-fmt</code> <p>In the example above, we configure the container's call to automatically bind (<code>-B</code> flag to mount the filesystem) the temporary folder. MRIQC will store the working directory there by default. Please replace the path with the appropriate path for your settings (i.e., laptop, cluster, etc.).</p> <pre><code>datalad containers-add \\\n    --call-fmt 'docker run -v {{${HOME}/tmp/}}:/tmp --cleanenv {img} {cmd}' \\\n    mriqc \\\n    --url docker://nipreps/mriqc:23.1.0\n</code></pre> Pinning a particular version of MRIQC <p>If a different version of MRIQC should be executed, replace the Docker image's tag (<code>23.1.0</code>) with the adequate version tag within the above command line.</p> </li> </ul>"},{"location":"data-management/preliminary/#hpc-users-instructions-to-install-datalad","title":"HPC users - instructions to install DataLad","text":"<p>When HPC is planned for processing, DataLad will be required on that system(s).</p> <ul> <li> <p> Start an interactive session on the HPC cluster</p> Do not run the installation of Conda and DataLad in the login node <p>HPC systems typically recommend using their login nodes only for tasks related to job submission, data management, and preparing jobscripts. Therefore, the execution of resource-intensive tasks such as fMRIPrep or building containers on login nodes can negatively impact the overall performance and responsiveness of the system for all users. Interactive sessions are a great alternative when available and should be used when creating the DataLad dataset. For example, in the case of systems operating SLURM, the following command would open a new interactive session: <pre><code>srun --nodes=1 --ntasks-per-node=1 --time=01:00:00 --pty bash -i\n</code></pre></p> </li> <li> <p> Install DataLad.     Generally, the most convenient and user-sandboxed installation (i.e., without requiring elevated permissions) can be achieved by using Conda, but other alternatives (such as lmod) can be equally valid:</p> Install DataLad with CondaInstall DataLad in HPC with lmod enabled <ul> <li> <p> Get and install Conda if it is not already deployed in the system:</p> <pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nbash Miniconda3-latest-Linux-x86_64.sh\n</code></pre> </li> <li> <p> Install DataLad:</p> <pre><code>conda install -c conda-forge -y \"datalad&gt;=0.19\" datalad-container\n</code></pre> </li> </ul> <ul> <li> <p> Check the availability and dependencies for a specific Python version (here we check 3.8.2):</p> <pre><code>module spider Python/3.8.2\n</code></pre> </li> <li> <p> Load Python (please note <code>ml</code> below is a shorthand for <code>module load</code>)</p> <pre><code>ml GCCcore/9.3.0 Python/3.8.2\n</code></pre> </li> <li> <p> Update pip:</p> <pre><code>python -m pip --user -U pip\n</code></pre> </li> <li> <p> Install DataLad:</p> <pre><code>python -m pip install --user \"datalad&gt;=0.19\" datalad-container\n</code></pre> </li> </ul> </li> <li> <p> Check datalad is properly installed, for instance:</p> <pre><code>$ datalad --version\ndatalad 0.19.2\n</code></pre> DataLad crashes (Conda installations) <p>DataLad may fail with the following error: <pre><code>ImportError: cannot import name 'getargspec' from 'inspect' (/home/users/cprovins/miniconda3/lib/python3.11/inspect.py)\n</code></pre></p> <p>In such a scenario, create a Conda environment with a lower version of Python, and re-install datalad <pre><code>conda create -n \"datalad\" python=3.10\nconda activate datalad\nconda install -c conda-forge datalad datalad-container\n</code></pre></p> </li> <li> <p> Configure your Git identity settings.</p> <pre><code>cd ~\ngit config --global --add user.name \"Jane Doe\"\ngit config --global --add user.email doe@example.com\n</code></pre> </li> </ul>"},{"location":"processing/functional-connectivity/","title":"Extracting functional connectivity","text":""},{"location":"processing/functional-connectivity/#computing-functional-connectivity","title":"Computing functional connectivity","text":"<p>First, make sure that the preprocessed fMRI data are available as <code>derivatives</code> in your dataset. An example of data structure should be as follows: <pre><code>\u251c\u2500\u2500 derivatives\n\u2502   \u251c\u2500\u2500 fmriprep-23.1.4\n\u2502   \u2502   \u251c\u2500\u2500 dataset_description.json\n\u2502   \u2502   \u2514\u2500\u2500 sub-pilot\n\u2502   \u2502       \u251c\u2500\u2500 anat\n\u2502   \u2502       \u251c\u2500\u2500 figures\n\u2502   \u2502       \u2514\u2500\u2500 ses-15\n</code></pre></p> <p>Then, the functional connectivity matrices can be computed using the <code>compute_fc.py</code> script. The simplest call of the script only needs a derivative dataset (usually from fMRIPrep). Following the above data structure, it would be called as follows: <pre><code>python compute_fc.py path_to_dataset/derivatives/fmriprep-23.1.4\n</code></pre></p> Default call of the <code>compute_fc.py</code> script <p>When using the default options, the pipeline will (in this order and for all functional tasks):</p> <ul> <li> Fetch the DiFuMo atlas (64 dimensions)</li> <li> Extract the region-wise averaged timeseries</li> <li> Find high motion volumes that have framewise displacement higher than 0.4 mm or higher than 5 standardized DVAR. Then also flag as outlier the segments that are shorter than 5 timepoints.</li> <li> Interpolate high motion volumes with cubic spline interpolation</li> <li> Apply a low-pass butterworth filter (cutoff frequency of 0.15 Hz)</li> <li> Censor high motion volumes</li> <li> Remove confounds: motions (6 parameters) and discrete cosine transform basis (high-pass filtering)</li> <li> Standardize the timeseries</li> <li> Compute the functional connectivity matrices as the sparse inverse covariance (see this example, using Graphical Lasso CV of scikit-learn)</li> </ul> <p>Most parameters of the pipeline can be specified in the options (see <code>python compute_fc.py -h</code> for more details).</p> <p>Finally, the pipeline will save the denoised timeseries and connectivity matrices as well as various visual reports (i.e., figures).</p> Example of visual report <ul> <li> Denoising confounds as a design matrix: </li> <li> Denoised timeseries as a carpet plot: </li> <li> Denoised timeseries as a signal plot: </li> <li> Functional connetivity matrix as a heatmap: </li> </ul> <p>The outputs will be stored in a <code>functional-connectivity</code> folder in the same parent directory as the preprocessed derivatives dataset. In the end, the data structure will look like this: <pre><code>\u251c\u2500\u2500 derivatives\n\u2502   \u251c\u2500\u2500 fmriprep-23.1.4\n\u2502   \u2502   \u2514\u2500\u2500 sub-pilot\n\u2502   \u2502       \u251c\u2500\u2500 anat\n\u2502   \u2502       \u251c\u2500\u2500 figures\n\u2502   \u2502       \u2514\u2500\u2500 ses-15\n\u2502   \u2502           \u251c\u2500\u2500 anat\n\u2502   \u2502           \u2514\u2500\u2500 func\n\u2502   \u2514\u2500\u2500 functional_connectivity\n\u2502       \u2514\u2500\u2500 DiFuMo64-LP\n\u2502           \u2514\u2500\u2500 sub-pilot\n\u2502               \u251c\u2500\u2500 figures\n\u2502               \u2514\u2500\u2500 ses-15\n\u2502                   \u2514\u2500\u2500 func\n</code></pre></p>"},{"location":"processing/preprocessing/","title":"Preprocessing","text":""},{"location":"processing/preprocessing/#executing-fmriprep","title":"Executing fMRIPrep","text":"<p>Because fMRIPrep creates a single anatomical reference for all sessions, we generate such reference first by setting the <code>--anat-only</code> flag. If that fMRIPrep execution finishes successfully, the anatomical processing outcomes will be stored in the output folder. We will then run one fMRIPrep process for each dataset's session, which is the recommended way for datasets with a large number of sessions (e.g., more than six sessions). We avert that session-wise fMRIPrep's processes run into race conditions by pre-computing the anatomical reference.</p> <ul> <li> <p> Submit the anatomical workflow:     Launch each session through fMRIPrep in parallel<pre><code>cd code/fmriprep\nbash ss-fmriprep.sh\n</code></pre></p> The sbatch file to run fMRIPrep with <code>--anat-only</code> <pre><code>#!/bin/bash\n# Copyright 2023 The Axon Lab &lt;theaxonlab@gmail.com&gt; \n# \n# Licensed under the Apache License, Version 2.0 (the \"License\"); \n# you may not use this file except in compliance with the License. \n# You may obtain a copy of the License at \n# \n#     http://www.apache.org/licenses/LICENSE-2.0 \n# \n# Unless required by applicable law or agreed to in writing, software \n# distributed under the License is distributed on an \"AS IS\" BASIS, \n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n# See the License for the specific language governing permissions and \n# limitations under the License. \n# \n# We support and encourage derived works from this project, please read \n# about our expectations at \n# \n#     https://www.nipreps.org/community/licensing/ \n#\n# STATEMENT OF CHANGES: This file is derived from work of the Nipreps\n# developers and has been adapted to run smoothly on our particular \n# dataset.\n#\n# ORIGINAL WORK'S ATTRIBUTION NOTICE:\n#\n#     Copyright 2021 The NiPreps Developers &lt;nipreps@gmail.com&gt;\n#\n#     Licensed under the Apache License, Version 2.0 (the \"License\");\n#     you may not use this file except in compliance with the License.\n#     You may obtain a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#     Unless required by applicable law or agreed to in writing, software\n#     distributed under the License is distributed on an \"AS IS\" BASIS,\n#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#     See the License for the specific language governing permissions and\n#     limitations under the License.\n\n#SBATCH --partition=russpold\n#SBATCH --mem=30GB\n#SBATCH --cpus-per-task=16\n#SBATCH --time=20:00:00\n#SBATCH --job-name=fmriprep\n#SBATCH --error=\"slurm-%A.err\"\n\n# Run only the anatomical workflow of fMRIPrep\n\nDATADIR=\"/oak/stanford/groups/russpold/inprocess/cprovins/hcph-pilot/\"\nSUB=\"sub-001\"\nSTUDY=`basename $DATADIR`\n\necho \"Processing the anatomical workflow on subject: $SUB\"\n\nIMG=\"/oak/stanford/groups/russpold/users/cprovins/singularity_images/fmriprep-23.1.4.simg\"\n\nWORKDIR=\"${L_SCRATCH}/fmriprep/${STUDY}/\"\nmkdir -p ${WORKDIR}\nOUTDIR=\"${DATADIR}/derivatives\"\nmkdir -p $OUTDIR\n\nPATCHES=\"\"\n\nBINDINGS=\"-B $DATADIR/inputs:/data:ro \\\n-B ${WORKDIR}:/work \\\n-B ${OUTDIR}:/out \\\n-B $DATADIR/code/license.txt:/opt/freesurfer/license.txt \\\n$PATCHES\"\n\nFMRIPREP_CMD=\"/data /out/fmriprep-23.1.4 participant \\\n        -w /work \\\n        --bids-filter-file /work/filter_file_undistorted.json \\\n        --anat-only --skip_bids_validation \\\n        --nprocs 4 --mem 25G --omp-nthreads 16 -vv\"\n\n#Create json file to filter undistorted anatomical scans\necho '{\"t1w\": {\"datatype\": \"anat\", \"acquisition\": \"undistorted\", \"suffix\": \"T1w\"}}' &gt; ${WORKDIR}/filter_file_undistorted.json\n\nSING_CMD=\"singularity run -e $BINDINGS $IMG $FMRIPREP_CMD\"\necho $SING_CMD\n$SING_CMD\necho \"Completed with return code: $?\"\n</code></pre> </li> <li> <p> Submit a job array with one scanning session each with the <code>--bids-filter-file</code> argument selecting the corresponding sessions, and point the <code>--fs-subjects-dir</code> argument to the folder where FreeSurfer results were stored.     Launch each session through fMRIPrep in parallel<pre><code>cd code/fmriprep\nbash ss-fmriprep.sh\n</code></pre></p> The sbatch file to run fMRIPrep session-wise <pre><code>#!/bin/bash\n# Copyright 2023 The Axon Lab &lt;theaxonlab@gmail.com&gt; \n# \n# Licensed under the Apache License, Version 2.0 (the \"License\"); \n# you may not use this file except in compliance with the License. \n# You may obtain a copy of the License at \n# \n#     http://www.apache.org/licenses/LICENSE-2.0 \n# \n# Unless required by applicable law or agreed to in writing, software \n# distributed under the License is distributed on an \"AS IS\" BASIS, \n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n# See the License for the specific language governing permissions and \n# limitations under the License. \n# \n# We support and encourage derived works from this project, please read \n# about our expectations at \n# \n#     https://www.nipreps.org/community/licensing/ \n#\n# STATEMENT OF CHANGES: This file is derived from work of the Nipreps\n# developers and has been adapted to run smoothly on our particular \n# dataset.\n#\n# ORIGINAL WORK'S ATTRIBUTION NOTICE:\n#\n#     Copyright 2021 The NiPreps Developers &lt;nipreps@gmail.com&gt;\n#\n#     Licensed under the Apache License, Version 2.0 (the \"License\");\n#     you may not use this file except in compliance with the License.\n#     You may obtain a copy of the License at\n#\n#         http://www.apache.org/licenses/LICENSE-2.0\n#\n#     Unless required by applicable law or agreed to in writing, software\n#     distributed under the License is distributed on an \"AS IS\" BASIS,\n#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#     See the License for the specific language governing permissions and\n#     limitations under the License.\n\n#SBATCH --partition=russpold\n#SBATCH --mem=55GB\n#SBATCH --cpus-per-task=16\n#SBATCH --time=20:00:00\n#SBATCH --job-name=fmriprep\n#SBATCH --error=\"slurm-%A_%a.err\"\n\n# Submit a Single Session through fMRIPrep\n\nARGS=($@)\nDATADIR=$1\nSTUDY=`basename $DATADIR`\n\nif [[ -n $SLURM_ARRAY_TASK_ID ]]; then\n  SES=${ARGS[`expr ${SLURM_ARRAY_TASK_ID} + 1`]}\nelse\n  SES=$2\nfi\n\necho \"Processing: $SES\"\n\nIMG=\"/oak/stanford/groups/russpold/users/cprovins/singularity_images/fmriprep-23.1.4.simg\"\n\nWORKDIR=\"${L_SCRATCH}/fmriprep/${STUDY}/${SES}\"\nmkdir -p ${WORKDIR}\nOUTDIR=\"${DATADIR}/derivatives\"\nmkdir -p $OUTDIR\n\nPATCHES=\"\"\n\nBINDINGS=\"-B $DATADIR/inputs:/data:ro \\\n-B ${WORKDIR}:/work \\\n-B ${OUTDIR}:/out \\\n-B $DATADIR/code/license.txt:/opt/freesurfer/license.txt \\\n-B ${HOME}/.cache/templateflow/tpl-MNI152NLin6Asym/:${HOME}/.cache/templateflow/tpl-MNI152NLin6Asym/\n$PATCHES\"\n\nFMRIPREP_CMD=\"/data /out/fmriprep-23.1.4 participant \\\n  -w /work \\\n  --bids-filter-file /work/filter_file_$SES.json \\\n  --skip_bids_validation \\\n  --fs-subjects-dir /out/fmriprep-23.1.4/sourcedata/freesurfer \\\n  --anat-derivatives /out/fmriprep-23.1.4 \\\n  --nprocs 4 --mem 45G --omp-nthreads 8 -vv\"\n\n#Create json file to filter one session only\necho '{\"bold\": {\"datatype\": \"func\", \"session\": \"'${SES#*-}'\", \"suffix\": \"bold\"}}' &gt; ${WORKDIR}/filter_file_${SES}.json\n\nSING_CMD=\"singularity run -e $BINDINGS $IMG $FMRIPREP_CMD\"\necho $SING_CMD\n$SING_CMD\necho \"Completed with return code: $?\"\n</code></pre> </li> </ul>"},{"location":"recruitment-scheduling-screening/recruitment/","title":"Recruitment and screening","text":"<p>Cohort I</p> <p>Recruitment, screening and informed consent do not apply to Cohort I because the participant is the Principal Investigator himself.</p> <p>Cohort III</p> <p>Recruitment, screening and informed consent do not apply to Cohort III because the sessions have already been acquired.</p>"},{"location":"recruitment-scheduling-screening/recruitment/#recruitment-shortlist","title":"Recruitment shortlist","text":"<ul> <li> Distribute the recruitment flyers at CHUV, as well as on EPFL and UNIL campuses, both physically and electronically (e.g., e-mail lists).</li> <li> Insert any new potential participant who shows interest by calling  ###-###-####, SMS, email, etc. in our recruits spreadsheet. Make sure you get an e-mail contact to send documents.</li> </ul> <p>Recruits shortlist</p> <ul> <li> Remove all flyers and indicate that recruitment is not open anymore once the shortlist quotas have been reached (5 males and 5 females for Cohort II).</li> </ul>"},{"location":"recruitment-scheduling-screening/recruitment/#first-contact","title":"First contact","text":"<p>Important</p> <ul> <li> Write an email to them within the next 24h.</li> <li> Use the email template and make sure you attach the MRI Safety and Screening Questionnaire and the Informed Consent Form.</li> <li> Confirm the reception of the email AND the documents over the phone.</li> </ul>"},{"location":"recruitment-scheduling-screening/recruitment/#phone-call","title":"Phone call","text":"<p>Info</p> <p>The study coordinator (\u2588\u2588\u2588, Assistante doctorante) will call the potential participant after at least three days of having sent the information in the case of cohort II (HRA, art. 16-3).</p> <ul> <li> Use the phone script to drive the conversation and record participant responses to questions.</li> <li> If participant consents to the phone screen, conduct it and mark the results (screener date, if responded \"yes\" to any medical questions, whether or not passed screener) in the appropriate columns of the recruitment spreadsheet.</li> <li> Confirm whether the potential participant understood the MRI Safety &amp; Screening Questionnaire, and discuss with them any questions or potential reasons that may disqualify them to participate.</li> </ul> <p>Carefully screen the subject</p> <ul> <li> In case of any doubts emerging from the MRI safety screening, indicate the potential participant that you will call them back within three days, after contacting the responsible physician.</li> <li> Collect as much information as possible about their case.</li> <li> Contact \u2588\u2588\u2588 with all the information.</li> <li> In case of negative assessment by the medical contact, the volunteer MUST NOT participate in the study.</li> <li> Otherwise, call back the participant as soon as possible to confirm participation.</li> </ul> <ul> <li> Female participants will be informed and must acknowledge that they must take a pregnancy test before the first scanning session.</li> <li> If the candidate participant does not pass the phone screen, then end the interview, informing them that they do not meet our inclusion criteria, and mark the screen fail in the recruitment spreadsheet.</li> <li> Make sure that the participant's questions about the study are all addressed and answered.</li> <li> Request the potential participant to confirm they are willing to continue.<ul> <li> Indicate in the shortlist of recruits that the participant is ready to schedule the first session.</li> <li> Tell the participant that they will be called back to set up the first session.</li> <li> Remind them that they can ask further questions at any time before the MRI scan session.</li> </ul> </li> </ul>"},{"location":"recruitment-scheduling-screening/recruitment/#templates","title":"Templates","text":""},{"location":"recruitment-scheduling-screening/recruitment/#first-contact-email-fr","title":"First contact email (FR)","text":"<p>Remember to attach the MRI Safety and Screening Questionnaire and the ICF.</p> <p>Objet: Invitation \u00e0 participer \u00e0 une \u00e9tude d'acquisition IRM du cerveau : informations et documents joints</p> <p>Cher/Ch\u00e8re [nom],</p> <p>Nous vous remercions vivement pour l'int\u00e9r\u00eat que vous portez \u00e0 notre \u00e9tude de recherche sur l'imagerie IRM du cerveau.</p> <p>Notre \u00e9quipe m\u00e8ne actuellement une \u00e9tude visant \u00e0 mieux comprendre les diff\u00e9rentes sources de variabilit\u00e9 lors d'un examen IRM.</p> <p>Nous recherchons des participants\u00b7tes \u00e2g\u00e9s de 24 \u00e0 55 ans, en bonne sant\u00e9 et sans ant\u00e9c\u00e9dents de maladies neurologiques. Les participants\u00b7tes doivent consentir \u00e0 la publication de leurs donn\u00e9es dans le cadre du projet. Des mesures de confidentialit\u00e9 sont rigoureusement mises en place pour garantir l'anonymat des donn\u00e9es. Elles impliquent notamment la suppression de toute information permettant l'identification des participants, telles que la date de naissance ou le nom.</p> <p>Participer \u00e0 cette \u00e9tude implique une pr\u00e9sence \u00e0 12 s\u00e9ances d'acquisition IRM du cerveau, d'environ 1h30 chacune. Ceci repr\u00e9sente un temps de participation total d'environ 18 heures. Vous recevrez une indemnit\u00e9 financi\u00e8re pour votre participation. Veuillez noter que si des d\u00e9couvertes fortuites concernant votre sant\u00e9 \u00e9taient faites au cours de l'exp\u00e9rience, vous consentez \u00e0 en \u00eatre inform\u00e9\u00b7e.</p> <p>Nous vous invitons \u00e0 prendre connaissance des documents joints afin d'obtenir un aper\u00e7u de l'\u00e9tude. Le premier document d\u00e9taille les implications d'une participation \u00e0 l'\u00e9tude, l'organisation des s\u00e9ances d'acquisition et fourni un r\u00e9sum\u00e9 des objectifs du projet. Le second document concerne les \u00e9ventuelles contre-indications \u00e0 passer un examen IRM. Veuillez le remplir soigneusement et nous le retourner.</p> <p>Si apr\u00e8s lecture des informations ci-dessus vous acceptez de participer, nous souhaiterions convenir d'un entretien t\u00e9l\u00e9phonique avec vous afin de r\u00e9capituler les points importants de votre participation. Cet entretien nous permettra \u00e9galement de v\u00e9rifier votre \u00e9ligibilit\u00e9 \u00e0 participer \u00e0 l'\u00e9tude et de r\u00e9pondre \u00e0 toutes vos \u00e9ventuelles questions. Nous vous prions de nous retourner votre r\u00e9ponse dans un d\u00e9lai de 3 jours ouvrables. Afin que nous puissions planifier l'entretien t\u00e9l\u00e9phonique, veuillez \u00e9galement nous indiquer les plages horaires dans lesquelles nous pourrions vous contacter.</p> <p>Entre-temps, si vous avez des questions, n'h\u00e9sitez pas \u00e0 nous contacter par e-mail ou par t\u00e9l\u00e9phone au  ###-###-####. Nous serons ravis de r\u00e9pondre \u00e0 toutes vos questions.</p> <p>Nous vous remercions encore une fois pour votre int\u00e9r\u00eat.</p> <p>Cordialement,  C\u00e9line PROVINS  Assistante-doctorante</p>"},{"location":"recruitment-scheduling-screening/recruitment/#first-contact-call-fr","title":"First contact call (FR)","text":"<p>First contact call script in French</p> <p>Bonjour ici C\u00e9line Provins,</p> <p>Je vous appelle concernant l'\u00e9tude d'acquisition IRM du cerveau. Le but de cet appel est de vous r\u00e9p\u00e9ter les \u00e9l\u00e9ments importants concernant le projet. Ensuite nous allons v\u00e9rifier ensemble que vous \u00eates d\u2019accord avec toutes les exigences pour participer \u00e0 ce projet et nous allons v\u00e9rifier que vous n\u2019avez pas de contre-indications qui vous emp\u00eachent de passer un examen IRM. De plus, je suis aussi l\u00e0 pour r\u00e9pondre \u00e0 toutes vos questions, donc n'h\u00e9sitez pas \u00e0 m'interrompre si vous ne comprenez pas quelque chose ou si vous avez des doutes.</p> <p>Est-ce que vous avez des questions jusque l\u00e0 ?</p> <p>Je vais maintenant vous pr\u00e9senter les \u00e9l\u00e9ments essentiels de votre participation \u00e0 notre \u00e9tude. La participation \u00e0 ce projet comprend 12 s\u00e9ances d'environ 1h30 qui se d\u00e9rouleront au CHUV. Chaque s\u00e9ance durera environ 1h30. Nous commencerons par remplir un bref questionnaire pour assurer la s\u00e9curit\u00e9 de la proc\u00e9dure, cela prendra environ 15 minutes ensuite, nous vous pr\u00e9parerons, nous vous expliquerons l\u2019examen et nous nous assurerons que vous ne portez rien qui puisse causer des perturbations magn\u00e9tiques. Nous v\u00e9rifierons \u00e9galement avec une liste de contr\u00f4le que toutes les mesures de s\u00e9curit\u00e9 sont prises et que vous n'avez pas d'\u00e9l\u00e9ments m\u00e9talliques sur vous. Ensuite vous passerez environ 1h15 dans le scanner.</p> <p>Dans chaque s\u00e9ance nous allons non seulement acqu\u00e9rir des images IRM mais nous allons aussi enregistrer des signaux physiologiques au moyen de quatres appareils suppl\u00e9mentaires. Ces appareils sont compatibles avec l\u2019IRM et ils n'affectent pas votre sant\u00e9.</p> <p>Le premier appareil est une ceinture respiratoire pour suivre votre respiration. C'est simplement une ceinture autour de votre ventre ou autour de votre thorax qui mesure le d\u00e9placement de votre ventre.</p> <p>Par la suite, nous installerons trois \u00e9lectrodes sur la partie sup\u00e9rieure de votre thorax. Ces \u00e9lectrodes seront fix\u00e9es \u00e0 l'aide d'un gel conducteur sur votre peau, permettant ainsi de mesurer vos pulsations cardiaques.</p> <p>Le troisi\u00e8me appareil est une canule respiratoire pour mesurer la concentration de dioxyde de carbone expir\u00e9. Une canule respiratoire est un tube que certaines personnes \u00e2g\u00e9es utilisent pour inhaler de l'oxyg\u00e8ne. La diff\u00e9rence c\u2019est que nous n\u2019allons pas vous donner du gaz, mais simplement mesurer la quantit\u00e9 de dioxide de cabone que vous expirez.</p> <p>Le 4\u00e8me appareil est un appareil pour mesurer le mouvement de vos pupilles. Cet appareil ne sera pas fix\u00e9 sur vous et n'a aucun effet ni sur votre sant\u00e9 ni sur votre confort. Durant toute la s\u00e9ance d'IRM, vous tiendrez un bouton alarme dans votre main, c'est-\u00e0-dire qu'\u00e0 n'importe quel moment si vous avez un probl\u00e8me vous pouvez appuyer sur ce bouton d'alarme et nous interrompons l\u2019examen imm\u00e9diatement et venons vous chercher \u00e0 l'int\u00e9rieur du scanner pour voir avec vous ce qui ne va pas. Vous pouvez interrompre une session \u00e0 tout moment sans explication.</p> <p>Est-ce que vous avez des questions? Non, alors continuons.</p> <p>Les risques li\u00e9s \u00e0 l'IRM sont les suivants.</p> <p>l\u2019IRM \u00e9met un fort champ magn\u00e9tique, il est donc dangereux de rentrer dans la salle avec des objets \u00e0 susceptibilit\u00e9 magn\u00e9tique. C'est pourquoi plus tard nous allons minutieusement v\u00e9rifier ensemble la liste du questionnaire de s\u00e9curit\u00e9 IRM. Toutefois en l\u2019absence d\u2019objet \u00e0 susceptibilit\u00e9 magn\u00e9tique, l\u2019IRM est compl\u00e8tement sans danger car il n\u2019utilise pas de rayonnement ionisant.  Il n'y a pas de danger m\u00eame si on fait beaucoup de s\u00e9ances.</p> <p>Notez que le tunnel est assez \u00e9troit, ce qui pourrait occasionner une l\u00e9g\u00e8re sensation de claustrophobie.</p> <p>Si vous \u00eates une femme, je dois vous informer qu\u2019avant la premi\u00e8re session vous allez devoir faire un test de grossesse. C'est pour v\u00e9rifier que vous n'\u00eates pas enceinte, car \u00e9thiquement nous n'avons pas le droit de scanner des femmes enceintes car les effets des IRM sur le f\u0153tus n'ont pas encore \u00e9t\u00e9 \u00e9tudi\u00e9s en d\u00e9tail. Avant chaque s\u00e9ance vous devrez \u00e9galement donner des informations sur vos r\u00e8gles comme le dernier jour des r\u00e8gles ainsi que la r\u00e9gularit\u00e9 de votre cycle. Ceci est important car le cycle menstruel a un effet sur le cerveau et pour la fiabilit\u00e9 de notre \u00e9tude nous avons besoin ces informations. N\u00e9anmoins, veuillez noter que vous avez la possibilit\u00e9 de choisir de ne pas inclure les informations concernant vos cycles menstruels lorsque nous rendrons les donn\u00e9es publiques.</p> <p>Les sessions d'IRM seront planifi\u00e9es en tenant compte de la disponibilit\u00e9 des \u00e9quipements, de vos pr\u00e9f\u00e9rences et de votre emploi du temps. La participation maximale s'\u00e9tend sur une p\u00e9riode de 20 semaines cons\u00e9cutives, soit 5 mois. Cependant, dans l'id\u00e9al, les s\u00e9ances seront planifi\u00e9es \u00e0 des intervalles r\u00e9guliers.</p> <p>Est-ce que vous avez des questions jusque-l\u00e0 ?</p> <p>Ok donc maintenant je veux juste v\u00e9rifier avec vous que vous \u00eates d'accord avec toutes les exigences concernant la participation \u00e0 ce projet. Est-ce que vous \u00eates \u00e2g\u00e9 entre 24 et 55 ans ? Avez-vous \u00e9t\u00e9 diagnostiqu\u00e9(e) avec un trouble ou une maladie neurologique ? Consentez-vous \u00e0 \u00eatre inform\u00e9(e) des d\u00e9couvertes fortuites relatives \u00e0 votre sant\u00e9 ? En effet, par souci \u00e9thique, les images de la premi\u00e8re session seront transmises \u00e0 un radiologue qui les examinera attentivement. Si une anomalie venait \u00e0 \u00eatre d\u00e9tect\u00e9e dans votre cerveau, vous seriez alors averti(e). Par la suite, un \u00e9l\u00e9ment d'une grande importance est que vous devez donner votre accord pour la publication de vos donn\u00e9es. Cependant, soyez assur\u00e9(e) que nous prendrons toutes les mesures n\u00e9cessaires pour garantir la confidentialit\u00e9 de vos donn\u00e9es avant toute publication.</p> <p>Par exemple, nous allons enlever toute informations qui permettraient de vous reconnaitre comme votre nom, votre date de naissance ou la date de l\u2019examen afin de prot\u00e9ger votre confidentialit\u00e9. \u00cates-vous d'accord avec ce point? Un autre \u00e9l\u00e9ment important est que la participation \u00e0 cette \u00e9tude implique de nombreuses sessions IRM. Comme je vous ai dit 12 sessions d'environ 1h30. Ainsi, je vous prie de prendre un moment pour r\u00e9fl\u00e9chir si votre engagement envers le projet n'est pas excessif ni susceptible de devenir pesant \u00e0 mesure que le temps avance, et si vous disposez du temps n\u00e9cessaire pour mener le projet \u00e0 bien. Vous devez aussi accepter de nous informer si vous prenez des m\u00e9dicaments, si vous consommez de l\u2019alcool ou de la drogue car ces substances ont un effet important sur le cerveau et nous avons besoin de savoir pour pouvoir quantifier ces effets.</p> <p>Une autre contrainte c'est que vous devez \u00e9viter de boire du caf\u00e9 4h avant les s\u00e9ances car le caf\u00e9 aussi est connu pour avoir des effets notables sur le cerveau.</p> <p>Maintenant que nous avons confirm\u00e9 que vous \u00eates d'accord avec toutes ces exigences, je vous rappelle que votre participation est enti\u00e8rement libre et que vous pouvez vous retirer \u00e0 tout moment sans explication. Cependant, il est primordial pour nous que les participants parviennent \u00e0 accomplir les 12 sessions afin d'assurer l'int\u00e9gralit\u00e9 de nos donn\u00e9es. Dans cette optique, nous pr\u00e9f\u00e9rons que vous vous engagiez r\u00e9solument \u00e0 mener \u00e0 terme les 12 sessions, en envisageant une interruption de votre participation uniquement en cas de circonstances urgentes ou impr\u00e9vues.</p> <p>Chaque s\u00e9ance sera r\u00e9mun\u00e9r\u00e9 45 francs plus les frais de transport.</p> <p>Des questions ?</p> <p>OK maintenant nous pouvons regarder ensemble le questionnaire de contr\u00f4le de s\u00e9curit\u00e9 et v\u00e9rifier que vous avez r\u00e9pondu non \u00e0 toutes les questions.</p> <p>Avez-vous r\u00e9pondu oui \u00e0 une des questions ? Non ok parfait.</p> <p>Je veux juste rev\u00e9rifier avec vous que vous n\u2019avez bien pas d'aide auditive.</p> <p>Vous n'avez pas de goutti\u00e8re dentaire, de proth\u00e8se dentaire, de fausses dents etc. Vous n'avez pas non plus de piercing de tatouage ou de maquillage permanent ni d\u2019implant capillaire Vous n'avez jamais \u00e9t\u00e9 bless\u00e9 par un objet m\u00e9tallique. Vous n'avez pas subi des op\u00e9rations dans lesquelles il y aurait des m\u00e9taux qui restent dans votre corps comme des clips chirurgicaux, des agrafes, des fixations vert\u00e9brale, un stimulateur de la moelle \u00e9pini\u00e8re, des extendeurs de tissu Vous ne portez pas de valve cardiaque. Vous portez pas de biostimulateur, de pompe \u00e0 m\u00e9dicament interne ou externe, de cath\u00e9ters ou d'articulation artificielle.</p> <p>C\u2019est parfait, vous \u00eates \u00e9ligible \u00e0 participer.</p> <p>Encore quelques instructions \u00e0 suivre avant chaque la s\u00e9ance. Il faut retirer tous les bijoux, piercing compris, et tous les accessoires de cheveux. Veuillez aussi retirer vos proth\u00e8ses dentaires, les fausses dents etc. Il faut \u00e9galement retirer les aides auditives et les lunettes. Si vous \u00eates un homme, veuillez s'il vous pla\u00eet vous raser la partie sup\u00e9rieure du torse car nous avons besoin de placer les \u00e9lectrodes \u00e0 m\u00eame la peau pour bien enregistrer le signal.</p> <p>Voil\u00e0 c\u2019est toutes les informations que j\u2019ai \u00e0 vous partager. Est-ce que vous avez des questions?</p> <p>En tout cas merci beaucoup pour votre participation! Si vous avez des questions, des doutes, n'h\u00e9sitez pas \u00e0 me rappeler \u00e0 ce num\u00e9ro et je vous rappelle dans quelques jours afin de fixer la premi\u00e8re session.</p> <p>Bonne journ\u00e9e.</p> <p>Au revoir.</p>"},{"location":"recruitment-scheduling-screening/scheduling/","title":"Scheduling","text":"<ul> <li> <p> Iteratively draw participants from the recruitment shortlist and call them back to set their first session.</p> <p>Stop calling potential participants when the sample size has been achieved</p> <p>Once the sample size is filled (e.g., 3M/3F for Cohort II), call the remainder of the participants in the shortlist to let them know that they have been moved into the wait list.</p> </li> <li> <p> The first session will always happen at MRI 1 (Prisma<sup>Fit</sup>, \u2588\u2588\u2588)</p> </li> </ul>"},{"location":"recruitment-scheduling-screening/scheduling/#scheduling-of-the-prismafit-system","title":"Scheduling of the Prisma<sup>Fit</sup> system (\u2588\u2588\u2588)","text":"<p>Contact \u2588\u2588\u2588, MRI Operational Manager, for any doubts/problems regarding this system</p> <ul> <li> Open the \u2588\u2588\u2588 scheduling system (URL) on a browser.</li> <li> With the participant on the phone, find a suitable, empty slot by scrolling the calendar.</li> <li> Click on the preferred slot, make sure that selected resource is \u2588\u2588\u2588</li> <li> Select \u2588\u2588\u2588 in the Operator dropdown menu.</li> <li> Select the adequate length for the session (120 minutes)</li> <li> Select Research on healthy subjects in the Type of Scan box.</li> <li> Select true in Technician Required if you are not a certified operator of the system.</li> </ul>"},{"location":"recruitment-scheduling-screening/scheduling/#scheduling-of-the-vidafit-system","title":"Scheduling of the Vida<sup>Fit</sup> system (\u2588\u2588\u2588)","text":"<p>Contact \u2588\u2588\u2588, Technical MRI Coordinator, for any doubts/problems regarding this system</p> <ul> <li> Open the \u2588\u2588\u2588 scheduling system (URL) on a browser.</li> <li> <p> With the participant on the phone, find a suitable, empty slot by scrolling the calendar.</p> <p>Clinical scanner hours are very restricted</p> <p>The study can only be executed on Fridays after 18h00</p> </li> <li> <p> Click on the preferred slot, make sure that selected resource is \u2588\u2588\u2588</p> </li> <li> Select \u2588\u2588\u2588 in the Operator dropdown menu.</li> <li> Select the adequate length for the session (60 minutes)</li> <li> Select Research on healthy subjects in the Type of Scan box.</li> <li> Select true in Technician Required.</li> </ul>"},{"location":"recruitment-scheduling-screening/scheduling/#scheduling-of-the-vida-system","title":"Scheduling of the Vida system (\u2588\u2588\u2588)","text":"<p>Only \u2588\u2588\u2588, Technical MRI Coordinator, can book this system.</p>"}]}