{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a437301a",
   "metadata": {},
   "source": [
    "# Converting HCPh's physio into BIDS\n",
    "\n",
    "This notebook finalizes the conversion of physiological recordings into BIDS.\n",
    "Before starting, make sure you run the `splice-runs.py` script on all sessions.\n",
    "As a result of running `splice-runs.py`, you will have one hdf5 file corresponding to each run in the input dataset.\n",
    "\n",
    "First, let's import some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d38bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_channel_id' from 'convert' (/data/home/oesteban/workspace/hcph-sops/code/physioconv/convert.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m timezone, timedelta\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _channel_id, _gen_timeseries, get_1st_trigger_time\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m2.5\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_channel_id' from 'convert' (/data/home/oesteban/workspace/hcph-sops/code/physioconv/convert.py)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from json import dumps, loads\n",
    "import string\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import timezone, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "from convert import _channel_id, _gen_timeseries, get_1st_trigger_time\n",
    "\n",
    "import h5py\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 2.5)\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.left'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.bottom'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144da13",
   "metadata": {},
   "source": [
    "Let's define some paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c10027",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/BIOPAC\")\n",
    "BIDS_PATH = Path(\"/data/datasets/hcph\")\n",
    "RECALIBRATED_SESSION = 23\n",
    "FIRST_O2_SESSION = 11 # The cable to record O2 signal has been received midway through the acquisition\n",
    "MISSING_RB = (\"excl029\", )\n",
    "\n",
    "participant = \"001\"\n",
    "session = \"001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128974e",
   "metadata": {},
   "source": [
    "In the file `code/scans.tsv`, we keep a lookup table of *AcqKnowledge* files generated.\n",
    "Some sessions (like 13) required restarting *AcqKnowledge* or some other issue and produced several *runs* as a consequence, we'll need to have special care with those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf7d6f",
   "metadata": {},
   "source": [
    "Prepare repeated metadata across JSON files.\n",
    "These JSON files may be consolidated at the top level of the BIDS structure for the most part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751b626",
   "metadata": {},
   "source": [
    "## Extracting data from already split HDF5 files\n",
    "Once the physiological recordings have been already split by runs with `split-runs.py`, we may finalize conversion to BIDS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c576a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_acq-reliability_dir-LR_physio.hdf5\"\n",
    "# src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_task-bht_dir-LR_physio.hdf5\"\n",
    "# src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_task-qct_dir-LR_physio.hdf5\"\n",
    "# src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_task-rsmovie_dir-LR_physio.hdf5\"\n",
    "out_path = (\n",
    "    BIDS_PATH\n",
    "    / f\"sub-{participant}\"\n",
    "    / f\"ses-{session}\"\n",
    "    / (\"func\" if \"task-\" in src_file.name else \"dwi\")\n",
    ")\n",
    "\n",
    "channels = {}\n",
    "\n",
    "with h5py.File(src_file, \"r\") as h5f:\n",
    "    start_recording = np.datetime64(\n",
    "        h5f.attrs[\"start_recording\"].decode(\"utf-8\").rsplit(\"+\", 1)[0]\n",
    "    )\n",
    "    start_run = h5f.attrs[\"start_run\"]\n",
    "    stop_run = h5f.attrs[\"stop_run\"]\n",
    "    \n",
    "    for i, key in enumerate(h5f.keys()):\n",
    "        metadata = h5f[key].attrs\n",
    "        channel_id = _channel_id(metadata[\"name\"])\n",
    "        channels[channel_id] = dict(metadata.items())\n",
    "        channels[channel_id][\"num\"] = int(key.split(\"_\")[-1])\n",
    "        channels[channel_id][\"data\"] = h5f[key][\"data\"][()]\n",
    "\n",
    "if session.startswith(\"pilot\") or int(session) < FIRST_O2_SESSION:\n",
    "    channels.pop(\"respiratory2\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd80d9",
   "metadata": {},
   "source": [
    "## Extracting the trigger and other digital signals\n",
    "We are ready to extract the trigger channel, identify the first trigger and store the corresponding `stim.tsv.gz` files.\n",
    "\n",
    "First, let's have a look at the trigger signal throughout the timespan of the active MRI scanning for this run.\n",
    "In this visualization, we are not showing the *preamble* (i.e., a few seconds that were recorded before scanning started) or the *appendix* (we split the recordings just before the next sequence starts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8579a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, first_trigger_t = get_1st_trigger_time(channels, start_run)\n",
    "\n",
    "plt.plot(channels[\"trigger\"][\"timeseries\"], channels[\"trigger\"][\"data\"] / 5)\n",
    "plt.xlim((-3, stop_run - start_run + 3))\n",
    "plt.title(f\"Run length: {stop_run - start_run:0.2f}s\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a911629",
   "metadata": {},
   "source": [
    "Now, we can create the sidecar JSON and proceed with storing the data in a `tsv.gz` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_filepath = out_path / src_file.name.replace(\"_physio.hdf5\", \"_stim.tsv.gz\")\n",
    "\n",
    "columns = [\"trigger\"] + sorted([_ch for _ch in channels.keys() if _ch.startswith(\"stim\")])\n",
    "trigger_data = {name: channels[name][\"data\"] for name in columns}\n",
    "\n",
    "trigger_sidecar = {\n",
    "    \"SamplingFrequency\": channels[\"trigger\"][\"frequency\"],\n",
    "    \"StartTime\": channels[\"trigger\"][\"timeseries\"][0],\n",
    "    \"Columns\": columns,\n",
    "    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n",
    "}\n",
    "\n",
    "for col in columns:\n",
    "    trigger_sidecar[col] = {\n",
    "        \"Description\": f\"Pulse signal [{channels[col]['name']}] generated with Psychopy\",\n",
    "        \"Units\": channels[col][\"units\"],\n",
    "        \"Model\": \"STP100D\",\n",
    "    }\n",
    "\n",
    "trigger_sidecar[\"trigger\"][\"Description\"] = f\"Scanner trigger signal [{channels['trigger']['name']}].\"\n",
    "\n",
    "if out_path.name == \"dwi\":\n",
    "    trigger_sidecar[\"trigger\"][\"Description\"] += (\n",
    "        \" IMPORTANT! The DWI sequence sends triggers during calibration.\"\n",
    "        \" Therefore, a total of 203 trigger pulses SHOULD be discarded at the beginning of the run\"\n",
    "        \" (corresponding to 2 x 87 slices single slice mode, plus 29 for one multi-slice volume).\"\n",
    "    )\n",
    "\n",
    "(trigger_filepath.parent / trigger_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(trigger_sidecar, indent=2))\n",
    "\n",
    "\n",
    "pd.DataFrame(trigger_data).to_csv(\n",
    "    trigger_filepath,\n",
    "    compression=\"gzip\",\n",
    "    header=False,\n",
    "    sep=\"\\t\",\n",
    "    na_rep=\"n/a\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66429b",
   "metadata": {},
   "source": [
    "## Extracting cardiac signal\n",
    "\n",
    "Once the trigger and other digital signals are extracted and stored, we proceed with the cardiac signal (ECG):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = \"cardiac\"\n",
    "\n",
    "# Generate BIDS name\n",
    "recording_filepath = out_path / src_file.name.replace(\"_physio.hdf5\", f\"_recording-{recording}_physio.tsv.gz\")\n",
    "\n",
    "# Generate the time axis\n",
    "channel_names = sorted([key for key in channels.keys() if key.startswith(recording)])\n",
    "\n",
    "# All recordings MUST have the same frequency and hence, have same time axis\n",
    "timeseries = _gen_timeseries(channels[channel_names[0]], offset=first_trigger_t)\n",
    "for name in channel_names:\n",
    "    channels[name][\"timeseries\"] = timeseries\n",
    "\n",
    "# Prepare metadata\n",
    "sidecar = loads(Path(f\"defaults_{recording}.json\").read_text()).copy()\n",
    "sidecar.update({\n",
    "    \"SamplingFrequency\": channels[channel_names[0]][\"frequency\"],\n",
    "    \"StartTime\": timeseries[0],\n",
    "})\n",
    "\n",
    "recording_data = {}  # Prepare dataframe\n",
    "for colname, name in zip(sidecar[\"Columns\"], channel_names):\n",
    "    sidecar[colname][\"Units\"] = channels[name][\"units\"]\n",
    "    recording_data[colname] = channels[name][\"data\"]\n",
    "\n",
    "sidecar[\"Columns\"] = list(recording_data.keys())\n",
    "\n",
    "# We can store metadata now\n",
    "(recording_filepath.parent / recording_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(sidecar, indent=2))\n",
    "\n",
    "recording_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abb24c",
   "metadata": {},
   "source": [
    "Now, let's peek into the data.\n",
    "First, we check the frequency is 5 kHz.\n",
    "Then, we visualize the trigger channel and extract the onset location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "plt.plot(channels[\"cardiac\"][\"timeseries\"], channels[\"cardiac\"][\"data\"])\n",
    "plt.plot(channels[\"trigger\"][\"timeseries\"], channels[\"trigger\"][\"data\"] / 40)\n",
    "plt.vlines(0, -0.2, 0.0, colors=\"r\")\n",
    "plt.xlim(-5, 10)\n",
    "plt.ylim(bottom=-0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(recording_data).to_csv(\n",
    "    recording_filepath,\n",
    "    compression=\"gzip\",\n",
    "    header=False,\n",
    "    sep=\"\\t\",\n",
    "    na_rep=\"n/a\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c59a21",
   "metadata": {},
   "source": [
    "## Extracting respiratory signals\n",
    "\n",
    "Next, we extract respiratory signals:\n",
    "\n",
    "- respiration belt and CO<sub>2</sub>, for all sessions before session 11\n",
    "- respiration belt, CO<sub>2</sub>, and O<sub>2</sub>, for all sessions from 11 onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7532db",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = \"respiratory\"\n",
    "\n",
    "# Generate BIDS name\n",
    "recording_filepath = out_path / src_file.name.replace(\"_physio.hdf5\", f\"_recording-{recording}_physio.tsv.gz\")\n",
    "\n",
    "# Generate the time axis\n",
    "channel_names = sorted([key for key in channels.keys() if key.startswith(recording)])\n",
    "\n",
    "# All recordings MUST have the same frequency and hence, have same time axis\n",
    "timeseries = _gen_timeseries(channels[channel_names[0]], offset=first_trigger_t)\n",
    "for name in channel_names:\n",
    "    channels[name][\"timeseries\"] = timeseries\n",
    "\n",
    "# Prepare metadata\n",
    "sidecar = loads(Path(f\"defaults_{recording}.json\").read_text()).copy()\n",
    "sidecar.update({\n",
    "    \"SamplingFrequency\": channels[channel_names[0]][\"frequency\"],\n",
    "    \"StartTime\": timeseries[0],\n",
    "})\n",
    "\n",
    "recording_data = {}  # Prepare dataframe\n",
    "for colname, name in zip(sidecar[\"Columns\"], channel_names):\n",
    "    sidecar[colname][\"Units\"] = channels[name][\"units\"]\n",
    "    recording_data[colname] = channels[name][\"data\"]\n",
    "\n",
    "sidecar[\"Columns\"] = list(recording_data.keys())\n",
    "\n",
    "# We can store metadata now\n",
    "(recording_filepath.parent / recording_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(sidecar, indent=2))\n",
    "\n",
    "recording_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "plt.plot(channels[\"trigger\"][\"timeseries\"], 0.5 * channels[\"respiratory1\"][\"data\"].max() * channels[\"trigger\"][\"data\"] / channels[\"trigger\"][\"data\"].max())\n",
    "\n",
    "plt.plot(channels[\"respiratory1\"][\"timeseries\"], channels[\"respiratory1\"][\"data\"])\n",
    "plt.xlim((-3, stop_run - start_run + 3));\n",
    "plt.plot(channels[\"respiratory0\"][\"timeseries\"], channels[\"respiratory1\"][\"data\"].max() * channels[\"respiratory0\"][\"data\"] / channels[\"respiratory0\"][\"data\"].max())\n",
    "# plt.xlim(-5, 10)\n",
    "# plt.ylim(bottom=-0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(recording_data).to_csv(\n",
    "    recording_filepath,\n",
    "    compression=\"gzip\",\n",
    "    header=False,\n",
    "    sep=\"\\t\",\n",
    "    na_rep=\"n/a\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
