{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a437301a",
   "metadata": {},
   "source": [
    "# Converting HCPh's physio into BIDS\n",
    "\n",
    "This notebook finalizes the conversion of physiological recordings into BIDS.\n",
    "Before starting, make sure you run the `splice-runs.py` script on all sessions.\n",
    "As a result of running `splice-runs.py`, you will have one hdf5 file corresponding to each run in the input dataset.\n",
    "\n",
    "First, let's import some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d38bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from json import dumps, loads\n",
    "import string\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import timezone, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "from acq2bids import (\n",
    "    _channel_id,\n",
    "    _gen_timeseries,\n",
    "    get_1st_trigger_time,\n",
    "    RECALIBRATED_SESSION,\n",
    "    FIRST_O2_SESSION,\n",
    "    MISSING_RB,\n",
    ")\n",
    "\n",
    "import h5py\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 2.5)\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['axes.spines.left'] = False\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.bottom'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6144da13",
   "metadata": {},
   "source": [
    "Let's define some paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c10027",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"/data/datasets/hcph-pilot-sourcedata/recordings/BIOPAC\")\n",
    "BIDS_PATH = Path(\"/data/datasets/hcph\")\n",
    "\n",
    "participant = \"001\"\n",
    "session = \"001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9128974e",
   "metadata": {},
   "source": [
    "In the file `code/scans.tsv`, we keep a lookup table of *AcqKnowledge* files generated.\n",
    "Some sessions (like 13) required restarting *AcqKnowledge* or some other issue and produced several *runs* as a consequence, we'll need to have special care with those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf7d6f",
   "metadata": {},
   "source": [
    "Prepare repeated metadata across JSON files.\n",
    "These JSON files may be consolidated at the top level of the BIDS structure for the most part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751b626",
   "metadata": {},
   "source": [
    "## Extracting data from already split HDF5 files\n",
    "Once the physiological recordings have been already split by runs with `split-runs.py`, we may finalize conversion to BIDS:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c576a79b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/data/datasets/hcph-pilot-sourcedata/recordings/BIOPAC/sub-001_ses-001_acq-reliability_dir-LR_physio.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m out_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     BIDS_PATH\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticipant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mses-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m/\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m src_file\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdwi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m channels \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m h5f:\n\u001b[1;32m     15\u001b[0m     start_recording \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime64(\n\u001b[1;32m     16\u001b[0m         h5f\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_recording\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     start_run \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_run\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.miniconda/lib/python3.9/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.miniconda/lib/python3.9/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/data/datasets/hcph-pilot-sourcedata/recordings/BIOPAC/sub-001_ses-001_acq-reliability_dir-LR_physio.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_acq-reliability_dir-LR_physio.hdf5\"\n",
    "# src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_task-bht_dir-LR_physio.hdf5\"\n",
    "# src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_task-qct_dir-LR_physio.hdf5\"\n",
    "# src_file = DATA_PATH / f\"sub-{participant}_ses-{session}_task-rsmovie_dir-LR_physio.hdf5\"\n",
    "out_path = (\n",
    "    BIDS_PATH\n",
    "    / f\"sub-{participant}\"\n",
    "    / f\"ses-{session}\"\n",
    "    / (\"func\" if \"task-\" in src_file.name else \"dwi\")\n",
    ")\n",
    "\n",
    "channels = {}\n",
    "\n",
    "with h5py.File(src_file, \"r\") as h5f:\n",
    "    start_recording = np.datetime64(\n",
    "        h5f.attrs[\"start_recording\"].decode(\"utf-8\").rsplit(\"+\", 1)[0]\n",
    "    )\n",
    "    start_run = h5f.attrs[\"start_run\"]\n",
    "    stop_run = h5f.attrs[\"stop_run\"]\n",
    "    \n",
    "    for i, key in enumerate(h5f.keys()):\n",
    "        metadata = h5f[key].attrs\n",
    "        channel_id = _channel_id(metadata[\"name\"])\n",
    "        channels[channel_id] = dict(metadata.items())\n",
    "        channels[channel_id][\"num\"] = int(key.split(\"_\")[-1])\n",
    "        channels[channel_id][\"data\"] = h5f[key][\"data\"][()]\n",
    "\n",
    "if session.startswith(\"pilot\") or int(session) < FIRST_O2_SESSION:\n",
    "    channels.pop(\"respiratory2\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd80d9",
   "metadata": {},
   "source": [
    "## Extracting the trigger and other digital signals\n",
    "We are ready to extract the trigger channel, identify the first trigger and store the corresponding `stim.tsv.gz` files.\n",
    "\n",
    "First, let's have a look at the trigger signal throughout the timespan of the active MRI scanning for this run.\n",
    "In this visualization, we are not showing the *preamble* (i.e., a few seconds that were recorded before scanning started) or the *appendix* (we split the recordings just before the next sequence starts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8579a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, first_trigger_t = get_1st_trigger_time(channels, start_run)\n",
    "\n",
    "plt.plot(channels[\"trigger\"][\"timeseries\"], channels[\"trigger\"][\"data\"] / 5)\n",
    "plt.xlim((-3, stop_run - start_run + 3))\n",
    "plt.title(f\"Run length: {stop_run - start_run:0.2f}s\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a911629",
   "metadata": {},
   "source": [
    "Now, we can create the sidecar JSON and proceed with storing the data in a `tsv.gz` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_filepath = out_path / src_file.name.replace(\"_physio.hdf5\", \"_stim.tsv.gz\")\n",
    "\n",
    "columns = [\"trigger\"] + sorted([_ch for _ch in channels.keys() if _ch.startswith(\"stim\")])\n",
    "trigger_data = {name: channels[name][\"data\"] for name in columns}\n",
    "\n",
    "trigger_sidecar = {\n",
    "    \"SamplingFrequency\": channels[\"trigger\"][\"frequency\"],\n",
    "    \"StartTime\": channels[\"trigger\"][\"timeseries\"][0],\n",
    "    \"Columns\": columns,\n",
    "    \"Manufacturer\": \"BIOPAC Systems, Inc., Goleta, CA, US\",\n",
    "}\n",
    "\n",
    "for col in columns:\n",
    "    trigger_sidecar[col] = {\n",
    "        \"Description\": f\"Pulse signal [{channels[col]['name']}] generated with Psychopy\",\n",
    "        \"Units\": channels[col][\"units\"],\n",
    "        \"Model\": \"STP100D\",\n",
    "    }\n",
    "\n",
    "trigger_sidecar[\"trigger\"][\"Description\"] = f\"Scanner trigger signal [{channels['trigger']['name']}].\"\n",
    "\n",
    "if out_path.name == \"dwi\":\n",
    "    trigger_sidecar[\"trigger\"][\"Description\"] += (\n",
    "        \" IMPORTANT! The DWI sequence sends triggers during calibration.\"\n",
    "        \" Therefore, a total of 203 trigger pulses SHOULD be discarded at the beginning of the run\"\n",
    "        \" (corresponding to 2 x 87 slices single slice mode, plus 29 for one multi-slice volume).\"\n",
    "    )\n",
    "\n",
    "(trigger_filepath.parent / trigger_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(trigger_sidecar, indent=2))\n",
    "\n",
    "\n",
    "pd.DataFrame(trigger_data).to_csv(\n",
    "    trigger_filepath,\n",
    "    compression=\"gzip\",\n",
    "    header=False,\n",
    "    sep=\"\\t\",\n",
    "    na_rep=\"n/a\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66429b",
   "metadata": {},
   "source": [
    "## Extracting cardiac signal\n",
    "\n",
    "Once the trigger and other digital signals are extracted and stored, we proceed with the cardiac signal (ECG):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = \"cardiac\"\n",
    "\n",
    "# Generate BIDS name\n",
    "recording_filepath = out_path / src_file.name.replace(\"_physio.hdf5\", f\"_recording-{recording}_physio.tsv.gz\")\n",
    "\n",
    "# Generate the time axis\n",
    "channel_names = sorted([key for key in channels.keys() if key.startswith(recording)])\n",
    "\n",
    "# All recordings MUST have the same frequency and hence, have same time axis\n",
    "timeseries = _gen_timeseries(channels[channel_names[0]], offset=first_trigger_t)\n",
    "for name in channel_names:\n",
    "    channels[name][\"timeseries\"] = timeseries\n",
    "\n",
    "# Prepare metadata\n",
    "sidecar = loads(Path(f\"defaults_{recording}.json\").read_text()).copy()\n",
    "sidecar.update({\n",
    "    \"SamplingFrequency\": channels[channel_names[0]][\"frequency\"],\n",
    "    \"StartTime\": timeseries[0],\n",
    "})\n",
    "\n",
    "recording_data = {}  # Prepare dataframe\n",
    "for colname, name in zip(sidecar[\"Columns\"], channel_names):\n",
    "    sidecar[colname][\"Units\"] = channels[name][\"units\"]\n",
    "    recording_data[colname] = channels[name][\"data\"]\n",
    "\n",
    "sidecar[\"Columns\"] = list(recording_data.keys())\n",
    "\n",
    "# We can store metadata now\n",
    "(recording_filepath.parent / recording_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(sidecar, indent=2))\n",
    "\n",
    "recording_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98abb24c",
   "metadata": {},
   "source": [
    "Now, let's peek into the data.\n",
    "First, we check the frequency is 5 kHz.\n",
    "Then, we visualize the trigger channel and extract the onset location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "plt.plot(channels[\"cardiac\"][\"timeseries\"], channels[\"cardiac\"][\"data\"])\n",
    "plt.plot(channels[\"trigger\"][\"timeseries\"], channels[\"trigger\"][\"data\"] / 40)\n",
    "plt.vlines(0, -0.2, 0.0, colors=\"r\")\n",
    "plt.xlim(-5, 10)\n",
    "plt.ylim(bottom=-0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(recording_data).to_csv(\n",
    "    recording_filepath,\n",
    "    compression=\"gzip\",\n",
    "    header=False,\n",
    "    sep=\"\\t\",\n",
    "    na_rep=\"n/a\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c59a21",
   "metadata": {},
   "source": [
    "## Extracting respiratory signals\n",
    "\n",
    "Next, we extract respiratory signals:\n",
    "\n",
    "- respiration belt and CO<sub>2</sub>, for all sessions before session 11\n",
    "- respiration belt, CO<sub>2</sub>, and O<sub>2</sub>, for all sessions from 11 onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7532db",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = \"respiratory\"\n",
    "\n",
    "# Generate BIDS name\n",
    "recording_filepath = out_path / src_file.name.replace(\"_physio.hdf5\", f\"_recording-{recording}_physio.tsv.gz\")\n",
    "\n",
    "# Generate the time axis\n",
    "channel_names = sorted([key for key in channels.keys() if key.startswith(recording)])\n",
    "\n",
    "# All recordings MUST have the same frequency and hence, have same time axis\n",
    "timeseries = _gen_timeseries(channels[channel_names[0]], offset=first_trigger_t)\n",
    "for name in channel_names:\n",
    "    channels[name][\"timeseries\"] = timeseries\n",
    "\n",
    "# Prepare metadata\n",
    "sidecar = loads(Path(f\"defaults_{recording}.json\").read_text()).copy()\n",
    "sidecar.update({\n",
    "    \"SamplingFrequency\": channels[channel_names[0]][\"frequency\"],\n",
    "    \"StartTime\": timeseries[0],\n",
    "})\n",
    "\n",
    "recording_data = {}  # Prepare dataframe\n",
    "for colname, name in zip(sidecar[\"Columns\"], channel_names):\n",
    "    sidecar[colname][\"Units\"] = channels[name][\"units\"]\n",
    "    recording_data[colname] = channels[name][\"data\"]\n",
    "\n",
    "sidecar[\"Columns\"] = list(recording_data.keys())\n",
    "\n",
    "# We can store metadata now\n",
    "(recording_filepath.parent / recording_filepath.name.replace(\".tsv.gz\", \".json\")).write_text(dumps(sidecar, indent=2))\n",
    "\n",
    "recording_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n",
    "plt.plot(channels[\"trigger\"][\"timeseries\"], 0.5 * channels[\"respiratory1\"][\"data\"].max() * channels[\"trigger\"][\"data\"] / channels[\"trigger\"][\"data\"].max())\n",
    "\n",
    "plt.plot(channels[\"respiratory1\"][\"timeseries\"], channels[\"respiratory1\"][\"data\"])\n",
    "plt.xlim((-3, stop_run - start_run + 3));\n",
    "plt.plot(channels[\"respiratory0\"][\"timeseries\"], channels[\"respiratory1\"][\"data\"].max() * channels[\"respiratory0\"][\"data\"] / channels[\"respiratory0\"][\"data\"].max())\n",
    "# plt.xlim(-5, 10)\n",
    "# plt.ylim(bottom=-0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(recording_data).to_csv(\n",
    "    recording_filepath,\n",
    "    compression=\"gzip\",\n",
    "    header=False,\n",
    "    sep=\"\\t\",\n",
    "    na_rep=\"n/a\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
